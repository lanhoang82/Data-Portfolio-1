---
title: "Galeries Lafayette - Brand Perceptions and How They Drive Loyalty and Commitment"
date: "19/5/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Advanced Data Driven Decision Making.

## Case Study 3.

```{r}
rm(list = ls()) #Clear the environment.
cat("\014") #Clear the console.
data =read.csv("Case Study III_Structural Equation Modeling.csv") #Download the data.
```

### Libraries.

```{r , message = FALSE}
library(ggplot2)
library(naniar)
library(corrplot)
library(Hmisc) #to calculate p-value of correlation matrix
library(ellipse)
library(gplots)
library(psych)
library(REdaS)
library(nFactors)
library(FactoMineR)
library(factoextra)
library(lavaan)
library(psy)
library(knitr)
library(semPlot)
library(dplyr)

```

### Data exploration.

We explore the data to see if there are any missing values. 

```{r}
summary(data)
```

As mentioned in the seminar, the value `999` represents missing values. To avoid this numeric value from being taken account in our models, we will convert this value to NA. 

```{r}
data_new =data.frame(sapply(data,function(x) ifelse((x==999),NA,x)))

summary(data_new)
```

```{r}
gg_miss_var(data_new, show_pct = TRUE)
```

### Run a factor analysis 1. First step: Calculate the correlation matrix

```{r}
#select the 22 images for the factor analysis
data_new1 <- data_new[,c(1:22)]

```

#### Correlation matrix.

Checking the adequacy of the correlation matrix.

Source: http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software

```{r}
raqMatrix_data = cor(data_new1, use="complete.obs") #We create a matrix.

corrplot(as.matrix(raqMatrix_data)) 
cor.plot(raqMatrix_data)
```

```{r}
options(scipen=999)
data.corr <- rcorr(as.matrix(data_new1))
data.corr$P
```

We see that all correlations are statistically significant.

### Anti-image Correlation, KMO and Bartlett’s Test

Source: https://www.rdocumentation.org/packages/psych/versions/2.1.9/topics/KMO

Source: https://www.statology.org/bartletts-test-of-sphericity/

```{r}
KMOTEST <- KMOS(data_new1, use="complete.obs")

KMOTEST$KMO
```

This seems to be a good results as it's more than 0.8.

```{r}
sort(KMOTEST$MSA) 
```

MSA is the overall Measure of Sampling Adequacy. MSA indicates „middling“ adequacy 
of data for FA. Since a value above 0.6 is required for a good factor analysis, 
we have all variables meeting this threshold. 

`Im2` and `Im6` have the lowest values but still over the threshold, so we will keep an eye out for them in further analysis. 

```{r}
bart_spher(data_new1, use="complete.obs") 

cortest.bartlett(as.matrix(raqMatrix_data), n=100) #optional. 
```

As the p.value < 0.05, our dataset is suitable for a data reduction technique. 
We could use this data frame for PCA or factor analysis. As our variables are generally
correlated, we could combine them into linear combinations that are able to capture 
significant variance present in the data.

Bartlett‘s Test of sphericity is highly significant: The H0 that all correlations 
between the IVs are 0 can be rejected.

### Question 1. What are the dimensions by which Galeries Lafayette is perceived?

In this first step, we run a confirmatory factor analysis to determine the dimensions
by which Galeries Lafayette is perceived by its customers. Prior to the CFA, run
an exploratory factor analysis in R to get an idea of which dimensions customers
perceive Galeries Lafayette

### Factor analysis using PCA method, as identified as the superior method from Case 2

Based on the information provided for the case, it is unclear how many factors/dimensions we will end up with the questionnaire’s designer.

```{r}
r_matrix <- corr.test(data_new1, use="complete.obs")$r

screeplot <- cbind(x = seq(1:22), data.frame(y = (eigen(r_matrix)$values)))

ggplot(screeplot, aes(x = x, y = y)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 1, color = "red") + xlab("Factors") + ylab("Eigenvalues") +
  ggtitle("Scree plot") +
  theme(plot.title = element_text(color="black", size=20, face="bold.italic", hjust = 0.5)) 
```

Generally, as a rule of thumb, a factor’s Eigenvalues greater than 1 is the good benchmark, as this is when a factor shows the contribution of this factor in explaining the total variance. Based on this Scree plot, we see that the Eigenvalue of 7 factors is just below the threshold value of 1, so perhaps this might not be the best number of factors. But as a measure of assurance, we will still run a principal axis factoring with 8 factors, as well as 7 factors and 6 factors to determine the best number of factors.

Here we examine another way of looking at the Eigenvalues through tabular format and in relations with the total variance explained. Let's see of it confirms what we previously said.

```{r}
eigen.v <- eigen(r_matrix)$values

var <- eigen.v/ncol(data_new1)*100

total.var <- cumsum(eigen.v/ncol(data_new1))*100

total.var.explained <- cbind(EigenValue = eigen.v, Variance = var, Total_Variance = total.var)

round(total.var.explained, 5)
```

With the original data set with 22 images, we see that the first factor has an eigenvalue of 9.97759 and that it can explain more than 40% of the overall variance. With 6 factors, we still have the eigenvalue of the 6th factor in the acceptable range (greater than 1) while explaining around 76% of the overall variance of all variables. So we’ll take note of 6 factors as the potential solution. However, when looking at the Eigenvalue, we can see that there is a huge drop between 8 and 9 factors (from 0.71161 to 0.56786). We should definitely not consider 9 factors but 8 might be a solution, as well as 7 factors. As a measure of assurance, we will still run a principal axis factoring with 8 factors, as well as 7 factors and 6 factors to determine the best number of factors.


### Factor Analysis for 8 factors

```{r}
pa_8 <- principal(data_new1, nfactors = 8, rotate = 'varimax')
print(pa_8$loadings, cutoff = 0.3, sort = TRUE)
```

```{r}
sort(pa_8[["communality"]])
```

```{r}
fa.diagram(pa_8)
```

We see that Im9, Im11 and Im15 have the lowest communalities of all. Meanwhile, Im8, Im9 and Im15 have low loadings, so we should keep an eye out for them. Furthermore, while Im8 is loaded with Im10 and Im14, which are all in the theme of food, Im8 is slightly different in that it's about French traditional cuisine while the other 2 images are about gourmet food. Not all French traditional cuisines are gourmet. 

Im9 is loaded together with Im6 and Im7. They are indeed around French themes, the country itself, the French art of living and French fashion. We could say that French fashion is slightly more specific than France the country and French art of living. 
Im15 is loaded with Im1 and Im2. While the first two images are about assortment qualities, Im15 is also about the quality of the brand selection in the sense that it's professional. It's also ambivalent that it's loaded also in Factor 8 about the professionalism of the Galleries. So this might be slightly out of place. We can examine if when we reduce a factor, Im15 would be loaded more accurately.

### For 7 factors 

```{r}
pa_7 <- principal(data_new1, nfactors = 7, rotate = 'varimax')
print(pa_7$loadings, cutoff = 0.3, sort = TRUE)
```

```{r}
sort(pa_7[["communality"]])
```

```{r}
fa.diagram(pa_7)
```

The spotted suspect Im 15, Im9 and Im8 keep having somewhat weak loadings. Im15 is still loaded with Im1 and Im2 and stopped being loaded with Im16 and Im19.

With 7 factors, we saw that Im16 and Im19 previously loading well in the 8th factor now spread across Factor 5, Factor 6 and Factor 7 with very weak loadings. The strongest loadings are with Factor 7 but the content of these Images don't go together with other Images in the same factor (about cuisines).

Perhaps we should have 8 factors after all. But to be sure, let's try with 6 factors, just as a safety measure for our analysis.

```{r}
pa_6 <- principal(data_new1, nfactors = 6, rotate = 'varimax')
print(pa_6$loadings, cutoff = 0.3, sort = TRUE)
```

```{r}
sort(pa_6[["communality"]])
```


```{r}
fa.diagram(pa_6)
```

We see that Im8 seems to have good loadings here in Factor 2. However when we look at the Image descriptions, the Images seem a rather out of place when Im8 talks about cuisine which goes with Im10 and Im14, but Im7 and Im6 talk about France-related things in general and not necessary relating to food.

Im9 (French fashion) still has low loading but now loaded in Factor 6 with Im18 and Im17 which talk about being trendy and hip in general. There are some relations, but I wouldn't say the link is very obvious.

Im15 now loaded with Im1, Im2, Im16 and Im19. While Im15 has closer ties with Im16 and Im19 (in terms of the professional aspect), it doesn't really link with Im1 and Im2 (in terms of assortment). So I would say this Factor doesn't really make sense.

So having 6 factors might be a stretch, forcing certain Images to be in the same factors.

With these in mind, I would say that 8 factors make the most sense as they seem to represent different separate concepts. We could try rerunning without the images that are causing issues (Im8, 9 and 15).

```{r}
data_new2 <- data_new1[,-c(8,9,15)] #New dataset.
```

### For 8 factors with new data set

```{r}
pa_8_new <- principal(data_new2, nfactors = 8, rotate = 'varimax')
print(pa_8_new$loadings, cutoff = 0.3, sort = TRUE)
```

```{r}
sort(pa_8_new[["communality"]])
```

```{r}
fa.diagram(pa_8_new)
```

### For 7 factors new data set

```{r}
pa_7_new <- principal(data_new2, nfactors = 7, rotate = 'varimax')
print(pa_7_new$loadings, cutoff = 0.3, sort = TRUE)
```

```{r}
sort(pa_7_new[["communality"]])
```

```{r}
fa.diagram(pa_7_new)
```

### For 6 factors new data set

```{r}
pa_6_new <- principal(data_new2, nfactors = 6, rotate = 'varimax')
print(pa_6_new$loadings, cutoff = 0.3, sort = TRUE)
```

```{r}
sort(pa_6_new[["communality"]])
```

```{r}
fa.diagram(pa_6_new)
```

Based on these reruns of the PCA models with different numbers of factors using the new data set, we can conclude that the model with 8 factors is the most optimal. This model has clean high loadings and no cross-loadings. The moment we reduce the number of factors, images are being forced with new factors that don't really make sense conceptually and they also have weaker cross-loadings.

We ended up with 8 dimensions:

Factor 1: Im3, Im4 and Im5. It could be associated to decoration.
Factor 2: Im6 and Im7. It could be associated to France country.
Factor 3: Im20, Im21 and Im22. It could be associated to relaxation atmosphere.
Factor 4: Im11, Im12 and Im13. It could be associated to luxury.
Factor 5: Im1 and Im2. It could be associated to assortment/diversity.
Factor 6: Im17 and Im18. It could be associated to trend.
Factor 7: Im16 and Im19. It could be associated to professionalism.
Factor 8: Im10 and Im14. It could be associated to gourmet food.

### Confirmatory Factor Analysis

As seen in the seminar of the 7th April, we create the model as follows:

```{r}
model<-"
Decoration=~Im3+Im4+Im5
France=~Im6+Im7
Relaxation=~Im20+Im21+Im22
Luxury=~Im11+Im12+Im13
Assortment=~Im1+Im2
Trend=~Im17+Im18
Professionalism=~Im16+Im19
Gourmet=~Im10+Im14
"

fit <- cfa(model, data=data_new, missing="ML")
Sum_fit <- summary(fit, fit.measures=TRUE,standardized=TRUE)
```

Let's have a look at some coefficients/values to estimate the global fit measures.

RMSEA lower or equal to 0.05, it is a good fit. (Hu & Bentler (1999) suggest a cut off value of 0.06 before one can conclude that there is a good fit between model and data.) Here, the RMSEA is 0.044 so we have a very good fit.

As mentioned in the lecture, ratio Chi2-value/df should be below 5 for samples up to 1000. Here, we note that we have 553 observation though. In our case, the Chi-square test: 259.047/124 = 2.089089, which is less than 5 so the fit of the model is good. 

Regarding the User Model versus Baseline Model, if the Comparative Fit Index (CFI) is > 0.95, we accept the model. Here, the CFI is equal to 0.982, so we can accept our model.

Our three global fit measures are very satisfactory!

```{r}
Sum_fit$FIT[c("chisq","df","rmsea","cfi")]
```

Regarding the Latent Variables part, the loading of all indicators (0.615 for Im11 and 0.760 for Im5 are the smallest ones) are very good. Almost each loading is more than 0.7 which means at least 50% of the indicator’s variance is accounted for by the underlying construct.

```{r}
CronDeco=cronbach(subset(data_new2, select = c(Im3:Im5)))
CronDeco

CronFrance=cronbach(subset(data_new2, select = c(Im6:Im7)))
CronFrance

CronRela=cronbach(subset(data_new2, select = c(Im20:Im22)))
CronRela

CronLux=cronbach(subset(data_new2, select = c(Im11:Im13)))
CronLux

CronAsso=cronbach(subset(data_new2, select = c(Im1:Im2)))
CronAsso

CronTrend=cronbach(subset(data_new2, select = c(Im17:Im18)))
CronTrend

CronPro=cronbach(subset(data_new2, select = c(Im16,Im19)))
CronPro

CronGourmet=cronbach(subset(data_new2, select = c(Im10,Im14)))
CronGourmet
```

All constructs have Cronbach’s Alpha more than 0.79 (Cronbach ́s a > 0.7, i.e. is good measurement) which indicate having high internal consistency reliability. we just look at modification indices to be sure. They all seem pretty normal and low. If anything Trend and Im13 (as part of Luxury), as well as Im11 and Im13 (both as part of Luxury) seem to be more more correlated and share some higher variance than the rest.

```{r}
modificationindices(fit) %>%filter(mi>10)

```

```{r}
std_fit=inspect(fit, "std")
std_fit$psi
```

The correlation matrix shows that the constructs are relatively distinct. If anything, Professionalism tends to show a bit more similarities with Decoration and Trend, but these are not too high and we could still choose to keep them. 


```{r}
parameterestimates(fit, boot.ci.type = "bca.simple", standardized = TRUE)%>% kable()
```

We can see that all the p-values are significant. Moreover, no ci.lower or ci.upper is negative or equal to 0 (except Im1 and Im7 with themselves). Everything is significant.

```{r}
#Local Fit

std.loadings<- inspect(fit, what="std")$lambda
check=std.loadings
check[check>0] <- 1
std.loadings[std.loadings==0] <- NA
std.loadings2 <- std.loadings^2
std.theta<- inspect(fit, what="std")$theta

#Individual item Reliability
IIR=std.loadings2/(colSums(std.theta)+std.loadings2)
IIR
```

True score variance of the item divided by total variance and should be larger than 0.4. Except for Im11, all the coefficients are larger than 0.4! 

```{r}
#Composite/Construct Reliability
sum.std.loadings<-colSums(std.loadings, na.rm=TRUE)^2
sum.std.theta<-rowSums(std.theta)
sum.std.theta=check*sum.std.theta
CR=sum.std.loadings/(sum.std.loadings+colSums(sum.std.theta))
CR
```

Construct reliabilities are above 0.6 for all constructs (even higher than 0.79 here)!

```{r}
#Average Variance Extracted 
std.loadings<- inspect(fit, what="std")$lambda
std.loadings <- std.loadings^2
AVE=colSums(std.loadings)/(colSums(sum.std.theta)+colSums(std.loadings))
AVE
```

The AVE lies 0 and 1 and should be higher than 0.5. Here all the AVE are above 0.62!

### 1. What are the dimensions by which Galeries Lafayette is perceived?
Based on all of the above, the identified image dimensions of the Galeries Lafayette are the 8 dimensions (Decoration, France, Relaxation, Luxury, Assortment, Trend, Professionalism and Gourmet) and see that we have a model with a very good fit because all the global and local fit measures are respected!

The rationales have been provided with each step above.


### 2. Are the mechanism driving the two outcomes similar ? Are satisfaction and affective commitment mediating the impact of image perceptions on outcomes ? If yes for which outcomes?

First we create and run the causal model and will look at the output to interpret
the results to answer these questions.

```{r}
model2<-"

##Measurement model (capturing relationships between latent constructs and observed indicators)

  Decoration=~Im3+Im4+Im5
  France=~Im6+Im7
  Relaxation=~Im20+Im21+Im22
  Luxury=~Im11+Im12+Im13
  Assortment=~Im1+Im2
  Trend=~Im17+Im18
  Professionalism=~Im16+Im19
  Gourmet=~Im10+Im14

  Satisfaction = ~ SAT_1 + SAT_2 + SAT_3
  Commitment = ~ COM_A1 + COM_A2 + COM_A3 + COM_A4
  Repurchase = ~ C_REP1 + C_REP2 + C_REP3
  Cocreation = ~ C_CR1 + C_CR3 + C_CR4
  
##Structural model (capturing relationships between latent constructions)


  Repurchase ~ a * Satisfaction + b * Commitment
  Cocreation ~ c * Satisfaction + d * Commitment
  
  Satisfaction ~ e*Gourmet+f*Assortment+g*Decoration+h*Relaxation+i*Luxury+j*Trend+k*France+l*Professionalism
  Commitment ~ m*Gourmet+n*Assortment+o*Decoration+p*Relaxation+q*Luxury+r*Trend+s*France+t*Professionalism
  Cocreation ~ u*Gourmet+v*Assortment+w*Decoration+x*Relaxation+y*Luxury+z*Trend+aa*France+bb*Professionalism
  Repurchase ~ cc*Gourmet+dd*Assortment+ee*Decoration+ff*Relaxation+gg*Luxury+hh*Trend+ii*France+jj*Professionalism

##Indirect effects

  ae:=a*e
  af:=a*f
  ag:=a*g
  ah:=a*h
  ai:=a*i
  aj:=a*j
  ak:=a*k
  al:=a*l
  
  bm:=b*m
  bn:=b*n
  bo:=b*o
  bp:=b*p
  bq:=b*q
  br:=b*r
  bs:=b*s
  bt:=b*t
  
  ce:=c*e
  cf:=c*f
  cg:=c*g
  ch:=c*h
  ci:=c*i
  cj:=c*j
  ck:=c*k
  cl:=c*l
  
  dm:=d*m
  dn:=d*n
  do:=d*o
  dp:=d*p
  dq:=d*q
  dr:=d*r
  ds:=d*s
  dt:=d*t

##Total effects


  te1:=u+(c*e)+(d*m)
  te2:=v+(c*f)+(d*n)
  te3:=w+(c*g)+(d*o)
  te4:=x+(c*h)+(d*p)
  te5:=y+(c*i)+(d*q)
  te6:=z+(c*j)+(d*r)
  te7:=aa+(c*k)+(d*s)
  te8:=bb+(c*l)+(d*t)
  
  te9:=cc+(a*e)+(b*m)
  te10:=dd+(a*f)+(b*n)
  te11:=ee+(a*g)+(b*o)
  te12:=ff+(a*h)+(b*p)
  te13:=gg+(a*i)+(b*q)
  te14:=hh+(a*j)+(b*r)
  te15:=ii+(a*k)+(b*s)
  te16:=jj+(a*l)+(b*t)

##Total indirect effects

  tie1:=(c*e)+(d*m)
  tie2:=(c*f)+(d*n)
  tie3:=(c*g)+(d*o)
  tie4:=(c*h)+(d*p)
  tie5:=(c*i)+(d*q)
  tie6:=(c*j)+(d*r)
  tie7:=(c*k)+(d*s)
  tie8:=(c*l)+(d*t)
  
  tie9:=(a*e)+(b*m)
  tie10:=(a*f)+(b*n)
  tie11:=(a*g)+(b*o)
  tie12:=(a*h)+(b*p)
  tie13:=(a*i)+(b*q)
  tie14:=(a*j)+(b*r)
  tie15:=(a*k)+(b*s)
  tie16:=(a*l)+(b*t)
"

fit2 <- cfa(model2, data=data_new, missing="ML", estimator="MLR")
Sum_fit=summary(fit2, fit.measures=TRUE, standardized=TRUE)
```

```{r}
semPaths(fit2, nCharNodes = 0, style = "lisrel", rotation = 2)
```

Note that `te` stands for total effects and `tie` for total indirect effects.

Let's have a look at some coefficients/values to estimate the global fit measures.

1. First we look at the RMSEA value to see if it's lower or equal to 0.05 to be a good fit. 
(Hu & Bentler (1999) suggest a cut off value of 0.06 before one can conclude 
that there is a good fit between model and data.) Here, the RMSEA is 0.033 so we have a very good fit.

2. We can look at a ratio of the Model Test User Model, if (Test statistic /  Degrees of freedom) < 5, the fit is good. 
As noted from the lecture, ratio Chi2-value/df should be below 5 for samples up to 1000. 
Here, we note that we have 553 observation though.
In our case, the Chi-square test: 632.247/399 = 1.584579 => the fit is good. 

3. Regarding the User Model versus Baseline Model, if the Comparative Fit Index 
(CFI) is > 0.95, we accept the model. Here, the CFI is equal to 0.975, so we 
can accept our model. The Robust Comparative Fit Index (CFI) is even higher 0.977.

Our three global fit measures are very satisfactory!


### 2.1. Are the mechanism driving the 2 outcome similar? 


As can be seen in the `Regression` section of the output and by looking at the standardized coefficient column, the `Affective Commitment` and `Customer Satisfaction` (our 2 mediators) are highly significant to explain the Cocreation Intention (p-value of respectively 0.012 and 0.000).Affective Commitment has a positive impact (0.377) and Customer Satisfaction a negative impact (-0.190) . We could say the more the customer is satisfied, the less the customer would be willing to participate in the cocreation process. 

The `Affective Commitment` and `Customer Satisfaction` (our 2 mediators) are highly significant to explain the `Repurchase Intention` as well (p-value of respectively 0.000 and 0.000). `Affective Commitment` has a positive impact (0.354) and `Customer Satisfaction` a positive impact (0.318). We note that the impact is higher for the `Affective Commitment` than `Customer Satisfaction`.

So we would say that the mechanism driving the 2 outcomes aren't really similar, due to `Customer Satisfaction` negatively impacting the outcome `Cocreation Intention`, while the same mediator has a positive impact on the outcome `Repurchase Intention`

### 2.2. Are `Customer Satisfaction` and `Affective Commitment` mediating the impact of image perceptions on outcomes? If yes, for which each of them? 

We do this by look at whether the significant levels (via p-values) 
of all the modelled effects (direct and indirect) in the `Defined Parameters` section
of the output.

We can see that the following effects are statistically significant (p-value < 0.05). 

`af`, `ag`, `al`, `bp`, `bs`, `cf`, `cl`, `dp`, `ds`, `te4`, `te12`, `tie4`, `tie7`,
`tie10`, `tie12`, `tie15` and `tie16`.

We can see that for some of them, the p-value is extremely significant (p-value 
of 0.000 for `bp`, `dp`, `te4`, `te12`, `tie4` and `tie12`). 
We will describe only two significant coefficient for an illustration purpose.

For instance, `af` (with a positive coefficient of 0.029 with a p-value of 0.027) 
corresponds to a path `Assortment–> Customer Satisfaction –> Repurchase Intention`, we could say 
that more the customer is happy with the Assortment, the more the client would be 
satisfied and it would increase the likelihood of buying again at the Galeries Lafayette. 
We could say that `Customer Satisfaction` mediates the impact of `Assortment` on the 
`Repurchase Intention`. 

Second example, `cf` (with a negative coefficient of -0.048  with a p-value of 0.039) 
corresponds to a path `Assortment –> Customer Satisfaction –> Cocreation Intention`, 
we could say that more the customer is happy with the Assortment, the more the 
client would be satisfied and it would decrease the likelihood of participating again 
in cocreation activities at the Galeries Lafayette. We could say that 
`Customer Satisfaction` mediates the impact of `Assortment` on the `Cocreation Intentions`. 
Also the following paths are significant:

We could say that Customer Satisfaction mediates the impact of Decoration and Professionalism 
on the repurchase intention activities:

  `ag`: `Decoration –> Customer Satisfaction –> Repurchase Intention` <br>
  
  `al`: `Professionalism –> Customer Satisfaction –> Repurchase Intention` <br>

We could say that Affective Commitment mediates the impact of 
Relaxation and France on the repurchase intention activities:

  `bp`: `Relaxation –> Affective Commitment –> Repurchase Intention` <br>
  
  `bs`: `France –> Affective Commitment –> Repurchase Intention` <br>


We could say that Customer Satisfaction mediates the impact of 
Professionalism on the cocreation intention activities:

  `cl`: `Professionalism –> Customer Satisfaction –> Cocreation Intentions` <br>

We could say that Affective Commitment mediates the impact of Relaxation and France 
on the Cocreation intention activities:

  `dp`: `Relaxation –> Affective Commitment –> Cocreation Intentions` <br>
  
  `ds`: `France –> Affective Commitment –> Cocreation Intentions` <br>


Moreover, we can see that no Images from 1 to 22 have significant impact on our 2 outcomes (Cocreation Intention and Repurchase Intention).

<br>


### 3.1. What is driving the two distinct outcomes ? 

We already answered a bit to this question previously but we will try to develop a bit more.

If we understood the question correctly, we note that regarding the Cocreation Intention, we have the same amount of significant coefficients for Affective Commitment and Customer Satisfaction (respectively dp, ds and cf,cl). However, regarding the Repurchase Intention, we have the more significant coefficients for Customer Satisfaction than Affective Commitment (respectively af, ag, al and bp, bs).

However, as we previously said, with regards to Cocreation Intention, Affective Commitment has a positive impact (0.377 - looking at the standardized coefficient column) and Customer Satisfaction a negative impact (-0.190), the Galeries Lafayettes should mostly try to improve their Affective Commitment and not the Customer Satisfaction because it would be counter-productive.

Also as previously said, with regards to `Repurchase Intention`, Affective Commitment has a positive impact (0.354) and Customer Satisfaction also has a positive impact (0.318). We note that the impact is higher from Affective Commitment on Repurchase Intention than the impact of Customer Satisfaction on Repurchase Intention. The Galeries Lafayettes should try to improve both these mediators but with a bit more emphasis on Affective Commitment.

### 3.2. Which image dimensions have the largest total effect on each of them?

Effects on Repurchase Intention:

  - The total effect `te12`(:=ff+(a* h)+(b*p)) which correspond to the total effect of Relaxation on the Repurchase intention is highly significant (p-value of 0.000). The standardized coefficient  representing the total effect is 0.254.
  
    - The total indirect effect `tie10` :=(a * f)+(b*n) which correspond to the total indirect effect of Assortment on the Repurchase Intention is also highly significant (p-value of 0.000). The coefficient is 0.103.
    
    - The total indirect effect `tie12` :=(a * h)+(b*p) which correspond to the total indirect effect of Relaxation on the Repurchase Intention is also highly significant (p-value of 0.000). The coefficient is 0.169.

  
  - The total indirect effect `tie15` :=(a*k)+(b*s) which correspond to the total indirect effect of France on the Repurchase Intention is also significant (p-value of 0.000). The standardized coefficient is 0.104
  
  - The total indirect effect `tie16` :=(a* l)+(b*t) which correspond to the total indirect effect of Professionalism on the Repurchase Intention is also significant (p-value of 0.000). The standardized coefficient is 0.197.

Effects on Cocreation Intention:


  - The total effect `te4`:= x +(c* h)+(d*p) which correspond to the total effect of Relaxation on the Cocreation Intention is also highly significant (p-value of 0.000). The standardized coefficient is 0.256. 

- The total indirect effect `tie4` := (c* h)+(d*p) which correspond to the total indirect effect of Relaxation on the Cocreation Intention is also highly significant (p-value of 0.000). The standardized coefficient is 0.141.

- The total indirect effect `tie7` := (c* k)+(d*s) which correspond to the total indirect effect of France on the Cocreation Intention is also highly significant (p-value of 0.000). The standardized coefficient is  0.051.


Based on this, we see that:

- Regarding `Repurchase Intention`, image dimension `Relaxation` has the largest total effect.

- Regarding `Cocreation Intention`, image dimension `Relaxation` also has the largest total effect. 




