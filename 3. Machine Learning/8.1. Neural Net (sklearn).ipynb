{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e9f0c2",
   "metadata": {},
   "source": [
    "# Model 8.1: Neural Network (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b0f612",
   "metadata": {},
   "source": [
    "## Import the libraries and cleaning of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060b2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#plotting lib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#Sklearn Lib metrics\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# Pipelines : \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "#Missing values : \n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer, IterativeImputer, SimpleImputer\n",
    "import missingno as msno\n",
    "\n",
    "#Dummy\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn. preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad35d019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>occ_code_level2</th>\n",
       "      <th>age</th>\n",
       "      <th>stock_dividends</th>\n",
       "      <th>mig_chg_msa</th>\n",
       "      <th>tax_filer_stat</th>\n",
       "      <th>det_hh_summ</th>\n",
       "      <th>mig_prev_sunbelt</th>\n",
       "      <th>hisp_origin</th>\n",
       "      <th>education</th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>capital_losses</th>\n",
       "      <th>vet_question</th>\n",
       "      <th>own_or_self</th>\n",
       "      <th>country_self</th>\n",
       "      <th>mig_move_reg</th>\n",
       "      <th>high_income</th>\n",
       "      <th>hs_college</th>\n",
       "      <th>class_worker</th>\n",
       "      <th>mig_same</th>\n",
       "      <th>unemp_reason</th>\n",
       "      <th>state_prev_res</th>\n",
       "      <th>ind_code_level2</th>\n",
       "      <th>race</th>\n",
       "      <th>country_mother</th>\n",
       "      <th>capital_gains</th>\n",
       "      <th>sex</th>\n",
       "      <th>ind_code_level1</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>union_member</th>\n",
       "      <th>fam_under_18</th>\n",
       "      <th>marital_stat</th>\n",
       "      <th>region_prev_res</th>\n",
       "      <th>mig_chg_reg</th>\n",
       "      <th>country_father</th>\n",
       "      <th>occ_code_level1</th>\n",
       "      <th>full_or_part_emp</th>\n",
       "      <th>weeks_worked</th>\n",
       "      <th>det_hh_fam_stat</th>\n",
       "      <th>num_emp</th>\n",
       "      <th>vet_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nonfiler</td>\n",
       "      <td>Householder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All other</td>\n",
       "      <td>11th grade</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe under 1 year old</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>Black</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in labor force</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Householder</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Householder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All other</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Self-employed-incorporated</td>\n",
       "      <td>Not in universe under 1 year old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Wholesale trade</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Full-time schedules</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Householder</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joint both under 65</td>\n",
       "      <td>Householder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All other</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Private</td>\n",
       "      <td>Not in universe under 1 year old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hospital services</td>\n",
       "      <td>Foreign born- Not a citizen of U S</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>Adm support including clerical</td>\n",
       "      <td>Full-time schedules</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Householder</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MSA to MSA</td>\n",
       "      <td>Joint one under 65 &amp; one 65+</td>\n",
       "      <td>Householder</td>\n",
       "      <td>No</td>\n",
       "      <td>All other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Same county</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>0</td>\n",
       "      <td>Black</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Same county</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Children or Armed Forces</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Householder</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>Nonfiler</td>\n",
       "      <td>Child under 18 never married</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>All other</td>\n",
       "      <td>Children</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Mother only present</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Nonmover</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Children or Armed Forces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Child &lt;18 never marr not in subfamily</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  occ_code_level2   age  stock_dividends mig_chg_msa  \\\n",
       "0   1                0  42.0              0.0         NaN   \n",
       "1   2               18  56.0              NaN         NaN   \n",
       "2   3               26  26.0              NaN         NaN   \n",
       "3   4                0  67.0              NaN  MSA to MSA   \n",
       "4   5                0   NaN              NaN    Nonmover   \n",
       "\n",
       "                 tax_filer_stat                   det_hh_summ  \\\n",
       "0                      Nonfiler                   Householder   \n",
       "1                           NaN                   Householder   \n",
       "2           Joint both under 65                   Householder   \n",
       "3  Joint one under 65 & one 65+                   Householder   \n",
       "4                      Nonfiler  Child under 18 never married   \n",
       "\n",
       "  mig_prev_sunbelt hisp_origin             education  wage_per_hour  \\\n",
       "0              NaN   All other            11th grade            0.0   \n",
       "1              NaN   All other  High school graduate            0.0   \n",
       "2              NaN   All other  High school graduate            0.0   \n",
       "3               No   All other                   NaN            0.0   \n",
       "4  Not in universe   All other              Children            0.0   \n",
       "\n",
       "   capital_losses     vet_question  own_or_self   country_self mig_move_reg  \\\n",
       "0             NaN  Not in universe            0  United-States          NaN   \n",
       "1             NaN  Not in universe            2  United-States          NaN   \n",
       "2             NaN  Not in universe            0          Haiti          NaN   \n",
       "3             NaN               No            0  United-States  Same county   \n",
       "4             0.0  Not in universe            0  United-States     Nonmover   \n",
       "\n",
       "   high_income       hs_college                class_worker  \\\n",
       "0            0  Not in universe             Not in universe   \n",
       "1            1  Not in universe  Self-employed-incorporated   \n",
       "2            0  Not in universe                     Private   \n",
       "3            0  Not in universe             Not in universe   \n",
       "4            0  Not in universe             Not in universe   \n",
       "\n",
       "                           mig_same     unemp_reason   state_prev_res  \\\n",
       "0  Not in universe under 1 year old  Not in universe  Not in universe   \n",
       "1  Not in universe under 1 year old              NaN  Not in universe   \n",
       "2  Not in universe under 1 year old              NaN  Not in universe   \n",
       "3                                No              NaN   North Carolina   \n",
       "4                               Yes  Not in universe  Not in universe   \n",
       "\n",
       "   ind_code_level2   race country_mother  capital_gains     sex  \\\n",
       "0                0  Black  United-States            0.0  Female   \n",
       "1               32    NaN  United-States            NaN    Male   \n",
       "2               41    NaN          Haiti            NaN     NaN   \n",
       "3                0  Black  United-States            0.0     NaN   \n",
       "4                0  White  United-States            0.0  Female   \n",
       "\n",
       "               ind_code_level1                         citizenship  \\\n",
       "0  Not in universe or children   Native- Born in the United States   \n",
       "1              Wholesale trade   Native- Born in the United States   \n",
       "2            Hospital services  Foreign born- Not a citizen of U S   \n",
       "3  Not in universe or children   Native- Born in the United States   \n",
       "4  Not in universe or children   Native- Born in the United States   \n",
       "\n",
       "      union_member         fam_under_18                     marital_stat  \\\n",
       "0  Not in universe      Not in universe                              NaN   \n",
       "1  Not in universe      Not in universe  Married-civilian spouse present   \n",
       "2  Not in universe      Not in universe                              NaN   \n",
       "3  Not in universe      Not in universe                              NaN   \n",
       "4  Not in universe  Mother only present                              NaN   \n",
       "\n",
       "   region_prev_res  mig_chg_reg country_father  \\\n",
       "0  Not in universe          NaN  United-States   \n",
       "1  Not in universe          NaN  United-States   \n",
       "2  Not in universe          NaN          Haiti   \n",
       "3        Northeast  Same county  United-States   \n",
       "4  Not in universe     Nonmover  United-States   \n",
       "\n",
       "                  occ_code_level1          full_or_part_emp  weeks_worked  \\\n",
       "0                 Not in universe        Not in labor force           0.0   \n",
       "1                           Sales       Full-time schedules           NaN   \n",
       "2  Adm support including clerical       Full-time schedules           NaN   \n",
       "3                 Not in universe  Children or Armed Forces           0.0   \n",
       "4                 Not in universe  Children or Armed Forces           NaN   \n",
       "\n",
       "                         det_hh_fam_stat  num_emp  vet_benefits  \n",
       "0                            Householder        0             2  \n",
       "1                            Householder        1             2  \n",
       "2                            Householder        3             2  \n",
       "3                            Householder        0             1  \n",
       "4  Child <18 never marr not in subfamily        0             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"Data/train.csv\")\n",
    "test_df = pd.read_csv(\"Data/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99328b15",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#removing id for train_df\n",
    "train_df.drop(\"id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d25fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming object into categories \n",
    "# for train\n",
    "for i in train_df.columns:\n",
    "    if train_df[i].dtypes == \"object\":\n",
    "        train_df[i] = train_df[i].astype(\"category\")\n",
    "# For test\n",
    "for i in test_df.columns:\n",
    "    if test_df[i].dtypes == \"object\":\n",
    "        test_df[i] = test_df[i].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e0106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= train_df.drop(\"high_income\", axis = 1)\n",
    "y = train_df[\"high_income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96febce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping our features that are categories in one vector\n",
    "# Same for numeric\n",
    "\n",
    "categorical_features = [i for i in X.columns if X[i].dtype.name == \"category\"]\n",
    "numerical_features = [i for i in X.columns if X[i].dtype.name != \"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1d0f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer_num\", SimpleImputer(strategy=\"mean\")),\n",
    "           (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"imputer_cat\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
    "           \n",
    "           (\"encoder\" , OneHotEncoder(handle_unknown=\"ignore\", sparse=False))]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", MLPClassifier(random_state=1))]\n",
    ")\n",
    "\n",
    "\n",
    "# score = cross_val_score(clf, X, y, cv=KFold(n_splits=5, shuffle=True, random_state=1),scoring = \"accuracy\",n_jobs = -1, verbose=2).mean()\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4163b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max. 10 layers\n",
    "# 5-20 neurons\n",
    "# Best was (3, 6) - (8, 2) - (3, 2) with around 0.856\n",
    "# (3, 6, 4) with 0.857\n",
    "# (3, 2, 3) with 0.8576\n",
    "#Â (4, 3, 3) with 0.858\n",
    "# Try: 2 to 8 layers, 2 to 6 neurons each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e57a5f97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " (2, 7),\n",
       " (2, 8),\n",
       " (2, 9),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (3, 6),\n",
       " (3, 7),\n",
       " (3, 8),\n",
       " (3, 9),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (4, 4),\n",
       " (4, 5),\n",
       " (4, 6),\n",
       " (4, 7),\n",
       " (4, 8),\n",
       " (4, 9),\n",
       " (5, 2),\n",
       " (5, 3),\n",
       " (5, 4),\n",
       " (5, 5),\n",
       " (5, 6),\n",
       " (5, 7),\n",
       " (5, 8),\n",
       " (5, 9),\n",
       " (6, 2),\n",
       " (6, 3),\n",
       " (6, 4),\n",
       " (6, 5),\n",
       " (6, 6),\n",
       " (6, 7),\n",
       " (6, 8),\n",
       " (6, 9),\n",
       " (7, 2),\n",
       " (7, 3),\n",
       " (7, 4),\n",
       " (7, 5),\n",
       " (7, 6),\n",
       " (7, 7),\n",
       " (7, 8),\n",
       " (7, 9),\n",
       " (8, 2),\n",
       " (8, 3),\n",
       " (8, 4),\n",
       " (8, 5),\n",
       " (8, 6),\n",
       " (8, 7),\n",
       " (8, 8),\n",
       " (8, 9),\n",
       " (9, 2),\n",
       " (9, 3),\n",
       " (9, 4),\n",
       " (9, 5),\n",
       " (9, 6),\n",
       " (9, 7),\n",
       " (9, 8),\n",
       " (9, 9)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(3, 3, 3),\n",
       " (3, 3, 4),\n",
       " (3, 3, 5),\n",
       " (3, 3, 6),\n",
       " (3, 4, 3),\n",
       " (3, 4, 4),\n",
       " (3, 4, 5),\n",
       " (3, 4, 6),\n",
       " (3, 5, 3),\n",
       " (3, 5, 4),\n",
       " (3, 5, 5),\n",
       " (3, 5, 6),\n",
       " (3, 6, 3),\n",
       " (3, 6, 4),\n",
       " (3, 6, 5),\n",
       " (3, 6, 6),\n",
       " (4, 3, 3),\n",
       " (4, 3, 4),\n",
       " (4, 3, 5),\n",
       " (4, 3, 6),\n",
       " (4, 4, 3),\n",
       " (4, 4, 4),\n",
       " (4, 4, 5),\n",
       " (4, 4, 6),\n",
       " (4, 5, 3),\n",
       " (4, 5, 4),\n",
       " (4, 5, 5),\n",
       " (4, 5, 6),\n",
       " (4, 6, 3),\n",
       " (4, 6, 4),\n",
       " (4, 6, 5),\n",
       " (4, 6, 6),\n",
       " (5, 3, 3),\n",
       " (5, 3, 4),\n",
       " (5, 3, 5),\n",
       " (5, 3, 6),\n",
       " (5, 4, 3),\n",
       " (5, 4, 4),\n",
       " (5, 4, 5),\n",
       " (5, 4, 6),\n",
       " (5, 5, 3),\n",
       " (5, 5, 4),\n",
       " (5, 5, 5),\n",
       " (5, 5, 6),\n",
       " (5, 6, 3),\n",
       " (5, 6, 4),\n",
       " (5, 6, 5),\n",
       " (5, 6, 6),\n",
       " (6, 3, 3),\n",
       " (6, 3, 4),\n",
       " (6, 3, 5),\n",
       " (6, 3, 6),\n",
       " (6, 4, 3),\n",
       " (6, 4, 4),\n",
       " (6, 4, 5),\n",
       " (6, 4, 6),\n",
       " (6, 5, 3),\n",
       " (6, 5, 4),\n",
       " (6, 5, 5),\n",
       " (6, 5, 6),\n",
       " (6, 6, 3),\n",
       " (6, 6, 4),\n",
       " (6, 6, 5),\n",
       " (6, 6, 6)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the list of all combinations of layers/neurons for the GridSearch\n",
    "# \n",
    "list_combinations_layers_2 = []\n",
    "list_combinations_layers_3 = []\n",
    "\n",
    "# 2 layers\n",
    "for i in np.arange(2, 10):\n",
    "    for j in np.arange(2, 10):\n",
    "        list_combinations_layers_2.append((i, j))\n",
    "\n",
    "# 3 layers\n",
    "for i in np.arange(3, 5):\n",
    "    for j in np.arange(2, 5):\n",
    "        for k in np.arange(2, 5):\n",
    "            list_combinations_layers_3.append((i, j, k))        \n",
    "        \n",
    "display(list_combinations_layers_2)\n",
    "display(list_combinations_layers_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d6679",
   "metadata": {},
   "source": [
    "## For 2 Layers Only: First Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6abfabee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__hidden_layer_sizes': [(2, 2),\n",
       "  (2, 3),\n",
       "  (2, 4),\n",
       "  (2, 5),\n",
       "  (2, 6),\n",
       "  (2, 7),\n",
       "  (2, 8),\n",
       "  (2, 9),\n",
       "  (3, 2),\n",
       "  (3, 3),\n",
       "  (3, 4),\n",
       "  (3, 5),\n",
       "  (3, 6),\n",
       "  (3, 7),\n",
       "  (3, 8),\n",
       "  (3, 9),\n",
       "  (4, 2),\n",
       "  (4, 3),\n",
       "  (4, 4),\n",
       "  (4, 5),\n",
       "  (4, 6),\n",
       "  (4, 7),\n",
       "  (4, 8),\n",
       "  (4, 9),\n",
       "  (5, 2),\n",
       "  (5, 3),\n",
       "  (5, 4),\n",
       "  (5, 5),\n",
       "  (5, 6),\n",
       "  (5, 7),\n",
       "  (5, 8),\n",
       "  (5, 9),\n",
       "  (6, 2),\n",
       "  (6, 3),\n",
       "  (6, 4),\n",
       "  (6, 5),\n",
       "  (6, 6),\n",
       "  (6, 7),\n",
       "  (6, 8),\n",
       "  (6, 9),\n",
       "  (7, 2),\n",
       "  (7, 3),\n",
       "  (7, 4),\n",
       "  (7, 5),\n",
       "  (7, 6),\n",
       "  (7, 7),\n",
       "  (7, 8),\n",
       "  (7, 9),\n",
       "  (8, 2),\n",
       "  (8, 3),\n",
       "  (8, 4),\n",
       "  (8, 5),\n",
       "  (8, 6),\n",
       "  (8, 7),\n",
       "  (8, 8),\n",
       "  (8, 9),\n",
       "  (9, 2),\n",
       "  (9, 3),\n",
       "  (9, 4),\n",
       "  (9, 5),\n",
       "  (9, 6),\n",
       "  (9, 7),\n",
       "  (9, 8),\n",
       "  (9, 9)],\n",
       " 'classifier__activation': ['relu'],\n",
       " 'classifier__solver': ['adam'],\n",
       " 'classifier__alpha': [0.05, 0.07],\n",
       " 'classifier__learning_rate': ['adaptive'],\n",
       " 'classifier__max_iter': [500]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param_2 = {\n",
    "    \"classifier__hidden_layer_sizes\": list_combinations_layers_2, \n",
    "              \"classifier__activation\": ['relu'],\n",
    "              \"classifier__solver\": ['adam'],\n",
    "              \"classifier__alpha\": [0.07],\n",
    "              \"classifier__learning_rate\": ['adaptive'],\n",
    "              \"classifier__max_iter\": [500],\n",
    "}\n",
    "\n",
    "hyper_param_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d68070da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_grid_search_2_cv = GridSearchCV(estimator = clf, param_grid=hyper_param_2, scoring=\"accuracy\",\n",
    "                           cv = KFold(n_splits=5, shuffle=True, random_state=1), n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b681ac1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['occ_code_level2',\n",
       "                                                                          'age',\n",
       "                                                                          'stock_dividends',\n",
       "                                                                          'wage_per_hour',\n",
       "                                                                          'capital_losses',\n",
       "                                                                          'own_or_self',\n",
       "                                                                          'ind_code_level2',\n",
       "                                                                          'capital_gains',\n",
       "                                                                          'week...\n",
       "                         'classifier__alpha': [0.05, 0.07],\n",
       "                         'classifier__hidden_layer_sizes': [(2, 2), (2, 3),\n",
       "                                                            (2, 4), (2, 5),\n",
       "                                                            (2, 6), (2, 7),\n",
       "                                                            (2, 8), (2, 9),\n",
       "                                                            (3, 2), (3, 3),\n",
       "                                                            (3, 4), (3, 5),\n",
       "                                                            (3, 6), (3, 7),\n",
       "                                                            (3, 8), (3, 9),\n",
       "                                                            (4, 2), (4, 3),\n",
       "                                                            (4, 4), (4, 5),\n",
       "                                                            (4, 6), (4, 7),\n",
       "                                                            (4, 8), (4, 9),\n",
       "                                                            (5, 2), (5, 3),\n",
       "                                                            (5, 4), (5, 5),\n",
       "                                                            (5, 6), (5, 7), ...],\n",
       "                         'classifier__learning_rate': ['adaptive'],\n",
       "                         'classifier__max_iter': [500],\n",
       "                         'classifier__solver': ['adam']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search_2_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53300715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__activation</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__hidden_layer_sizes</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>23.356496</td>\n",
       "      <td>4.379460</td>\n",
       "      <td>0.114901</td>\n",
       "      <td>0.036194</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864311</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.861093</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.861117</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>24.245143</td>\n",
       "      <td>2.764926</td>\n",
       "      <td>0.089091</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863853</td>\n",
       "      <td>0.865318</td>\n",
       "      <td>0.856973</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.860879</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>14.458806</td>\n",
       "      <td>2.865559</td>\n",
       "      <td>0.087635</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.862113</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.860635</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.860659</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>24.330876</td>\n",
       "      <td>6.371064</td>\n",
       "      <td>0.089167</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.864402</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.860586</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>19.456142</td>\n",
       "      <td>6.487702</td>\n",
       "      <td>0.082803</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>24.369640</td>\n",
       "      <td>3.331783</td>\n",
       "      <td>0.098046</td>\n",
       "      <td>0.013520</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.864585</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.860366</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>18.753976</td>\n",
       "      <td>4.657214</td>\n",
       "      <td>0.087550</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.860256</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>19.502033</td>\n",
       "      <td>5.313578</td>\n",
       "      <td>0.088530</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.861093</td>\n",
       "      <td>0.860256</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>23.323514</td>\n",
       "      <td>6.193535</td>\n",
       "      <td>0.091468</td>\n",
       "      <td>0.013306</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.865318</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.860256</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>24.981552</td>\n",
       "      <td>2.707485</td>\n",
       "      <td>0.088823</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865409</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.860238</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16.846170</td>\n",
       "      <td>3.305417</td>\n",
       "      <td>0.095248</td>\n",
       "      <td>0.011361</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.860219</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18.235730</td>\n",
       "      <td>3.835911</td>\n",
       "      <td>0.088552</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864677</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.860201</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>18.533593</td>\n",
       "      <td>3.900801</td>\n",
       "      <td>0.083235</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863670</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.856973</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.860183</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>19.451309</td>\n",
       "      <td>4.146196</td>\n",
       "      <td>0.093091</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.861381</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.860128</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>20.093515</td>\n",
       "      <td>4.633449</td>\n",
       "      <td>0.091102</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.864585</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.860109</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>21.912961</td>\n",
       "      <td>2.561337</td>\n",
       "      <td>0.085317</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.860269</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.860091</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>19.829117</td>\n",
       "      <td>3.877292</td>\n",
       "      <td>0.092727</td>\n",
       "      <td>0.010251</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863761</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.860036</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>18.248815</td>\n",
       "      <td>3.030102</td>\n",
       "      <td>0.089404</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865501</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.860036</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>13.562570</td>\n",
       "      <td>3.508403</td>\n",
       "      <td>0.084096</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862937</td>\n",
       "      <td>0.859458</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.861826</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>21.928531</td>\n",
       "      <td>5.048645</td>\n",
       "      <td>0.081159</td>\n",
       "      <td>0.007413</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.864494</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>18.576591</td>\n",
       "      <td>2.875667</td>\n",
       "      <td>0.094912</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(6, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.859981</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>20.262663</td>\n",
       "      <td>6.114873</td>\n",
       "      <td>0.085345</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860740</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.859926</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.593160</td>\n",
       "      <td>2.143276</td>\n",
       "      <td>0.083728</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.859926</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>22.458758</td>\n",
       "      <td>2.530923</td>\n",
       "      <td>0.089144</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863761</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.854867</td>\n",
       "      <td>0.861276</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.859908</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>19.879278</td>\n",
       "      <td>4.069450</td>\n",
       "      <td>0.088623</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.859835</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>26.843425</td>\n",
       "      <td>4.763704</td>\n",
       "      <td>0.092107</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.859816</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>15.999311</td>\n",
       "      <td>1.162132</td>\n",
       "      <td>0.089858</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864036</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.859816</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>16.779008</td>\n",
       "      <td>4.032774</td>\n",
       "      <td>0.094495</td>\n",
       "      <td>0.011326</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.859798</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>18.901944</td>\n",
       "      <td>3.475905</td>\n",
       "      <td>0.089876</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865409</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.854226</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.859798</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>25.115048</td>\n",
       "      <td>3.281830</td>\n",
       "      <td>0.083051</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.860910</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.859762</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>22.904518</td>\n",
       "      <td>6.335308</td>\n",
       "      <td>0.092516</td>\n",
       "      <td>0.010138</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863303</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.859762</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>20.796835</td>\n",
       "      <td>4.939724</td>\n",
       "      <td>0.094847</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(6, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865135</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.854317</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.859725</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>18.351928</td>\n",
       "      <td>1.936782</td>\n",
       "      <td>0.070901</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.859725</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>16.199807</td>\n",
       "      <td>3.962967</td>\n",
       "      <td>0.095125</td>\n",
       "      <td>0.009929</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.860648</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.859688</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21.093216</td>\n",
       "      <td>3.855341</td>\n",
       "      <td>0.093875</td>\n",
       "      <td>0.006808</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.859597</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>24.927282</td>\n",
       "      <td>3.113208</td>\n",
       "      <td>0.102255</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.856894</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.860086</td>\n",
       "      <td>0.862009</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>18.738102</td>\n",
       "      <td>3.316193</td>\n",
       "      <td>0.096021</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862846</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.859523</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.081574</td>\n",
       "      <td>2.065070</td>\n",
       "      <td>0.088562</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.859523</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>20.941391</td>\n",
       "      <td>4.361755</td>\n",
       "      <td>0.075953</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(6, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864677</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.859523</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>21.050755</td>\n",
       "      <td>5.400555</td>\n",
       "      <td>0.089162</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865409</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.859505</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>21.098545</td>\n",
       "      <td>3.139012</td>\n",
       "      <td>0.095259</td>\n",
       "      <td>0.016864</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>0.859487</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>26.392401</td>\n",
       "      <td>3.455138</td>\n",
       "      <td>0.099186</td>\n",
       "      <td>0.019439</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.860923</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.859432</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.035852</td>\n",
       "      <td>0.518350</td>\n",
       "      <td>0.085610</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.861198</td>\n",
       "      <td>0.860819</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.859395</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>30.856700</td>\n",
       "      <td>4.649344</td>\n",
       "      <td>0.089956</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.854867</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.859359</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>28.382160</td>\n",
       "      <td>2.758505</td>\n",
       "      <td>0.084398</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.864494</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.859359</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>21.418168</td>\n",
       "      <td>3.813806</td>\n",
       "      <td>0.085177</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.859641</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>0.859322</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>13.834078</td>\n",
       "      <td>3.839286</td>\n",
       "      <td>0.083284</td>\n",
       "      <td>0.015225</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.861381</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.859322</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>23.355677</td>\n",
       "      <td>2.828481</td>\n",
       "      <td>0.107736</td>\n",
       "      <td>0.026220</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.859285</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>21.115594</td>\n",
       "      <td>2.914914</td>\n",
       "      <td>0.091681</td>\n",
       "      <td>0.014088</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(6, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864219</td>\n",
       "      <td>0.862846</td>\n",
       "      <td>0.853768</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.859267</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.448398</td>\n",
       "      <td>1.652601</td>\n",
       "      <td>0.079962</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.859194</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>19.779092</td>\n",
       "      <td>1.405830</td>\n",
       "      <td>0.097216</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.859139</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>22.384201</td>\n",
       "      <td>4.118059</td>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.007135</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864311</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.855325</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.859139</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>24.711107</td>\n",
       "      <td>7.055306</td>\n",
       "      <td>0.083798</td>\n",
       "      <td>0.010464</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860923</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.859102</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>19.984539</td>\n",
       "      <td>5.326911</td>\n",
       "      <td>0.093038</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863120</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.853127</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.859047</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>22.232496</td>\n",
       "      <td>6.283568</td>\n",
       "      <td>0.089215</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.860557</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.860086</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.859011</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>28.031139</td>\n",
       "      <td>1.863052</td>\n",
       "      <td>0.092708</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860374</td>\n",
       "      <td>0.863120</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.859011</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20.976715</td>\n",
       "      <td>4.615848</td>\n",
       "      <td>0.096708</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862937</td>\n",
       "      <td>0.857993</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>11.586057</td>\n",
       "      <td>1.054266</td>\n",
       "      <td>0.091336</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>23.154912</td>\n",
       "      <td>2.786340</td>\n",
       "      <td>0.085001</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.857993</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.858956</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>17.676678</td>\n",
       "      <td>4.428709</td>\n",
       "      <td>0.085428</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(6, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.859183</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.858956</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>16.662240</td>\n",
       "      <td>4.462267</td>\n",
       "      <td>0.094432</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.854867</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.858956</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.935230</td>\n",
       "      <td>2.921066</td>\n",
       "      <td>0.096542</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.860086</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.858919</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>13.225083</td>\n",
       "      <td>2.422956</td>\n",
       "      <td>0.091662</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.859824</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.858864</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>24.845441</td>\n",
       "      <td>4.091600</td>\n",
       "      <td>0.091589</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>0.855325</td>\n",
       "      <td>0.858827</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>19.443914</td>\n",
       "      <td>8.321630</td>\n",
       "      <td>0.092415</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860740</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.853951</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.860086</td>\n",
       "      <td>0.858791</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>11.905120</td>\n",
       "      <td>4.661249</td>\n",
       "      <td>0.089492</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.861838</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.858791</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>23.860224</td>\n",
       "      <td>6.317284</td>\n",
       "      <td>0.084833</td>\n",
       "      <td>0.006526</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.860635</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.858773</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>24.575471</td>\n",
       "      <td>9.752947</td>\n",
       "      <td>0.089716</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.858736</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>18.503736</td>\n",
       "      <td>3.133952</td>\n",
       "      <td>0.094628</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.858718</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20.688080</td>\n",
       "      <td>2.980279</td>\n",
       "      <td>0.088739</td>\n",
       "      <td>0.011077</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862937</td>\n",
       "      <td>0.858909</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.858718</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>19.109399</td>\n",
       "      <td>4.521230</td>\n",
       "      <td>0.077373</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>0.854775</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.858681</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>27.048116</td>\n",
       "      <td>4.947624</td>\n",
       "      <td>0.098480</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.858663</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>26.027098</td>\n",
       "      <td>4.663209</td>\n",
       "      <td>0.091206</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.857169</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.858644</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>19.534136</td>\n",
       "      <td>2.110801</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.860923</td>\n",
       "      <td>0.854043</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.858644</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>20.866142</td>\n",
       "      <td>4.932779</td>\n",
       "      <td>0.100611</td>\n",
       "      <td>0.014895</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(6, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.860831</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.858608</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>11.434500</td>\n",
       "      <td>3.435288</td>\n",
       "      <td>0.084718</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859641</td>\n",
       "      <td>0.858085</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>21.773412</td>\n",
       "      <td>3.052769</td>\n",
       "      <td>0.086599</td>\n",
       "      <td>0.007201</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.858085</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.860269</td>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>13.529856</td>\n",
       "      <td>4.362162</td>\n",
       "      <td>0.086507</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.338431</td>\n",
       "      <td>5.769616</td>\n",
       "      <td>0.095264</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.858542</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.858535</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>31.504917</td>\n",
       "      <td>5.018081</td>\n",
       "      <td>0.105525</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.856711</td>\n",
       "      <td>0.854958</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.858480</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>21.876034</td>\n",
       "      <td>3.688202</td>\n",
       "      <td>0.088996</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(6, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.857444</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.858461</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>13.814645</td>\n",
       "      <td>4.970910</td>\n",
       "      <td>0.087784</td>\n",
       "      <td>0.008890</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860099</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>22.946612</td>\n",
       "      <td>2.895767</td>\n",
       "      <td>0.091885</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.860831</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.858406</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19.890677</td>\n",
       "      <td>3.803803</td>\n",
       "      <td>0.089629</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858634</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.858370</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>25.206811</td>\n",
       "      <td>2.677204</td>\n",
       "      <td>0.091150</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861198</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.853768</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.858351</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>23.740871</td>\n",
       "      <td>5.431804</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.010629</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.860374</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.858315</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>16.997145</td>\n",
       "      <td>1.800651</td>\n",
       "      <td>0.087165</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.858909</td>\n",
       "      <td>0.853310</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.858315</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.976112</td>\n",
       "      <td>3.383908</td>\n",
       "      <td>0.097311</td>\n",
       "      <td>0.019835</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860831</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.854775</td>\n",
       "      <td>0.858296</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>14.932330</td>\n",
       "      <td>0.838145</td>\n",
       "      <td>0.094289</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862846</td>\n",
       "      <td>0.858726</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.858260</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.126337</td>\n",
       "      <td>1.605055</td>\n",
       "      <td>0.099034</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861198</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.858150</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>18.620349</td>\n",
       "      <td>3.537997</td>\n",
       "      <td>0.090933</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.860099</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.858132</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.167171</td>\n",
       "      <td>5.417250</td>\n",
       "      <td>0.093179</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.858095</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>20.643500</td>\n",
       "      <td>4.726852</td>\n",
       "      <td>0.093361</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.857535</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.858058</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.057545</td>\n",
       "      <td>6.116418</td>\n",
       "      <td>0.102890</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.856437</td>\n",
       "      <td>0.858909</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.858022</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.797087</td>\n",
       "      <td>4.684627</td>\n",
       "      <td>0.082357</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859458</td>\n",
       "      <td>0.857993</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.860178</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.857894</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>23.164682</td>\n",
       "      <td>2.226155</td>\n",
       "      <td>0.097663</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.858176</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.857894</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14.885205</td>\n",
       "      <td>1.859156</td>\n",
       "      <td>0.083662</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859824</td>\n",
       "      <td>0.858634</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.857839</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>25.911052</td>\n",
       "      <td>2.646540</td>\n",
       "      <td>0.093605</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860740</td>\n",
       "      <td>0.854605</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.860635</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>28.348121</td>\n",
       "      <td>1.814676</td>\n",
       "      <td>0.097402</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861381</td>\n",
       "      <td>0.859183</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.854134</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16.508564</td>\n",
       "      <td>2.265444</td>\n",
       "      <td>0.089994</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862937</td>\n",
       "      <td>0.860831</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.852486</td>\n",
       "      <td>0.857765</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>18.958596</td>\n",
       "      <td>6.178921</td>\n",
       "      <td>0.087513</td>\n",
       "      <td>0.008538</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.858451</td>\n",
       "      <td>0.852944</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.956592</td>\n",
       "      <td>4.981025</td>\n",
       "      <td>0.089549</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863120</td>\n",
       "      <td>0.858542</td>\n",
       "      <td>0.854958</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.855050</td>\n",
       "      <td>0.857655</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>19.712139</td>\n",
       "      <td>2.643788</td>\n",
       "      <td>0.088244</td>\n",
       "      <td>0.005653</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858176</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.854501</td>\n",
       "      <td>0.857564</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>13.394450</td>\n",
       "      <td>2.542402</td>\n",
       "      <td>0.085757</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859000</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.854409</td>\n",
       "      <td>0.857546</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.018156</td>\n",
       "      <td>3.656008</td>\n",
       "      <td>0.097047</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858634</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.856973</td>\n",
       "      <td>0.857454</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>9.530806</td>\n",
       "      <td>1.821335</td>\n",
       "      <td>0.083965</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860557</td>\n",
       "      <td>0.858634</td>\n",
       "      <td>0.852852</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>0.857436</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>13.436330</td>\n",
       "      <td>2.183852</td>\n",
       "      <td>0.079802</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.856973</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.854592</td>\n",
       "      <td>0.857326</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.368456</td>\n",
       "      <td>3.369664</td>\n",
       "      <td>0.091403</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861381</td>\n",
       "      <td>0.857901</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.854958</td>\n",
       "      <td>0.857326</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.371075</td>\n",
       "      <td>3.273680</td>\n",
       "      <td>0.127188</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859092</td>\n",
       "      <td>0.856986</td>\n",
       "      <td>0.854592</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.857179</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.170033</td>\n",
       "      <td>2.307139</td>\n",
       "      <td>0.084885</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859916</td>\n",
       "      <td>0.858817</td>\n",
       "      <td>0.854226</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.857161</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>12.789743</td>\n",
       "      <td>2.598324</td>\n",
       "      <td>0.084992</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.860099</td>\n",
       "      <td>0.852852</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.857106</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.987947</td>\n",
       "      <td>2.750742</td>\n",
       "      <td>0.086293</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.857444</td>\n",
       "      <td>0.853768</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.853768</td>\n",
       "      <td>0.857088</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>11.225041</td>\n",
       "      <td>3.120304</td>\n",
       "      <td>0.084912</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.857261</td>\n",
       "      <td>0.853219</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.854226</td>\n",
       "      <td>0.857033</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.697493</td>\n",
       "      <td>2.763572</td>\n",
       "      <td>0.102558</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859092</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.852578</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>0.856996</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>14.001033</td>\n",
       "      <td>1.698254</td>\n",
       "      <td>0.098019</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.859000</td>\n",
       "      <td>0.853860</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>0.853310</td>\n",
       "      <td>0.856886</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.864673</td>\n",
       "      <td>3.416859</td>\n",
       "      <td>0.161675</td>\n",
       "      <td>0.072331</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860374</td>\n",
       "      <td>0.857901</td>\n",
       "      <td>0.853219</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.854043</td>\n",
       "      <td>0.856850</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>18.032323</td>\n",
       "      <td>6.333455</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.859641</td>\n",
       "      <td>0.854226</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.856831</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.676230</td>\n",
       "      <td>2.633184</td>\n",
       "      <td>0.086308</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.858451</td>\n",
       "      <td>0.855050</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.853860</td>\n",
       "      <td>0.856722</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>16.115235</td>\n",
       "      <td>3.211210</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858817</td>\n",
       "      <td>0.856986</td>\n",
       "      <td>0.854043</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.855050</td>\n",
       "      <td>0.856685</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>13.836911</td>\n",
       "      <td>1.864469</td>\n",
       "      <td>0.094124</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859458</td>\n",
       "      <td>0.857810</td>\n",
       "      <td>0.854775</td>\n",
       "      <td>0.854409</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.856410</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.585507</td>\n",
       "      <td>6.008313</td>\n",
       "      <td>0.085438</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858634</td>\n",
       "      <td>0.857901</td>\n",
       "      <td>0.852394</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.853493</td>\n",
       "      <td>0.856374</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.600848</td>\n",
       "      <td>2.361564</td>\n",
       "      <td>0.109238</td>\n",
       "      <td>0.025141</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.857810</td>\n",
       "      <td>0.859092</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.854226</td>\n",
       "      <td>0.856062</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>11.370613</td>\n",
       "      <td>4.646482</td>\n",
       "      <td>0.084973</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858634</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.851570</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.853219</td>\n",
       "      <td>0.855550</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>11.388639</td>\n",
       "      <td>3.583290</td>\n",
       "      <td>0.084154</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858817</td>\n",
       "      <td>0.857993</td>\n",
       "      <td>0.852394</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.851479</td>\n",
       "      <td>0.855458</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.476600</td>\n",
       "      <td>8.170997</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858542</td>\n",
       "      <td>0.860923</td>\n",
       "      <td>0.854867</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.696456</td>\n",
       "      <td>0.825497</td>\n",
       "      <td>0.064552</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>10.966549</td>\n",
       "      <td>4.023865</td>\n",
       "      <td>0.095186</td>\n",
       "      <td>0.022113</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859824</td>\n",
       "      <td>0.857352</td>\n",
       "      <td>0.852944</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.696456</td>\n",
       "      <td>0.824728</td>\n",
       "      <td>0.064174</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.734260</td>\n",
       "      <td>6.126808</td>\n",
       "      <td>0.095712</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.689251</td>\n",
       "      <td>0.689526</td>\n",
       "      <td>0.696548</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.724872</td>\n",
       "      <td>0.066698</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5.187360</td>\n",
       "      <td>5.182668</td>\n",
       "      <td>0.097177</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.689251</td>\n",
       "      <td>0.689526</td>\n",
       "      <td>0.696548</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.724762</td>\n",
       "      <td>0.066478</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "124      23.356496      4.379460         0.114901        0.036194   \n",
       "115      24.245143      2.764926         0.089091        0.007372   \n",
       "85       14.458806      2.865559         0.087635        0.008237   \n",
       "117      24.330876      6.371064         0.089167        0.009662   \n",
       "98       19.456142      6.487702         0.082803        0.005630   \n",
       "51       24.369640      3.331783         0.098046        0.013520   \n",
       "112      18.753976      4.657214         0.087550        0.009357   \n",
       "90       19.502033      5.313578         0.088530        0.005282   \n",
       "120      23.323514      6.193535         0.091468        0.013306   \n",
       "42       24.981552      2.707485         0.088823        0.014187   \n",
       "21       16.846170      3.305417         0.095248        0.011361   \n",
       "26       18.235730      3.835911         0.088552        0.011256   \n",
       "106      18.533593      3.900801         0.083235        0.009641   \n",
       "31       19.451309      4.146196         0.093091        0.017040   \n",
       "123      20.093515      4.633449         0.091102        0.008010   \n",
       "48       21.912961      2.561337         0.085317        0.005417   \n",
       "34       19.829117      3.877292         0.092727        0.010251   \n",
       "119      18.248815      3.030102         0.089404        0.004534   \n",
       "82       13.562570      3.508403         0.084096        0.011465   \n",
       "107      21.928531      5.048645         0.081159        0.007413   \n",
       "99       18.576591      2.875667         0.094912        0.003562   \n",
       "94       20.262663      6.114873         0.085345        0.013247   \n",
       "18       15.593160      2.143276         0.083728        0.008428   \n",
       "54       22.458758      2.530923         0.089144        0.013727   \n",
       "43       19.879278      4.069450         0.088623        0.009405   \n",
       "113      26.843425      4.763704         0.092107        0.010098   \n",
       "86       15.999311      1.162132         0.089858        0.006315   \n",
       "55       16.779008      4.032774         0.094495        0.011326   \n",
       "116      18.901944      3.475905         0.089876        0.009195   \n",
       "108      25.115048      3.281830         0.083051        0.003918   \n",
       "35       22.904518      6.335308         0.092516        0.010138   \n",
       "97       20.796835      4.939724         0.094847        0.009328   \n",
       "127      18.351928      1.936782         0.070901        0.002553   \n",
       "95       16.199807      3.962967         0.095125        0.009929   \n",
       "109      21.093216      3.855341         0.093875        0.006808   \n",
       "50       24.927282      3.113208         0.102255        0.012050   \n",
       "52       18.738102      3.316193         0.096021        0.009521   \n",
       "29       17.081574      2.065070         0.088562        0.013822   \n",
       "102      20.941391      4.361755         0.075953        0.002424   \n",
       "33       21.050755      5.400555         0.089162        0.002543   \n",
       "111      21.098545      3.139012         0.095259        0.016864   \n",
       "47       26.392401      3.455138         0.099186        0.019439   \n",
       "20       13.035852      0.518350         0.085610        0.008411   \n",
       "121      30.856700      4.649344         0.089956        0.003383   \n",
       "122      28.382160      2.758505         0.084398        0.003864   \n",
       "32       21.418168      3.813806         0.085177        0.007815   \n",
       "87       13.834078      3.839286         0.083284        0.015225   \n",
       "53       23.355677      2.828481         0.107736        0.026220   \n",
       "101      21.115594      2.914914         0.091681        0.014088   \n",
       "23       14.448398      1.652601         0.079962        0.004993   \n",
       "62       19.779092      1.405830         0.097216        0.006495   \n",
       "39       22.384201      4.118059         0.088131        0.007135   \n",
       "104      24.711107      7.055306         0.083798        0.010464   \n",
       "45       19.984539      5.326911         0.093038        0.002377   \n",
       "118      22.232496      6.283568         0.089215        0.004443   \n",
       "125      28.031139      1.863052         0.092708        0.013343   \n",
       "37       20.976715      4.615848         0.096708        0.008581   \n",
       "84       11.586057      1.054266         0.091336        0.011753   \n",
       "114      23.154912      2.786340         0.085001        0.009412   \n",
       "96       17.676678      4.428709         0.085428        0.006981   \n",
       "79       16.662240      4.462267         0.094432        0.012341   \n",
       "8        17.935230      2.921066         0.096542        0.007304   \n",
       "89       13.225083      2.422956         0.091662        0.011553   \n",
       "46       24.845441      4.091600         0.091589        0.005660   \n",
       "105      19.443914      8.321630         0.092415        0.005342   \n",
       "81       11.905120      4.661249         0.089492        0.009280   \n",
       "110      23.860224      6.317284         0.084833        0.006526   \n",
       "40       24.575471      9.752947         0.089716        0.010037   \n",
       "93       18.503736      3.133952         0.094628        0.013736   \n",
       "38       20.688080      2.980279         0.088739        0.011077   \n",
       "92       19.109399      4.521230         0.077373        0.002407   \n",
       "61       27.048116      4.947624         0.098480        0.006999   \n",
       "60       26.027098      4.663209         0.091206        0.002665   \n",
       "30       19.534136      2.110801         0.078597        0.007077   \n",
       "103      20.866142      4.932779         0.100611        0.014895   \n",
       "73       11.434500      3.435288         0.084718        0.001693   \n",
       "91       21.773412      3.052769         0.086599        0.007201   \n",
       "75       13.529856      4.362162         0.086507        0.003475   \n",
       "11       13.338431      5.769616         0.095264        0.006046   \n",
       "49       31.504917      5.018081         0.105525        0.021488   \n",
       "100      21.876034      3.688202         0.088996        0.014674   \n",
       "83       13.814645      4.970910         0.087784        0.008890   \n",
       "58       22.946612      2.895767         0.091885        0.004340   \n",
       "27       19.890677      3.803803         0.089629        0.008892   \n",
       "63       25.206811      2.677204         0.091150        0.004792   \n",
       "36       23.740871      5.431804         0.085152        0.010629   \n",
       "72       16.997145      1.800651         0.087165        0.003026   \n",
       "13       18.976112      3.383908         0.097311        0.019835   \n",
       "80       14.932330      0.838145         0.094289        0.009205   \n",
       "15       15.126337      1.605055         0.099034        0.008711   \n",
       "126      18.620349      3.537997         0.090933        0.008732   \n",
       "17       14.167171      5.417250         0.093179        0.010288   \n",
       "59       20.643500      4.726852         0.093361        0.003891   \n",
       "19       18.057545      6.116418         0.102890        0.027800   \n",
       "9        13.797087      4.684627         0.082357        0.007289   \n",
       "56       23.164682      2.226155         0.097663        0.011995   \n",
       "25       14.885205      1.859156         0.083662        0.006705   \n",
       "44       25.911052      2.646540         0.093605        0.013108   \n",
       "57       28.348121      1.814676         0.097402        0.006410   \n",
       "22       16.508564      2.265444         0.089994        0.007085   \n",
       "41       18.958596      6.178921         0.087513        0.008538   \n",
       "16       15.956592      4.981025         0.089549        0.006014   \n",
       "28       19.712139      2.643788         0.088244        0.005653   \n",
       "77       13.394450      2.542402         0.085757        0.001944   \n",
       "12       19.018156      3.656008         0.097047        0.009740   \n",
       "66        9.530806      1.821335         0.083965        0.000379   \n",
       "67       13.436330      2.183852         0.079802        0.004899   \n",
       "14       15.368456      3.369664         0.091403        0.013795   \n",
       "1        15.371075      3.273680         0.127188        0.020750   \n",
       "6        14.170033      2.307139         0.084885        0.006708   \n",
       "74       12.789743      2.598324         0.084992        0.000945   \n",
       "7        10.987947      2.750742         0.086293        0.006977   \n",
       "71       11.225041      3.120304         0.084912        0.006680   \n",
       "10       12.697493      2.763572         0.102558        0.012531   \n",
       "70       14.001033      1.698254         0.098019        0.010581   \n",
       "2        14.864673      3.416859         0.161675        0.072331   \n",
       "76       18.032323      6.333455         0.086619        0.001047   \n",
       "4        13.676230      2.633184         0.086308        0.010425   \n",
       "78       16.115235      3.211210         0.085858        0.000665   \n",
       "65       13.836911      1.864469         0.094124        0.006174   \n",
       "5        13.585507      6.008313         0.085438        0.005067   \n",
       "3        13.600848      2.361564         0.109238        0.025141   \n",
       "69       11.370613      4.646482         0.084973        0.007713   \n",
       "68       11.388639      3.583290         0.084154        0.000318   \n",
       "0        15.476600      8.170997         0.115300        0.005233   \n",
       "64       10.966549      4.023865         0.095186        0.022113   \n",
       "24        5.734260      6.126808         0.095712        0.013270   \n",
       "88        5.187360      5.182668         0.097177        0.003859   \n",
       "\n",
       "    param_classifier__activation param_classifier__alpha  \\\n",
       "124                         relu                    0.07   \n",
       "115                         relu                    0.07   \n",
       "85                          relu                    0.07   \n",
       "117                         relu                    0.07   \n",
       "98                          relu                    0.07   \n",
       "51                          relu                    0.05   \n",
       "112                         relu                    0.07   \n",
       "90                          relu                    0.07   \n",
       "120                         relu                    0.07   \n",
       "42                          relu                    0.05   \n",
       "21                          relu                    0.05   \n",
       "26                          relu                    0.05   \n",
       "106                         relu                    0.07   \n",
       "31                          relu                    0.05   \n",
       "123                         relu                    0.07   \n",
       "48                          relu                    0.05   \n",
       "34                          relu                    0.05   \n",
       "119                         relu                    0.07   \n",
       "82                          relu                    0.07   \n",
       "107                         relu                    0.07   \n",
       "99                          relu                    0.07   \n",
       "94                          relu                    0.07   \n",
       "18                          relu                    0.05   \n",
       "54                          relu                    0.05   \n",
       "43                          relu                    0.05   \n",
       "113                         relu                    0.07   \n",
       "86                          relu                    0.07   \n",
       "55                          relu                    0.05   \n",
       "116                         relu                    0.07   \n",
       "108                         relu                    0.07   \n",
       "35                          relu                    0.05   \n",
       "97                          relu                    0.07   \n",
       "127                         relu                    0.07   \n",
       "95                          relu                    0.07   \n",
       "109                         relu                    0.07   \n",
       "50                          relu                    0.05   \n",
       "52                          relu                    0.05   \n",
       "29                          relu                    0.05   \n",
       "102                         relu                    0.07   \n",
       "33                          relu                    0.05   \n",
       "111                         relu                    0.07   \n",
       "47                          relu                    0.05   \n",
       "20                          relu                    0.05   \n",
       "121                         relu                    0.07   \n",
       "122                         relu                    0.07   \n",
       "32                          relu                    0.05   \n",
       "87                          relu                    0.07   \n",
       "53                          relu                    0.05   \n",
       "101                         relu                    0.07   \n",
       "23                          relu                    0.05   \n",
       "62                          relu                    0.05   \n",
       "39                          relu                    0.05   \n",
       "104                         relu                    0.07   \n",
       "45                          relu                    0.05   \n",
       "118                         relu                    0.07   \n",
       "125                         relu                    0.07   \n",
       "37                          relu                    0.05   \n",
       "84                          relu                    0.07   \n",
       "114                         relu                    0.07   \n",
       "96                          relu                    0.07   \n",
       "79                          relu                    0.07   \n",
       "8                           relu                    0.05   \n",
       "89                          relu                    0.07   \n",
       "46                          relu                    0.05   \n",
       "105                         relu                    0.07   \n",
       "81                          relu                    0.07   \n",
       "110                         relu                    0.07   \n",
       "40                          relu                    0.05   \n",
       "93                          relu                    0.07   \n",
       "38                          relu                    0.05   \n",
       "92                          relu                    0.07   \n",
       "61                          relu                    0.05   \n",
       "60                          relu                    0.05   \n",
       "30                          relu                    0.05   \n",
       "103                         relu                    0.07   \n",
       "73                          relu                    0.07   \n",
       "91                          relu                    0.07   \n",
       "75                          relu                    0.07   \n",
       "11                          relu                    0.05   \n",
       "49                          relu                    0.05   \n",
       "100                         relu                    0.07   \n",
       "83                          relu                    0.07   \n",
       "58                          relu                    0.05   \n",
       "27                          relu                    0.05   \n",
       "63                          relu                    0.05   \n",
       "36                          relu                    0.05   \n",
       "72                          relu                    0.07   \n",
       "13                          relu                    0.05   \n",
       "80                          relu                    0.07   \n",
       "15                          relu                    0.05   \n",
       "126                         relu                    0.07   \n",
       "17                          relu                    0.05   \n",
       "59                          relu                    0.05   \n",
       "19                          relu                    0.05   \n",
       "9                           relu                    0.05   \n",
       "56                          relu                    0.05   \n",
       "25                          relu                    0.05   \n",
       "44                          relu                    0.05   \n",
       "57                          relu                    0.05   \n",
       "22                          relu                    0.05   \n",
       "41                          relu                    0.05   \n",
       "16                          relu                    0.05   \n",
       "28                          relu                    0.05   \n",
       "77                          relu                    0.07   \n",
       "12                          relu                    0.05   \n",
       "66                          relu                    0.07   \n",
       "67                          relu                    0.07   \n",
       "14                          relu                    0.05   \n",
       "1                           relu                    0.05   \n",
       "6                           relu                    0.05   \n",
       "74                          relu                    0.07   \n",
       "7                           relu                    0.05   \n",
       "71                          relu                    0.07   \n",
       "10                          relu                    0.05   \n",
       "70                          relu                    0.07   \n",
       "2                           relu                    0.05   \n",
       "76                          relu                    0.07   \n",
       "4                           relu                    0.05   \n",
       "78                          relu                    0.07   \n",
       "65                          relu                    0.07   \n",
       "5                           relu                    0.05   \n",
       "3                           relu                    0.05   \n",
       "69                          relu                    0.07   \n",
       "68                          relu                    0.07   \n",
       "0                           relu                    0.05   \n",
       "64                          relu                    0.07   \n",
       "24                          relu                    0.05   \n",
       "88                          relu                    0.07   \n",
       "\n",
       "    param_classifier__hidden_layer_sizes param_classifier__learning_rate  \\\n",
       "124                               (9, 6)                        adaptive   \n",
       "115                               (8, 5)                        adaptive   \n",
       "85                                (4, 7)                        adaptive   \n",
       "117                               (8, 7)                        adaptive   \n",
       "98                                (6, 4)                        adaptive   \n",
       "51                                (8, 5)                        adaptive   \n",
       "112                               (8, 2)                        adaptive   \n",
       "90                                (5, 4)                        adaptive   \n",
       "120                               (9, 2)                        adaptive   \n",
       "42                                (7, 4)                        adaptive   \n",
       "21                                (4, 7)                        adaptive   \n",
       "26                                (5, 4)                        adaptive   \n",
       "106                               (7, 4)                        adaptive   \n",
       "31                                (5, 9)                        adaptive   \n",
       "123                               (9, 5)                        adaptive   \n",
       "48                                (8, 2)                        adaptive   \n",
       "34                                (6, 4)                        adaptive   \n",
       "119                               (8, 9)                        adaptive   \n",
       "82                                (4, 4)                        adaptive   \n",
       "107                               (7, 5)                        adaptive   \n",
       "99                                (6, 5)                        adaptive   \n",
       "94                                (5, 8)                        adaptive   \n",
       "18                                (4, 4)                        adaptive   \n",
       "54                                (8, 8)                        adaptive   \n",
       "43                                (7, 5)                        adaptive   \n",
       "113                               (8, 3)                        adaptive   \n",
       "86                                (4, 8)                        adaptive   \n",
       "55                                (8, 9)                        adaptive   \n",
       "116                               (8, 6)                        adaptive   \n",
       "108                               (7, 6)                        adaptive   \n",
       "35                                (6, 5)                        adaptive   \n",
       "97                                (6, 3)                        adaptive   \n",
       "127                               (9, 9)                        adaptive   \n",
       "95                                (5, 9)                        adaptive   \n",
       "109                               (7, 7)                        adaptive   \n",
       "50                                (8, 4)                        adaptive   \n",
       "52                                (8, 6)                        adaptive   \n",
       "29                                (5, 7)                        adaptive   \n",
       "102                               (6, 8)                        adaptive   \n",
       "33                                (6, 3)                        adaptive   \n",
       "111                               (7, 9)                        adaptive   \n",
       "47                                (7, 9)                        adaptive   \n",
       "20                                (4, 6)                        adaptive   \n",
       "121                               (9, 3)                        adaptive   \n",
       "122                               (9, 4)                        adaptive   \n",
       "32                                (6, 2)                        adaptive   \n",
       "87                                (4, 9)                        adaptive   \n",
       "53                                (8, 7)                        adaptive   \n",
       "101                               (6, 7)                        adaptive   \n",
       "23                                (4, 9)                        adaptive   \n",
       "62                                (9, 8)                        adaptive   \n",
       "39                                (6, 9)                        adaptive   \n",
       "104                               (7, 2)                        adaptive   \n",
       "45                                (7, 7)                        adaptive   \n",
       "118                               (8, 8)                        adaptive   \n",
       "125                               (9, 7)                        adaptive   \n",
       "37                                (6, 7)                        adaptive   \n",
       "84                                (4, 6)                        adaptive   \n",
       "114                               (8, 4)                        adaptive   \n",
       "96                                (6, 2)                        adaptive   \n",
       "79                                (3, 9)                        adaptive   \n",
       "8                                 (3, 2)                        adaptive   \n",
       "89                                (5, 3)                        adaptive   \n",
       "46                                (7, 8)                        adaptive   \n",
       "105                               (7, 3)                        adaptive   \n",
       "81                                (4, 3)                        adaptive   \n",
       "110                               (7, 8)                        adaptive   \n",
       "40                                (7, 2)                        adaptive   \n",
       "93                                (5, 7)                        adaptive   \n",
       "38                                (6, 8)                        adaptive   \n",
       "92                                (5, 6)                        adaptive   \n",
       "61                                (9, 7)                        adaptive   \n",
       "60                                (9, 6)                        adaptive   \n",
       "30                                (5, 8)                        adaptive   \n",
       "103                               (6, 9)                        adaptive   \n",
       "73                                (3, 3)                        adaptive   \n",
       "91                                (5, 5)                        adaptive   \n",
       "75                                (3, 5)                        adaptive   \n",
       "11                                (3, 5)                        adaptive   \n",
       "49                                (8, 3)                        adaptive   \n",
       "100                               (6, 6)                        adaptive   \n",
       "83                                (4, 5)                        adaptive   \n",
       "58                                (9, 4)                        adaptive   \n",
       "27                                (5, 5)                        adaptive   \n",
       "63                                (9, 9)                        adaptive   \n",
       "36                                (6, 6)                        adaptive   \n",
       "72                                (3, 2)                        adaptive   \n",
       "13                                (3, 7)                        adaptive   \n",
       "80                                (4, 2)                        adaptive   \n",
       "15                                (3, 9)                        adaptive   \n",
       "126                               (9, 8)                        adaptive   \n",
       "17                                (4, 3)                        adaptive   \n",
       "59                                (9, 5)                        adaptive   \n",
       "19                                (4, 5)                        adaptive   \n",
       "9                                 (3, 3)                        adaptive   \n",
       "56                                (9, 2)                        adaptive   \n",
       "25                                (5, 3)                        adaptive   \n",
       "44                                (7, 6)                        adaptive   \n",
       "57                                (9, 3)                        adaptive   \n",
       "22                                (4, 8)                        adaptive   \n",
       "41                                (7, 3)                        adaptive   \n",
       "16                                (4, 2)                        adaptive   \n",
       "28                                (5, 6)                        adaptive   \n",
       "77                                (3, 7)                        adaptive   \n",
       "12                                (3, 6)                        adaptive   \n",
       "66                                (2, 4)                        adaptive   \n",
       "67                                (2, 5)                        adaptive   \n",
       "14                                (3, 8)                        adaptive   \n",
       "1                                 (2, 3)                        adaptive   \n",
       "6                                 (2, 8)                        adaptive   \n",
       "74                                (3, 4)                        adaptive   \n",
       "7                                 (2, 9)                        adaptive   \n",
       "71                                (2, 9)                        adaptive   \n",
       "10                                (3, 4)                        adaptive   \n",
       "70                                (2, 8)                        adaptive   \n",
       "2                                 (2, 4)                        adaptive   \n",
       "76                                (3, 6)                        adaptive   \n",
       "4                                 (2, 6)                        adaptive   \n",
       "78                                (3, 8)                        adaptive   \n",
       "65                                (2, 3)                        adaptive   \n",
       "5                                 (2, 7)                        adaptive   \n",
       "3                                 (2, 5)                        adaptive   \n",
       "69                                (2, 7)                        adaptive   \n",
       "68                                (2, 6)                        adaptive   \n",
       "0                                 (2, 2)                        adaptive   \n",
       "64                                (2, 2)                        adaptive   \n",
       "24                                (5, 2)                        adaptive   \n",
       "88                                (5, 2)                        adaptive   \n",
       "\n",
       "    param_classifier__max_iter param_classifier__solver  \\\n",
       "124                        500                     adam   \n",
       "115                        500                     adam   \n",
       "85                         500                     adam   \n",
       "117                        500                     adam   \n",
       "98                         500                     adam   \n",
       "51                         500                     adam   \n",
       "112                        500                     adam   \n",
       "90                         500                     adam   \n",
       "120                        500                     adam   \n",
       "42                         500                     adam   \n",
       "21                         500                     adam   \n",
       "26                         500                     adam   \n",
       "106                        500                     adam   \n",
       "31                         500                     adam   \n",
       "123                        500                     adam   \n",
       "48                         500                     adam   \n",
       "34                         500                     adam   \n",
       "119                        500                     adam   \n",
       "82                         500                     adam   \n",
       "107                        500                     adam   \n",
       "99                         500                     adam   \n",
       "94                         500                     adam   \n",
       "18                         500                     adam   \n",
       "54                         500                     adam   \n",
       "43                         500                     adam   \n",
       "113                        500                     adam   \n",
       "86                         500                     adam   \n",
       "55                         500                     adam   \n",
       "116                        500                     adam   \n",
       "108                        500                     adam   \n",
       "35                         500                     adam   \n",
       "97                         500                     adam   \n",
       "127                        500                     adam   \n",
       "95                         500                     adam   \n",
       "109                        500                     adam   \n",
       "50                         500                     adam   \n",
       "52                         500                     adam   \n",
       "29                         500                     adam   \n",
       "102                        500                     adam   \n",
       "33                         500                     adam   \n",
       "111                        500                     adam   \n",
       "47                         500                     adam   \n",
       "20                         500                     adam   \n",
       "121                        500                     adam   \n",
       "122                        500                     adam   \n",
       "32                         500                     adam   \n",
       "87                         500                     adam   \n",
       "53                         500                     adam   \n",
       "101                        500                     adam   \n",
       "23                         500                     adam   \n",
       "62                         500                     adam   \n",
       "39                         500                     adam   \n",
       "104                        500                     adam   \n",
       "45                         500                     adam   \n",
       "118                        500                     adam   \n",
       "125                        500                     adam   \n",
       "37                         500                     adam   \n",
       "84                         500                     adam   \n",
       "114                        500                     adam   \n",
       "96                         500                     adam   \n",
       "79                         500                     adam   \n",
       "8                          500                     adam   \n",
       "89                         500                     adam   \n",
       "46                         500                     adam   \n",
       "105                        500                     adam   \n",
       "81                         500                     adam   \n",
       "110                        500                     adam   \n",
       "40                         500                     adam   \n",
       "93                         500                     adam   \n",
       "38                         500                     adam   \n",
       "92                         500                     adam   \n",
       "61                         500                     adam   \n",
       "60                         500                     adam   \n",
       "30                         500                     adam   \n",
       "103                        500                     adam   \n",
       "73                         500                     adam   \n",
       "91                         500                     adam   \n",
       "75                         500                     adam   \n",
       "11                         500                     adam   \n",
       "49                         500                     adam   \n",
       "100                        500                     adam   \n",
       "83                         500                     adam   \n",
       "58                         500                     adam   \n",
       "27                         500                     adam   \n",
       "63                         500                     adam   \n",
       "36                         500                     adam   \n",
       "72                         500                     adam   \n",
       "13                         500                     adam   \n",
       "80                         500                     adam   \n",
       "15                         500                     adam   \n",
       "126                        500                     adam   \n",
       "17                         500                     adam   \n",
       "59                         500                     adam   \n",
       "19                         500                     adam   \n",
       "9                          500                     adam   \n",
       "56                         500                     adam   \n",
       "25                         500                     adam   \n",
       "44                         500                     adam   \n",
       "57                         500                     adam   \n",
       "22                         500                     adam   \n",
       "41                         500                     adam   \n",
       "16                         500                     adam   \n",
       "28                         500                     adam   \n",
       "77                         500                     adam   \n",
       "12                         500                     adam   \n",
       "66                         500                     adam   \n",
       "67                         500                     adam   \n",
       "14                         500                     adam   \n",
       "1                          500                     adam   \n",
       "6                          500                     adam   \n",
       "74                         500                     adam   \n",
       "7                          500                     adam   \n",
       "71                         500                     adam   \n",
       "10                         500                     adam   \n",
       "70                         500                     adam   \n",
       "2                          500                     adam   \n",
       "76                         500                     adam   \n",
       "4                          500                     adam   \n",
       "78                         500                     adam   \n",
       "65                         500                     adam   \n",
       "5                          500                     adam   \n",
       "3                          500                     adam   \n",
       "69                         500                     adam   \n",
       "68                         500                     adam   \n",
       "0                          500                     adam   \n",
       "64                         500                     adam   \n",
       "24                         500                     adam   \n",
       "88                         500                     adam   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "124  {'classifier__activation': 'relu', 'classifier...           0.864311   \n",
       "115  {'classifier__activation': 'relu', 'classifier...           0.863853   \n",
       "85   {'classifier__activation': 'relu', 'classifier...           0.863395   \n",
       "117  {'classifier__activation': 'relu', 'classifier...           0.862296   \n",
       "98   {'classifier__activation': 'relu', 'classifier...           0.861655   \n",
       "51   {'classifier__activation': 'relu', 'classifier...           0.862022   \n",
       "112  {'classifier__activation': 'relu', 'classifier...           0.861930   \n",
       "90   {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "120  {'classifier__activation': 'relu', 'classifier...           0.861014   \n",
       "42   {'classifier__activation': 'relu', 'classifier...           0.865409   \n",
       "21   {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "26   {'classifier__activation': 'relu', 'classifier...           0.864677   \n",
       "106  {'classifier__activation': 'relu', 'classifier...           0.863670   \n",
       "31   {'classifier__activation': 'relu', 'classifier...           0.863029   \n",
       "123  {'classifier__activation': 'relu', 'classifier...           0.862022   \n",
       "48   {'classifier__activation': 'relu', 'classifier...           0.861930   \n",
       "34   {'classifier__activation': 'relu', 'classifier...           0.863761   \n",
       "119  {'classifier__activation': 'relu', 'classifier...           0.865501   \n",
       "82   {'classifier__activation': 'relu', 'classifier...           0.862937   \n",
       "107  {'classifier__activation': 'relu', 'classifier...           0.862296   \n",
       "99   {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "94   {'classifier__activation': 'relu', 'classifier...           0.860740   \n",
       "18   {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "54   {'classifier__activation': 'relu', 'classifier...           0.863761   \n",
       "43   {'classifier__activation': 'relu', 'classifier...           0.861564   \n",
       "113  {'classifier__activation': 'relu', 'classifier...           0.864127   \n",
       "86   {'classifier__activation': 'relu', 'classifier...           0.864036   \n",
       "55   {'classifier__activation': 'relu', 'classifier...           0.863029   \n",
       "116  {'classifier__activation': 'relu', 'classifier...           0.865409   \n",
       "108  {'classifier__activation': 'relu', 'classifier...           0.862205   \n",
       "35   {'classifier__activation': 'relu', 'classifier...           0.863303   \n",
       "97   {'classifier__activation': 'relu', 'classifier...           0.865135   \n",
       "127  {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "95   {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "109  {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "50   {'classifier__activation': 'relu', 'classifier...           0.861106   \n",
       "52   {'classifier__activation': 'relu', 'classifier...           0.862846   \n",
       "29   {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "102  {'classifier__activation': 'relu', 'classifier...           0.864677   \n",
       "33   {'classifier__activation': 'relu', 'classifier...           0.865409   \n",
       "111  {'classifier__activation': 'relu', 'classifier...           0.862571   \n",
       "47   {'classifier__activation': 'relu', 'classifier...           0.863029   \n",
       "20   {'classifier__activation': 'relu', 'classifier...           0.860007   \n",
       "121  {'classifier__activation': 'relu', 'classifier...           0.863395   \n",
       "122  {'classifier__activation': 'relu', 'classifier...           0.861472   \n",
       "32   {'classifier__activation': 'relu', 'classifier...           0.863029   \n",
       "87   {'classifier__activation': 'relu', 'classifier...           0.861747   \n",
       "53   {'classifier__activation': 'relu', 'classifier...           0.860282   \n",
       "101  {'classifier__activation': 'relu', 'classifier...           0.864219   \n",
       "23   {'classifier__activation': 'relu', 'classifier...           0.862022   \n",
       "62   {'classifier__activation': 'relu', 'classifier...           0.861655   \n",
       "39   {'classifier__activation': 'relu', 'classifier...           0.864311   \n",
       "104  {'classifier__activation': 'relu', 'classifier...           0.860923   \n",
       "45   {'classifier__activation': 'relu', 'classifier...           0.863120   \n",
       "118  {'classifier__activation': 'relu', 'classifier...           0.861930   \n",
       "125  {'classifier__activation': 'relu', 'classifier...           0.860374   \n",
       "37   {'classifier__activation': 'relu', 'classifier...           0.862937   \n",
       "84   {'classifier__activation': 'relu', 'classifier...           0.861106   \n",
       "114  {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "96   {'classifier__activation': 'relu', 'classifier...           0.861930   \n",
       "79   {'classifier__activation': 'relu', 'classifier...           0.862663   \n",
       "8    {'classifier__activation': 'relu', 'classifier...           0.861747   \n",
       "89   {'classifier__activation': 'relu', 'classifier...           0.860282   \n",
       "46   {'classifier__activation': 'relu', 'classifier...           0.863487   \n",
       "105  {'classifier__activation': 'relu', 'classifier...           0.860740   \n",
       "81   {'classifier__activation': 'relu', 'classifier...           0.862022   \n",
       "110  {'classifier__activation': 'relu', 'classifier...           0.860007   \n",
       "40   {'classifier__activation': 'relu', 'classifier...           0.861289   \n",
       "93   {'classifier__activation': 'relu', 'classifier...           0.861564   \n",
       "38   {'classifier__activation': 'relu', 'classifier...           0.862937   \n",
       "92   {'classifier__activation': 'relu', 'classifier...           0.861472   \n",
       "61   {'classifier__activation': 'relu', 'classifier...           0.861014   \n",
       "60   {'classifier__activation': 'relu', 'classifier...           0.862205   \n",
       "30   {'classifier__activation': 'relu', 'classifier...           0.861655   \n",
       "103  {'classifier__activation': 'relu', 'classifier...           0.861106   \n",
       "73   {'classifier__activation': 'relu', 'classifier...           0.859641   \n",
       "91   {'classifier__activation': 'relu', 'classifier...           0.860282   \n",
       "75   {'classifier__activation': 'relu', 'classifier...           0.861747   \n",
       "11   {'classifier__activation': 'relu', 'classifier...           0.861472   \n",
       "49   {'classifier__activation': 'relu', 'classifier...           0.862571   \n",
       "100  {'classifier__activation': 'relu', 'classifier...           0.860465   \n",
       "83   {'classifier__activation': 'relu', 'classifier...           0.860099   \n",
       "58   {'classifier__activation': 'relu', 'classifier...           0.861655   \n",
       "27   {'classifier__activation': 'relu', 'classifier...           0.858634   \n",
       "63   {'classifier__activation': 'relu', 'classifier...           0.861198   \n",
       "36   {'classifier__activation': 'relu', 'classifier...           0.861106   \n",
       "72   {'classifier__activation': 'relu', 'classifier...           0.863487   \n",
       "13   {'classifier__activation': 'relu', 'classifier...           0.860831   \n",
       "80   {'classifier__activation': 'relu', 'classifier...           0.862846   \n",
       "15   {'classifier__activation': 'relu', 'classifier...           0.861198   \n",
       "126  {'classifier__activation': 'relu', 'classifier...           0.862663   \n",
       "17   {'classifier__activation': 'relu', 'classifier...           0.860190   \n",
       "59   {'classifier__activation': 'relu', 'classifier...           0.857535   \n",
       "19   {'classifier__activation': 'relu', 'classifier...           0.856437   \n",
       "9    {'classifier__activation': 'relu', 'classifier...           0.859458   \n",
       "56   {'classifier__activation': 'relu', 'classifier...           0.861472   \n",
       "25   {'classifier__activation': 'relu', 'classifier...           0.859824   \n",
       "44   {'classifier__activation': 'relu', 'classifier...           0.860740   \n",
       "57   {'classifier__activation': 'relu', 'classifier...           0.861381   \n",
       "22   {'classifier__activation': 'relu', 'classifier...           0.862937   \n",
       "41   {'classifier__activation': 'relu', 'classifier...           0.860282   \n",
       "16   {'classifier__activation': 'relu', 'classifier...           0.863120   \n",
       "28   {'classifier__activation': 'relu', 'classifier...           0.860465   \n",
       "77   {'classifier__activation': 'relu', 'classifier...           0.860465   \n",
       "12   {'classifier__activation': 'relu', 'classifier...           0.858634   \n",
       "66   {'classifier__activation': 'relu', 'classifier...           0.860557   \n",
       "67   {'classifier__activation': 'relu', 'classifier...           0.858268   \n",
       "14   {'classifier__activation': 'relu', 'classifier...           0.861381   \n",
       "1    {'classifier__activation': 'relu', 'classifier...           0.859092   \n",
       "6    {'classifier__activation': 'relu', 'classifier...           0.859916   \n",
       "74   {'classifier__activation': 'relu', 'classifier...           0.858268   \n",
       "7    {'classifier__activation': 'relu', 'classifier...           0.860465   \n",
       "71   {'classifier__activation': 'relu', 'classifier...           0.861014   \n",
       "10   {'classifier__activation': 'relu', 'classifier...           0.859092   \n",
       "70   {'classifier__activation': 'relu', 'classifier...           0.860282   \n",
       "2    {'classifier__activation': 'relu', 'classifier...           0.860374   \n",
       "76   {'classifier__activation': 'relu', 'classifier...           0.858268   \n",
       "4    {'classifier__activation': 'relu', 'classifier...           0.859733   \n",
       "78   {'classifier__activation': 'relu', 'classifier...           0.858817   \n",
       "65   {'classifier__activation': 'relu', 'classifier...           0.859458   \n",
       "5    {'classifier__activation': 'relu', 'classifier...           0.858634   \n",
       "3    {'classifier__activation': 'relu', 'classifier...           0.857810   \n",
       "69   {'classifier__activation': 'relu', 'classifier...           0.858634   \n",
       "68   {'classifier__activation': 'relu', 'classifier...           0.858817   \n",
       "0    {'classifier__activation': 'relu', 'classifier...           0.858542   \n",
       "64   {'classifier__activation': 'relu', 'classifier...           0.859824   \n",
       "24   {'classifier__activation': 'relu', 'classifier...           0.689251   \n",
       "88   {'classifier__activation': 'relu', 'classifier...           0.689251   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "124           0.862388           0.860361           0.861093   \n",
       "115           0.865318           0.856973           0.857797   \n",
       "85            0.862113           0.858346           0.860635   \n",
       "117           0.864402           0.858713           0.858346   \n",
       "98            0.862205           0.859995           0.858987   \n",
       "51            0.864585           0.857522           0.859537   \n",
       "112           0.861289           0.858713           0.858987   \n",
       "90            0.863212           0.855691           0.858529   \n",
       "120           0.865318           0.857248           0.859262   \n",
       "42            0.862205           0.857888           0.856790   \n",
       "21            0.861289           0.858346           0.859445   \n",
       "26            0.862663           0.855874           0.858621   \n",
       "106           0.862296           0.856973           0.859811   \n",
       "31            0.861381           0.857980           0.859811   \n",
       "123           0.864585           0.858621           0.859720   \n",
       "48            0.862296           0.858438           0.860269   \n",
       "34            0.861106           0.857888           0.858163   \n",
       "119           0.861747           0.859170           0.856515   \n",
       "82            0.859458           0.857522           0.861826   \n",
       "107           0.864494           0.856698           0.859628   \n",
       "99            0.861289           0.856240           0.859445   \n",
       "94            0.861564           0.858346           0.860361   \n",
       "18            0.861747           0.857156           0.860727   \n",
       "54            0.862479           0.854867           0.861276   \n",
       "43            0.863578           0.858987           0.857431   \n",
       "113           0.861289           0.856881           0.858255   \n",
       "86            0.861564           0.859995           0.857797   \n",
       "55            0.862296           0.859354           0.856790   \n",
       "116           0.862205           0.854226           0.858804   \n",
       "108           0.860007           0.856607           0.860910   \n",
       "35            0.859550           0.858072           0.858804   \n",
       "97            0.862296           0.860544           0.854317   \n",
       "127           0.863487           0.857522           0.857339   \n",
       "95            0.860648           0.856240           0.859811   \n",
       "109           0.861106           0.858896           0.855782   \n",
       "50            0.856894           0.857797           0.860086   \n",
       "52            0.861014           0.856332           0.859811   \n",
       "29            0.861564           0.855691           0.857888   \n",
       "102           0.860007           0.857614           0.858896   \n",
       "33            0.862571           0.858255           0.856149   \n",
       "111           0.861564           0.856607           0.858621   \n",
       "47            0.860923           0.855874           0.859079   \n",
       "20            0.861198           0.860819           0.858255   \n",
       "121           0.861655           0.854867           0.860452   \n",
       "122           0.864494           0.858346           0.857248   \n",
       "32            0.859641           0.857431           0.858438   \n",
       "87            0.861381           0.857064           0.860727   \n",
       "53            0.862022           0.857064           0.859720   \n",
       "101           0.862846           0.853768           0.859079   \n",
       "23            0.859550           0.858621           0.859995   \n",
       "62            0.861472           0.855691           0.857156   \n",
       "39            0.861655           0.855325           0.856790   \n",
       "104           0.861472           0.857064           0.859628   \n",
       "45            0.862571           0.857156           0.853127   \n",
       "118           0.860557           0.856240           0.860086   \n",
       "125           0.863120           0.857705           0.857156   \n",
       "37            0.857993           0.858529           0.855782   \n",
       "84            0.860007           0.859628           0.857431   \n",
       "114           0.857993           0.858621           0.856790   \n",
       "96            0.859183           0.858163           0.859445   \n",
       "79            0.860282           0.854867           0.860452   \n",
       "8             0.859550           0.855508           0.860086   \n",
       "89            0.859824           0.858346           0.856515   \n",
       "46            0.863395           0.855782           0.856149   \n",
       "105           0.860007           0.853951           0.859170   \n",
       "81            0.861838           0.855782           0.857614   \n",
       "110           0.859550           0.855874           0.860635   \n",
       "40            0.862571           0.856607           0.857339   \n",
       "93            0.859550           0.855966           0.858621   \n",
       "38            0.858909           0.855141           0.858346   \n",
       "92            0.859550           0.854775           0.858346   \n",
       "61            0.861106           0.857705           0.857614   \n",
       "60            0.857169           0.857431           0.860361   \n",
       "30            0.860923           0.854043           0.859262   \n",
       "103           0.860831           0.856332           0.856881   \n",
       "73            0.858085           0.857431           0.857888   \n",
       "91            0.858085           0.857797           0.860269   \n",
       "75            0.860190           0.856423           0.857888   \n",
       "11            0.858542           0.857064           0.858804   \n",
       "49            0.856711           0.854958           0.857614   \n",
       "100           0.857444           0.857797           0.857705   \n",
       "83            0.857627           0.855966           0.859170   \n",
       "58            0.860831           0.855966           0.857980   \n",
       "27            0.861747           0.855782           0.858346   \n",
       "63            0.862571           0.853768           0.857156   \n",
       "36            0.860374           0.855782           0.855966   \n",
       "72            0.858909           0.853310           0.859354   \n",
       "13            0.861014           0.858804           0.856057   \n",
       "80            0.858726           0.856057           0.858072   \n",
       "15            0.860007           0.856515           0.856790   \n",
       "126           0.860099           0.855599           0.857064   \n",
       "17            0.860190           0.855966           0.857064   \n",
       "59            0.863578           0.856057           0.857156   \n",
       "19            0.858909           0.855416           0.858896   \n",
       "9             0.857993           0.855141           0.860178   \n",
       "56            0.858176           0.855508           0.857797   \n",
       "25            0.858634           0.858713           0.855599   \n",
       "44            0.854605           0.855141           0.860635   \n",
       "57            0.859183           0.855141           0.859262   \n",
       "22            0.860831           0.857339           0.855233   \n",
       "41            0.858451           0.852944           0.859354   \n",
       "16            0.858542           0.854958           0.856607   \n",
       "28            0.858176           0.855508           0.859170   \n",
       "77            0.859000           0.858072           0.855782   \n",
       "12            0.859366           0.856698           0.855599   \n",
       "66            0.858634           0.852852           0.860452   \n",
       "67            0.858268           0.856973           0.858529   \n",
       "14            0.857901           0.855233           0.857156   \n",
       "1             0.856986           0.854592           0.858987   \n",
       "6             0.858817           0.854226           0.857431   \n",
       "74            0.860099           0.852852           0.857156   \n",
       "7             0.857444           0.853768           0.859995   \n",
       "71            0.857261           0.853219           0.859445   \n",
       "10            0.861289           0.852578           0.857339   \n",
       "70            0.859000           0.853860           0.857980   \n",
       "2             0.857901           0.853219           0.858713   \n",
       "76            0.859641           0.854226           0.855141   \n",
       "4             0.858451           0.855050           0.856515   \n",
       "78            0.856986           0.854043           0.858529   \n",
       "65            0.857810           0.854775           0.854409   \n",
       "5             0.857901           0.852394           0.859445   \n",
       "3             0.859092           0.850563           0.858621   \n",
       "69            0.857627           0.851570           0.856698   \n",
       "68            0.857993           0.852394           0.856607   \n",
       "0             0.860923           0.854867           0.856698   \n",
       "64            0.857352           0.852944           0.857064   \n",
       "24            0.689526           0.696548           0.690871   \n",
       "88            0.689526           0.696548           0.690871   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "124           0.857431         0.861117        0.002279                1  \n",
       "115           0.860452         0.860879        0.003271                2  \n",
       "85            0.858804         0.860659        0.001918                3  \n",
       "117           0.859170         0.860586        0.002367                4  \n",
       "98            0.859811         0.860531        0.001205                5  \n",
       "51            0.858163         0.860366        0.002614                6  \n",
       "112           0.860361         0.860256        0.001255                7  \n",
       "90            0.861093         0.860256        0.002811                8  \n",
       "120           0.858438         0.860256        0.002812                9  \n",
       "42            0.858896         0.860238        0.003157               10  \n",
       "21            0.858438         0.860219        0.001985               11  \n",
       "26            0.859170         0.860201        0.003110               12  \n",
       "106           0.858163         0.860183        0.002496               13  \n",
       "31            0.858438         0.860128        0.001874               14  \n",
       "123           0.855599         0.860109        0.003046               15  \n",
       "48            0.857522         0.860091        0.001877               16  \n",
       "34            0.859262         0.860036        0.002179               17  \n",
       "119           0.857248         0.860036        0.003278               18  \n",
       "82            0.858255         0.860000        0.002071               19  \n",
       "107           0.856881         0.860000        0.003041               20  \n",
       "99            0.859354         0.859981        0.002422               21  \n",
       "94            0.858621         0.859926        0.001244               22  \n",
       "18            0.857248         0.859926        0.002315               23  \n",
       "54            0.857156         0.859908        0.003356               24  \n",
       "43            0.857614         0.859835        0.002385               25  \n",
       "113           0.858529         0.859816        0.002587               26  \n",
       "86            0.855691         0.859816        0.002898               27  \n",
       "55            0.857522         0.859798        0.002494               28  \n",
       "116           0.858346         0.859798        0.003780               29  \n",
       "108           0.859079         0.859762        0.001885               30  \n",
       "35            0.859079         0.859762        0.001835               31  \n",
       "97            0.856332         0.859725        0.003932               32  \n",
       "127           0.856332         0.859725        0.003287               32  \n",
       "95            0.858987         0.859688        0.002131               34  \n",
       "109           0.858255         0.859597        0.002758               35  \n",
       "50            0.862009         0.859578        0.001943               36  \n",
       "52            0.857614         0.859523        0.002331               37  \n",
       "29            0.859720         0.859523        0.002530               38  \n",
       "102           0.856423         0.859523        0.002844               39  \n",
       "33            0.855141         0.859505        0.003902               40  \n",
       "111           0.858072         0.859487        0.002230               41  \n",
       "47            0.858255         0.859432        0.002422               42  \n",
       "20            0.856698         0.859395        0.001687               43  \n",
       "121           0.856423         0.859359        0.003211               44  \n",
       "122           0.855233         0.859359        0.003266               45  \n",
       "32            0.858072         0.859322        0.001988               46  \n",
       "87            0.855691         0.859322        0.002465               47  \n",
       "53            0.857339         0.859285        0.001865               48  \n",
       "101           0.856423         0.859267        0.003891               49  \n",
       "23            0.855782         0.859194        0.002036               50  \n",
       "62            0.859720         0.859139        0.002364               51  \n",
       "39            0.857614         0.859139        0.003331               52  \n",
       "104           0.856423         0.859102        0.002027               53  \n",
       "45            0.859262         0.859047        0.003679               54  \n",
       "118           0.856240         0.859011        0.002342               55  \n",
       "125           0.856698         0.859011        0.002418               56  \n",
       "37            0.859628         0.858974        0.002344               57  \n",
       "84            0.856698         0.858974        0.001649               58  \n",
       "114           0.858621         0.858956        0.002013               59  \n",
       "96            0.856057         0.858956        0.001906               60  \n",
       "79            0.856515         0.858956        0.002843               61  \n",
       "8             0.857705         0.858919        0.002139               62  \n",
       "89            0.859354         0.858864        0.001339               63  \n",
       "46            0.855325         0.858827        0.003776               64  \n",
       "105           0.860086         0.858791        0.002471               65  \n",
       "81            0.856698         0.858791        0.002628               66  \n",
       "110           0.857797         0.858773        0.001729               67  \n",
       "40            0.855874         0.858736        0.002680               68  \n",
       "93            0.857888         0.858718        0.001847               69  \n",
       "38            0.858255         0.858718        0.002489               70  \n",
       "92            0.859262         0.858681        0.002202               71  \n",
       "61            0.855874         0.858663        0.002064               72  \n",
       "60            0.856057         0.858644        0.002279               73  \n",
       "30            0.857339         0.858644        0.002739               74  \n",
       "103           0.857888         0.858608        0.001993               75  \n",
       "73            0.859811         0.858571        0.000968               76  \n",
       "91            0.856423         0.858571        0.001501               77  \n",
       "75            0.856607         0.858571        0.002081               78  \n",
       "11            0.856790         0.858535        0.001668               79  \n",
       "49            0.860544         0.858480        0.002730               80  \n",
       "100           0.858896         0.858461        0.001118               81  \n",
       "83            0.859262         0.858425        0.001466               82  \n",
       "58            0.855599         0.858406        0.002468               83  \n",
       "27            0.857339         0.858370        0.001961               84  \n",
       "63            0.857064         0.858351        0.003162               85  \n",
       "36            0.858346         0.858315        0.002189               86  \n",
       "72            0.856515         0.858315        0.003360               87  \n",
       "13            0.854775         0.858296        0.002509               88  \n",
       "80            0.855599         0.858260        0.002577               89  \n",
       "15            0.856240         0.858150        0.002045               90  \n",
       "126           0.855233         0.858132        0.002841               91  \n",
       "17            0.857064         0.858095        0.001757               92  \n",
       "59            0.855966         0.858058        0.002826               93  \n",
       "19            0.860452         0.858022        0.001831               94  \n",
       "9             0.856698         0.857894        0.001826               95  \n",
       "56            0.856515         0.857894        0.002024               96  \n",
       "25            0.856423         0.857839        0.001572               97  \n",
       "44            0.857980         0.857820        0.002607               98  \n",
       "57            0.854134         0.857820        0.002734               99  \n",
       "22            0.852486         0.857765        0.003758              100  \n",
       "41            0.857431         0.857692        0.002556              101  \n",
       "16            0.855050         0.857655        0.003027              102  \n",
       "28            0.854501         0.857564        0.002235              103  \n",
       "77            0.854409         0.857546        0.002185              104  \n",
       "12            0.856973         0.857454        0.001363              105  \n",
       "66            0.854684         0.857436        0.003126              106  \n",
       "67            0.854592         0.857326        0.001471              107  \n",
       "14            0.854958         0.857326        0.002315              108  \n",
       "1             0.856240         0.857179        0.001705              109  \n",
       "6             0.855416         0.857161        0.002101              110  \n",
       "74            0.857156         0.857106        0.002384              111  \n",
       "7             0.853768         0.857088        0.002899              112  \n",
       "71            0.854226         0.857033        0.002972              113  \n",
       "10            0.854684         0.856996        0.003092              114  \n",
       "70            0.853310         0.856886        0.002798              115  \n",
       "2             0.854043         0.856850        0.002759              116  \n",
       "76            0.856881         0.856831        0.001980              117  \n",
       "4             0.853860         0.856722        0.002149              118  \n",
       "78            0.855050         0.856685        0.001881              119  \n",
       "65            0.855599         0.856410        0.001928              120  \n",
       "5             0.853493         0.856374        0.002864              121  \n",
       "3             0.854226         0.856062        0.003237              122  \n",
       "69            0.853219         0.855550        0.002699              123  \n",
       "68            0.851479         0.855458        0.002975              124  \n",
       "0             0.696456         0.825497        0.064552              125  \n",
       "64            0.696456         0.824728        0.064174              126  \n",
       "24            0.858163         0.724872        0.066698              127  \n",
       "88            0.857614         0.724762        0.066478              128  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_2 = pd.DataFrame(nn_grid_search_2_cv.cv_results_)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "cv_res_2.sort_values(by=\"mean_test_score\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9659e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn_grid_search_2_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9471c1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__activation</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__hidden_layer_sizes</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>20.093515</td>\n",
       "      <td>4.633449</td>\n",
       "      <td>0.091102</td>\n",
       "      <td>0.00801</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.864585</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.85972</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.860109</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "123      20.093515      4.633449         0.091102         0.00801   \n",
       "\n",
       "    param_classifier__activation param_classifier__alpha  \\\n",
       "123                         relu                    0.07   \n",
       "\n",
       "    param_classifier__hidden_layer_sizes param_classifier__learning_rate  \\\n",
       "123                               (9, 5)                        adaptive   \n",
       "\n",
       "    param_classifier__max_iter param_classifier__solver  \\\n",
       "123                        500                     adam   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "123  {'classifier__activation': 'relu', 'classifier...           0.862022   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "123           0.864585           0.858621            0.85972   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "123           0.855599         0.860109        0.003046               15  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores = nn_grid_search_2_cv.cv_results_[\"mean_test_score\"]\n",
    "best_index = np.argmax(mean_scores)\n",
    "se_scores = nn_grid_search_2_cv.cv_results_[\"std_test_score\"] / np.sqrt(5)\n",
    "\n",
    "one_stand_error_data_frame = cv_res_2[cv_res_2[\"mean_test_score\"] >= (mean_scores[best_index] - se_scores[best_index])]\n",
    "one_stand_error_data_frame[one_stand_error_data_frame[\"mean_test_score\"] == one_stand_error_data_frame[\"mean_test_score\"].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147c2dd",
   "metadata": {},
   "source": [
    "## For 2 Layers Only: Further Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08d1a911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 6),\n",
       " (4, 7),\n",
       " (8, 7),\n",
       " (8, 5),\n",
       " (5, 4),\n",
       " (9, 2),\n",
       " (7, 4),\n",
       " (5, 9),\n",
       " (9, 5),\n",
       " (8, 2),\n",
       " (6, 4),\n",
       " (8, 9),\n",
       " (4, 4),\n",
       " (7, 5)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_combinations_layers_2_bis = [(9,6), (4,7), (8,7), (8,5), (5,4), (9,2), (7,4), (5,9), (9,5), (8,2), (6,4), (8,9), (4,4), (7,5)]\n",
    "list_combinations_layers_2_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "715f34a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__hidden_layer_sizes': [(9, 6),\n",
       "  (4, 7),\n",
       "  (8, 7),\n",
       "  (8, 5),\n",
       "  (5, 4),\n",
       "  (9, 2),\n",
       "  (7, 4),\n",
       "  (5, 9),\n",
       "  (9, 5),\n",
       "  (8, 2),\n",
       "  (6, 4),\n",
       "  (8, 9),\n",
       "  (4, 4),\n",
       "  (7, 5)],\n",
       " 'classifier__activation': ['relu'],\n",
       " 'classifier__solver': ['adam', 'sgd'],\n",
       " 'classifier__alpha': [0.05, 0.07, 0.1, 0.15],\n",
       " 'classifier__learning_rate': ['adaptive'],\n",
       " 'classifier__max_iter': [500]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param_2_bis = {\n",
    "    \"classifier__hidden_layer_sizes\": list_combinations_layers_2, \n",
    "              \"classifier__activation\": ['relu'],\n",
    "              \"classifier__solver\": ['adam', 'sgd'],\n",
    "              \"classifier__alpha\": [0.05, 0.07, 0.1, 0.15],\n",
    "              \"classifier__learning_rate\": ['adaptive'],\n",
    "              \"classifier__max_iter\": [500],\n",
    "}\n",
    "\n",
    "hyper_param_2_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f92b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_grid_search_2_bis_cv = GridSearchCV(estimator = clf, param_grid=hyper_param_2_bis, scoring=\"accuracy\",\n",
    "                           cv = KFold(n_splits=5, shuffle=True, random_state=1), n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9739cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathisdasilva/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/mathisdasilva/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['occ_code_level2',\n",
       "                                                                          'age',\n",
       "                                                                          'stock_dividends',\n",
       "                                                                          'wage_per_hour',\n",
       "                                                                          'capital_losses',\n",
       "                                                                          'own_or_self',\n",
       "                                                                          'ind_code_level2',\n",
       "                                                                          'capital_gains',\n",
       "                                                                          'week...\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__activation': ['relu'],\n",
       "                         'classifier__alpha': [0.05, 0.07, 0.1, 0.15],\n",
       "                         'classifier__hidden_layer_sizes': [(9, 6), (4, 7),\n",
       "                                                            (8, 7), (8, 5),\n",
       "                                                            (5, 4), (9, 2),\n",
       "                                                            (7, 4), (5, 9),\n",
       "                                                            (9, 5), (8, 2),\n",
       "                                                            (6, 4), (8, 9),\n",
       "                                                            (4, 4), (7, 5)],\n",
       "                         'classifier__learning_rate': ['adaptive'],\n",
       "                         'classifier__max_iter': [500],\n",
       "                         'classifier__solver': ['adam', 'sgd']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search_2_bis_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "756da314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__activation</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__hidden_layer_sizes</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>48.224739</td>\n",
       "      <td>10.300063</td>\n",
       "      <td>0.089994</td>\n",
       "      <td>0.008707</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864494</td>\n",
       "      <td>0.864585</td>\n",
       "      <td>0.862558</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.862435</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43.324375</td>\n",
       "      <td>3.821641</td>\n",
       "      <td>0.094835</td>\n",
       "      <td>0.015218</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.861551</td>\n",
       "      <td>0.862009</td>\n",
       "      <td>0.861917</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>45.631303</td>\n",
       "      <td>4.516217</td>\n",
       "      <td>0.090557</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.863761</td>\n",
       "      <td>0.861460</td>\n",
       "      <td>0.861368</td>\n",
       "      <td>0.861643</td>\n",
       "      <td>0.862160</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>57.769066</td>\n",
       "      <td>9.106674</td>\n",
       "      <td>0.094443</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.862192</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.862009</td>\n",
       "      <td>0.862087</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>61.525934</td>\n",
       "      <td>8.427042</td>\n",
       "      <td>0.086840</td>\n",
       "      <td>0.010787</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865043</td>\n",
       "      <td>0.862846</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.861460</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.861977</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>45.414496</td>\n",
       "      <td>4.205337</td>\n",
       "      <td>0.087752</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.863670</td>\n",
       "      <td>0.860819</td>\n",
       "      <td>0.861276</td>\n",
       "      <td>0.861368</td>\n",
       "      <td>0.861941</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>58.092817</td>\n",
       "      <td>6.151161</td>\n",
       "      <td>0.088214</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864311</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.861734</td>\n",
       "      <td>0.862009</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.861941</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>44.565576</td>\n",
       "      <td>4.401295</td>\n",
       "      <td>0.098359</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.863120</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.861093</td>\n",
       "      <td>0.861368</td>\n",
       "      <td>0.861849</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>55.821003</td>\n",
       "      <td>7.258525</td>\n",
       "      <td>0.084959</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.862284</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.861813</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>14.232385</td>\n",
       "      <td>3.849240</td>\n",
       "      <td>0.083856</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863761</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.861643</td>\n",
       "      <td>0.861460</td>\n",
       "      <td>0.862375</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>51.765707</td>\n",
       "      <td>4.061901</td>\n",
       "      <td>0.086669</td>\n",
       "      <td>0.010524</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865043</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.860819</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.861739</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>55.266781</td>\n",
       "      <td>6.945655</td>\n",
       "      <td>0.090272</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864402</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.861643</td>\n",
       "      <td>0.861551</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.861703</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>55.173573</td>\n",
       "      <td>7.794404</td>\n",
       "      <td>0.090709</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864036</td>\n",
       "      <td>0.861381</td>\n",
       "      <td>0.862925</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.860178</td>\n",
       "      <td>0.861629</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>33.206001</td>\n",
       "      <td>6.538495</td>\n",
       "      <td>0.089536</td>\n",
       "      <td>0.014484</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864036</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.860635</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.861574</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>42.450972</td>\n",
       "      <td>4.528418</td>\n",
       "      <td>0.081269</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.862558</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.861574</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>23.896105</td>\n",
       "      <td>3.810573</td>\n",
       "      <td>0.095188</td>\n",
       "      <td>0.018649</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.867973</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.861574</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>35.739260</td>\n",
       "      <td>2.658329</td>\n",
       "      <td>0.089315</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.860740</td>\n",
       "      <td>0.860819</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.861643</td>\n",
       "      <td>0.861428</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>34.418846</td>\n",
       "      <td>3.857186</td>\n",
       "      <td>0.087669</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.860910</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.861391</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>19.012197</td>\n",
       "      <td>4.352049</td>\n",
       "      <td>0.107691</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.864494</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.860910</td>\n",
       "      <td>0.861355</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>43.430043</td>\n",
       "      <td>4.778187</td>\n",
       "      <td>0.094807</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.864036</td>\n",
       "      <td>0.862101</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.861336</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>37.335153</td>\n",
       "      <td>9.580024</td>\n",
       "      <td>0.094497</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863853</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.861734</td>\n",
       "      <td>0.861190</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>15.976844</td>\n",
       "      <td>5.460293</td>\n",
       "      <td>0.086701</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.861153</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22.907213</td>\n",
       "      <td>3.300409</td>\n",
       "      <td>0.094556</td>\n",
       "      <td>0.028355</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864311</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.861093</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.861117</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32.671436</td>\n",
       "      <td>5.470251</td>\n",
       "      <td>0.092043</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863853</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.860178</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.861460</td>\n",
       "      <td>0.861098</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>27.014659</td>\n",
       "      <td>7.984976</td>\n",
       "      <td>0.088752</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863761</td>\n",
       "      <td>0.862113</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.861460</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.861062</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>43.051634</td>\n",
       "      <td>5.170196</td>\n",
       "      <td>0.100133</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.861381</td>\n",
       "      <td>0.862192</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.861025</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>34.770198</td>\n",
       "      <td>4.971093</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.861381</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.861007</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>15.444904</td>\n",
       "      <td>2.989725</td>\n",
       "      <td>0.093772</td>\n",
       "      <td>0.029537</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863670</td>\n",
       "      <td>0.864768</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.861007</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>19.394796</td>\n",
       "      <td>4.553185</td>\n",
       "      <td>0.098219</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.861276</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.860915</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>36.243047</td>\n",
       "      <td>7.955717</td>\n",
       "      <td>0.093526</td>\n",
       "      <td>0.012472</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.863303</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.860915</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>24.192707</td>\n",
       "      <td>3.087743</td>\n",
       "      <td>0.097393</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863853</td>\n",
       "      <td>0.865318</td>\n",
       "      <td>0.856973</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.860879</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>42.105501</td>\n",
       "      <td>7.788965</td>\n",
       "      <td>0.096457</td>\n",
       "      <td>0.007852</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.861093</td>\n",
       "      <td>0.860860</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>33.973806</td>\n",
       "      <td>4.080074</td>\n",
       "      <td>0.102496</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.861734</td>\n",
       "      <td>0.860842</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>18.912283</td>\n",
       "      <td>5.053798</td>\n",
       "      <td>0.102365</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.864219</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.860842</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>18.049946</td>\n",
       "      <td>2.728313</td>\n",
       "      <td>0.094853</td>\n",
       "      <td>0.009922</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.860805</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.282031</td>\n",
       "      <td>4.069968</td>\n",
       "      <td>0.094044</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862846</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.860787</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>16.783587</td>\n",
       "      <td>2.460190</td>\n",
       "      <td>0.095468</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.860769</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>37.847371</td>\n",
       "      <td>9.285119</td>\n",
       "      <td>0.085309</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.862937</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.860910</td>\n",
       "      <td>0.860732</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>39.247286</td>\n",
       "      <td>3.449764</td>\n",
       "      <td>0.102837</td>\n",
       "      <td>0.009063</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.860831</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.861002</td>\n",
       "      <td>0.860695</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>62.295155</td>\n",
       "      <td>6.256912</td>\n",
       "      <td>0.091371</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.860677</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14.500244</td>\n",
       "      <td>3.368943</td>\n",
       "      <td>0.091624</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.862113</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.860635</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.860659</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>15.515101</td>\n",
       "      <td>2.740052</td>\n",
       "      <td>0.090664</td>\n",
       "      <td>0.007413</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.860640</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>23.852378</td>\n",
       "      <td>6.803305</td>\n",
       "      <td>0.090963</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.864402</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.860586</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>56.811876</td>\n",
       "      <td>9.121085</td>\n",
       "      <td>0.096001</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.860567</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20.692949</td>\n",
       "      <td>5.508919</td>\n",
       "      <td>0.094171</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>30.890603</td>\n",
       "      <td>5.604667</td>\n",
       "      <td>0.083710</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.860819</td>\n",
       "      <td>0.860457</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>58.720219</td>\n",
       "      <td>16.618369</td>\n",
       "      <td>0.100896</td>\n",
       "      <td>0.019446</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864768</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.860457</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>15.676047</td>\n",
       "      <td>3.044182</td>\n",
       "      <td>0.090380</td>\n",
       "      <td>0.011363</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.861002</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.860384</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.088182</td>\n",
       "      <td>1.581017</td>\n",
       "      <td>0.095697</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.864585</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.860366</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>53.967949</td>\n",
       "      <td>9.350553</td>\n",
       "      <td>0.093606</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.860329</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>38.887838</td>\n",
       "      <td>3.934977</td>\n",
       "      <td>0.087525</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865043</td>\n",
       "      <td>0.862937</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>0.860311</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>39.009651</td>\n",
       "      <td>2.716497</td>\n",
       "      <td>0.094960</td>\n",
       "      <td>0.024739</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864768</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.860292</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>52.114778</td>\n",
       "      <td>12.320773</td>\n",
       "      <td>0.090766</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.860274</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.811211</td>\n",
       "      <td>5.879062</td>\n",
       "      <td>0.094439</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.860256</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20.465358</td>\n",
       "      <td>5.608537</td>\n",
       "      <td>0.100354</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.861093</td>\n",
       "      <td>0.860256</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>24.016541</td>\n",
       "      <td>6.635008</td>\n",
       "      <td>0.092742</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.865318</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.860256</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>17.057352</td>\n",
       "      <td>4.247100</td>\n",
       "      <td>0.092108</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.860238</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25.556299</td>\n",
       "      <td>3.081565</td>\n",
       "      <td>0.093923</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865409</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.860238</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.897376</td>\n",
       "      <td>3.989432</td>\n",
       "      <td>0.092302</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.860219</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>40.931929</td>\n",
       "      <td>2.719083</td>\n",
       "      <td>0.090961</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.860201</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.374248</td>\n",
       "      <td>4.060170</td>\n",
       "      <td>0.094970</td>\n",
       "      <td>0.011970</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864677</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.860201</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>21.748613</td>\n",
       "      <td>4.553638</td>\n",
       "      <td>0.109873</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863670</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.856973</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.860183</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>52.422155</td>\n",
       "      <td>8.074858</td>\n",
       "      <td>0.089415</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.860146</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1280.476164</td>\n",
       "      <td>2.847890</td>\n",
       "      <td>0.083826</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.864036</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.860146</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>49.610481</td>\n",
       "      <td>13.019717</td>\n",
       "      <td>0.100733</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.861198</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.860128</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.099401</td>\n",
       "      <td>4.264735</td>\n",
       "      <td>0.088709</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.861381</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.860128</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>22.029776</td>\n",
       "      <td>6.655652</td>\n",
       "      <td>0.093936</td>\n",
       "      <td>0.011815</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.861198</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.860109</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>21.489764</td>\n",
       "      <td>4.418258</td>\n",
       "      <td>0.100059</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.864585</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.860109</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.724587</td>\n",
       "      <td>1.663784</td>\n",
       "      <td>0.084062</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.860269</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.860091</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.403246</td>\n",
       "      <td>16.784792</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.019697</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.860054</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.199292</td>\n",
       "      <td>3.553345</td>\n",
       "      <td>0.095918</td>\n",
       "      <td>0.008709</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863761</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.860036</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>18.438753</td>\n",
       "      <td>2.943687</td>\n",
       "      <td>0.103589</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865501</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.860036</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>15.510002</td>\n",
       "      <td>2.699347</td>\n",
       "      <td>0.095794</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862937</td>\n",
       "      <td>0.859458</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.861826</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>35.569580</td>\n",
       "      <td>8.615361</td>\n",
       "      <td>0.094507</td>\n",
       "      <td>0.013787</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861838</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.861917</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>23.618040</td>\n",
       "      <td>4.896386</td>\n",
       "      <td>0.109593</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.864494</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15.997369</td>\n",
       "      <td>2.822076</td>\n",
       "      <td>0.092121</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.859926</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>11.206103</td>\n",
       "      <td>3.197351</td>\n",
       "      <td>0.087140</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.859908</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>36.200621</td>\n",
       "      <td>7.764146</td>\n",
       "      <td>0.093081</td>\n",
       "      <td>0.017650</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.861093</td>\n",
       "      <td>0.859890</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>33.520692</td>\n",
       "      <td>5.930097</td>\n",
       "      <td>0.084886</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860557</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.861002</td>\n",
       "      <td>0.859890</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>17.961828</td>\n",
       "      <td>4.446891</td>\n",
       "      <td>0.107020</td>\n",
       "      <td>0.016184</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863761</td>\n",
       "      <td>0.862113</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.859853</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>20.599356</td>\n",
       "      <td>5.688892</td>\n",
       "      <td>0.085912</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860648</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.859835</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19.491941</td>\n",
       "      <td>4.230904</td>\n",
       "      <td>0.093453</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.859835</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>20.336893</td>\n",
       "      <td>3.221090</td>\n",
       "      <td>0.105906</td>\n",
       "      <td>0.021268</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.859816</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16.337458</td>\n",
       "      <td>3.154843</td>\n",
       "      <td>0.092470</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.859798</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>19.101154</td>\n",
       "      <td>4.881093</td>\n",
       "      <td>0.089001</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862113</td>\n",
       "      <td>0.862113</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.859743</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>21.372049</td>\n",
       "      <td>5.444252</td>\n",
       "      <td>0.089134</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863120</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.859707</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>15.558688</td>\n",
       "      <td>4.006007</td>\n",
       "      <td>0.097557</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.860648</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.859688</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>14.649730</td>\n",
       "      <td>1.407420</td>\n",
       "      <td>0.090736</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.861826</td>\n",
       "      <td>0.853951</td>\n",
       "      <td>0.859652</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>21.238442</td>\n",
       "      <td>3.911861</td>\n",
       "      <td>0.086967</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861838</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.859633</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>18.901875</td>\n",
       "      <td>3.702895</td>\n",
       "      <td>0.089826</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.859458</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.859597</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>19.765153</td>\n",
       "      <td>2.319390</td>\n",
       "      <td>0.095298</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865226</td>\n",
       "      <td>0.860557</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.859560</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>15.401656</td>\n",
       "      <td>3.990246</td>\n",
       "      <td>0.087997</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.859414</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>17.102467</td>\n",
       "      <td>4.009645</td>\n",
       "      <td>0.096666</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862113</td>\n",
       "      <td>0.859092</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.859377</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>35.763989</td>\n",
       "      <td>10.301523</td>\n",
       "      <td>0.088338</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.860831</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.861093</td>\n",
       "      <td>0.859359</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.695105</td>\n",
       "      <td>3.636555</td>\n",
       "      <td>0.098428</td>\n",
       "      <td>0.012070</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.859285</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>37.171500</td>\n",
       "      <td>3.005767</td>\n",
       "      <td>0.087072</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860374</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.859176</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>34.971404</td>\n",
       "      <td>11.414152</td>\n",
       "      <td>0.095643</td>\n",
       "      <td>0.007478</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.859029</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>37.242400</td>\n",
       "      <td>12.072190</td>\n",
       "      <td>0.086698</td>\n",
       "      <td>0.010715</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.861838</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.858992</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33.637327</td>\n",
       "      <td>8.625462</td>\n",
       "      <td>0.085954</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861198</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.858901</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.858945</td>\n",
       "      <td>4.559271</td>\n",
       "      <td>0.089345</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>0.860374</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.858828</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>29.565314</td>\n",
       "      <td>3.784334</td>\n",
       "      <td>0.104037</td>\n",
       "      <td>0.009825</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.858828</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>30.924718</td>\n",
       "      <td>3.988641</td>\n",
       "      <td>0.084626</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859916</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.858809</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>15.835518</td>\n",
       "      <td>2.806821</td>\n",
       "      <td>0.095820</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.858542</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.858736</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.111192</td>\n",
       "      <td>5.113399</td>\n",
       "      <td>0.111778</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.857169</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.858644</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>38.262459</td>\n",
       "      <td>15.255896</td>\n",
       "      <td>0.093066</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861381</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.858535</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>14.991407</td>\n",
       "      <td>4.478562</td>\n",
       "      <td>0.097397</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858726</td>\n",
       "      <td>0.859183</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>0.862284</td>\n",
       "      <td>0.855325</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21.706900</td>\n",
       "      <td>4.435984</td>\n",
       "      <td>0.090567</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.857535</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.858058</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>22.347596</td>\n",
       "      <td>2.312549</td>\n",
       "      <td>0.091906</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860740</td>\n",
       "      <td>0.858542</td>\n",
       "      <td>0.854501</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.858003</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>771.016709</td>\n",
       "      <td>609.229337</td>\n",
       "      <td>0.094473</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.858176</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.857894</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>23.797740</td>\n",
       "      <td>3.638876</td>\n",
       "      <td>0.089959</td>\n",
       "      <td>0.010865</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860557</td>\n",
       "      <td>0.858726</td>\n",
       "      <td>0.854501</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.857857</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>22.624022</td>\n",
       "      <td>2.181341</td>\n",
       "      <td>0.095328</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860374</td>\n",
       "      <td>0.858359</td>\n",
       "      <td>0.854592</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.856973</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20.861293</td>\n",
       "      <td>0.794856</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>0.858451</td>\n",
       "      <td>0.854592</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.857674</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "75       48.224739     10.300063         0.089994        0.008707   \n",
       "7        43.324375      3.821641         0.094835        0.015218   \n",
       "35       45.631303      4.516217         0.090557        0.004387   \n",
       "47       57.769066      9.106674         0.094443        0.006186   \n",
       "67       61.525934      8.427042         0.086840        0.010787   \n",
       "91       45.414496      4.205337         0.087752        0.009657   \n",
       "11       58.092817      6.151161         0.088214        0.006990   \n",
       "63       44.565576      4.401295         0.098359        0.006002   \n",
       "19       55.821003      7.258525         0.084959        0.004683   \n",
       "88       14.232385      3.849240         0.083856        0.005873   \n",
       "95       51.765707      4.061901         0.086669        0.010524   \n",
       "39       55.266781      6.945655         0.090272        0.005901   \n",
       "103      55.173573      7.794404         0.090709        0.008436   \n",
       "71       33.206001      6.538495         0.089536        0.014484   \n",
       "83       42.450972      4.528418         0.081269        0.002615   \n",
       "84       23.896105      3.810573         0.095188        0.018649   \n",
       "43       35.739260      2.658329         0.089315        0.005978   \n",
       "99       34.418846      3.857186         0.087669        0.008576   \n",
       "102      19.012197      4.352049         0.107691        0.009336   \n",
       "27       43.430043      4.778187         0.094807        0.011718   \n",
       "51       37.335153      9.580024         0.094497        0.010727   \n",
       "110      15.976844      5.460293         0.086701        0.008236   \n",
       "28       22.907213      3.300409         0.094556        0.028355   \n",
       "15       32.671436      5.470251         0.092043        0.006558   \n",
       "56       27.014659      7.984976         0.088752        0.002789   \n",
       "55       43.051634      5.170196         0.100133        0.020040   \n",
       "111      34.770198      4.971093         0.070469        0.002454   \n",
       "106      15.444904      2.989725         0.093772        0.029537   \n",
       "74       19.394796      4.553185         0.098219        0.011577   \n",
       "23       36.243047      7.955717         0.093526        0.012472   \n",
       "34       24.192707      3.087743         0.097393        0.006324   \n",
       "107      42.105501      7.788965         0.096457        0.007852   \n",
       "87       33.973806      4.080074         0.102496        0.011275   \n",
       "82       18.912283      5.053798         0.102365        0.025002   \n",
       "96       18.049946      2.728313         0.094853        0.009922   \n",
       "3        29.282031      4.069968         0.094044        0.015133   \n",
       "90       16.783587      2.460190         0.095468        0.003472   \n",
       "79       37.847371      9.285119         0.085309        0.006511   \n",
       "31       39.247286      3.449764         0.102837        0.009063   \n",
       "17       62.295155      6.256912         0.091371        0.003848   \n",
       "30       14.500244      3.368943         0.091624        0.002742   \n",
       "100      15.515101      2.740052         0.090664        0.007413   \n",
       "32       23.852378      6.803305         0.090963        0.009228   \n",
       "45       56.811876      9.121085         0.096001        0.004311   \n",
       "48       20.692949      5.508919         0.094171        0.011893   \n",
       "59       30.890603      5.604667         0.083710        0.010827   \n",
       "101      58.720219     16.618369         0.100896        0.019446   \n",
       "78       15.676047      3.044182         0.090380        0.011363   \n",
       "6        23.088182      1.581017         0.095697        0.007723   \n",
       "85       53.967949      9.350553         0.093606        0.005286   \n",
       "65       38.887838      3.934977         0.087525        0.006428   \n",
       "37       39.009651      2.716497         0.094960        0.024739   \n",
       "29       52.114778     12.320773         0.090766        0.007241   \n",
       "46       19.811211      5.879062         0.094439        0.011551   \n",
       "36       20.465358      5.608537         0.100354        0.016665   \n",
       "38       24.016541      6.635008         0.092742        0.006001   \n",
       "104      17.057352      4.247100         0.092108        0.010841   \n",
       "12       25.556299      3.081565         0.093923        0.007601   \n",
       "2        15.897376      3.989432         0.092302        0.009551   \n",
       "93       40.931929      2.719083         0.090961        0.007083   \n",
       "8        18.374248      4.060170         0.094970        0.011970   \n",
       "40       21.748613      4.553638         0.109873        0.007032   \n",
       "73       52.422155      8.074858         0.089415        0.008165   \n",
       "9      1280.476164      2.847890         0.083826        0.008210   \n",
       "57       49.610481     13.019717         0.100733        0.021472   \n",
       "14       20.099401      4.264735         0.088709        0.005755   \n",
       "76       22.029776      6.655652         0.093936        0.011815   \n",
       "44       21.489764      4.418258         0.100059        0.013158   \n",
       "18       19.724587      1.663784         0.084062        0.006446   \n",
       "1        56.403246     16.784792         0.120643        0.019697   \n",
       "20       20.199292      3.553345         0.095918        0.008709   \n",
       "50       18.438753      2.943687         0.103589        0.009608   \n",
       "52       15.510002      2.699347         0.095794        0.018547   \n",
       "77       35.569580      8.615361         0.094507        0.013787   \n",
       "54       23.618040      4.896386         0.109593        0.024412   \n",
       "24       15.997369      2.822076         0.092121        0.005069   \n",
       "98       11.206103      3.197351         0.087140        0.007588   \n",
       "49       36.200621      7.764146         0.093081        0.017650   \n",
       "21       33.520692      5.930097         0.084886        0.005123   \n",
       "58       17.961828      4.446891         0.107020        0.016184   \n",
       "72       20.599356      5.688892         0.085912        0.005583   \n",
       "26       19.491941      4.230904         0.093453        0.010881   \n",
       "94       20.336893      3.221090         0.105906        0.021268   \n",
       "22       16.337458      3.154843         0.092470        0.006175   \n",
       "64       19.101154      4.881093         0.089001        0.003021   \n",
       "62       21.372049      5.444252         0.089134        0.007524   \n",
       "42       15.558688      4.006007         0.097557        0.009959   \n",
       "80       14.649730      1.407420         0.090736        0.006681   \n",
       "66       21.238442      3.911861         0.086967        0.006510   \n",
       "92       18.901875      3.702895         0.089826        0.007520   \n",
       "68       19.765153      2.319390         0.095298        0.013708   \n",
       "70       15.401656      3.990246         0.087997        0.006749   \n",
       "60       17.102467      4.009645         0.096666        0.003866   \n",
       "105      35.763989     10.301523         0.088338        0.008168   \n",
       "4        22.695105      3.636555         0.098428        0.012070   \n",
       "89       37.171500      3.005767         0.087072        0.009460   \n",
       "41       34.971404     11.414152         0.095643        0.007478   \n",
       "97       37.242400     12.072190         0.086698        0.010715   \n",
       "13       33.637327      8.625462         0.085954        0.007450   \n",
       "5        28.858945      4.559271         0.089345        0.007092   \n",
       "33       29.565314      3.784334         0.104037        0.009825   \n",
       "61       30.924718      3.988641         0.084626        0.007540   \n",
       "86       15.835518      2.806821         0.095820        0.005679   \n",
       "0        26.111192      5.113399         0.111778        0.002114   \n",
       "69       38.262459     15.255896         0.093066        0.005472   \n",
       "108      14.991407      4.478562         0.097397        0.017525   \n",
       "16       21.706900      4.435984         0.090567        0.003420   \n",
       "81       22.347596      2.312549         0.091906        0.011566   \n",
       "10      771.016709    609.229337         0.094473        0.013220   \n",
       "109      23.797740      3.638876         0.089959        0.010865   \n",
       "53       22.624022      2.181341         0.095328        0.009380   \n",
       "25       20.861293      0.794856         0.101695        0.004924   \n",
       "\n",
       "    param_classifier__activation param_classifier__alpha  \\\n",
       "75                          relu                     0.1   \n",
       "7                           relu                    0.05   \n",
       "35                          relu                    0.07   \n",
       "47                          relu                    0.07   \n",
       "67                          relu                     0.1   \n",
       "91                          relu                    0.15   \n",
       "11                          relu                    0.05   \n",
       "63                          relu                     0.1   \n",
       "19                          relu                    0.05   \n",
       "88                          relu                    0.15   \n",
       "95                          relu                    0.15   \n",
       "39                          relu                    0.07   \n",
       "103                         relu                    0.15   \n",
       "71                          relu                     0.1   \n",
       "83                          relu                     0.1   \n",
       "84                          relu                    0.15   \n",
       "43                          relu                    0.07   \n",
       "99                          relu                    0.15   \n",
       "102                         relu                    0.15   \n",
       "27                          relu                    0.05   \n",
       "51                          relu                    0.07   \n",
       "110                         relu                    0.15   \n",
       "28                          relu                    0.07   \n",
       "15                          relu                    0.05   \n",
       "56                          relu                     0.1   \n",
       "55                          relu                    0.07   \n",
       "111                         relu                    0.15   \n",
       "106                         relu                    0.15   \n",
       "74                          relu                     0.1   \n",
       "23                          relu                    0.05   \n",
       "34                          relu                    0.07   \n",
       "107                         relu                    0.15   \n",
       "87                          relu                    0.15   \n",
       "82                          relu                     0.1   \n",
       "96                          relu                    0.15   \n",
       "3                           relu                    0.05   \n",
       "90                          relu                    0.15   \n",
       "79                          relu                     0.1   \n",
       "31                          relu                    0.07   \n",
       "17                          relu                    0.05   \n",
       "30                          relu                    0.07   \n",
       "100                         relu                    0.15   \n",
       "32                          relu                    0.07   \n",
       "45                          relu                    0.07   \n",
       "48                          relu                    0.07   \n",
       "59                          relu                     0.1   \n",
       "101                         relu                    0.15   \n",
       "78                          relu                     0.1   \n",
       "6                           relu                    0.05   \n",
       "85                          relu                    0.15   \n",
       "65                          relu                     0.1   \n",
       "37                          relu                    0.07   \n",
       "29                          relu                    0.07   \n",
       "46                          relu                    0.07   \n",
       "36                          relu                    0.07   \n",
       "38                          relu                    0.07   \n",
       "104                         relu                    0.15   \n",
       "12                          relu                    0.05   \n",
       "2                           relu                    0.05   \n",
       "93                          relu                    0.15   \n",
       "8                           relu                    0.05   \n",
       "40                          relu                    0.07   \n",
       "73                          relu                     0.1   \n",
       "9                           relu                    0.05   \n",
       "57                          relu                     0.1   \n",
       "14                          relu                    0.05   \n",
       "76                          relu                     0.1   \n",
       "44                          relu                    0.07   \n",
       "18                          relu                    0.05   \n",
       "1                           relu                    0.05   \n",
       "20                          relu                    0.05   \n",
       "50                          relu                    0.07   \n",
       "52                          relu                    0.07   \n",
       "77                          relu                     0.1   \n",
       "54                          relu                    0.07   \n",
       "24                          relu                    0.05   \n",
       "98                          relu                    0.15   \n",
       "49                          relu                    0.07   \n",
       "21                          relu                    0.05   \n",
       "58                          relu                     0.1   \n",
       "72                          relu                     0.1   \n",
       "26                          relu                    0.05   \n",
       "94                          relu                    0.15   \n",
       "22                          relu                    0.05   \n",
       "64                          relu                     0.1   \n",
       "62                          relu                     0.1   \n",
       "42                          relu                    0.07   \n",
       "80                          relu                     0.1   \n",
       "66                          relu                     0.1   \n",
       "92                          relu                    0.15   \n",
       "68                          relu                     0.1   \n",
       "70                          relu                     0.1   \n",
       "60                          relu                     0.1   \n",
       "105                         relu                    0.15   \n",
       "4                           relu                    0.05   \n",
       "89                          relu                    0.15   \n",
       "41                          relu                    0.07   \n",
       "97                          relu                    0.15   \n",
       "13                          relu                    0.05   \n",
       "5                           relu                    0.05   \n",
       "33                          relu                    0.07   \n",
       "61                          relu                     0.1   \n",
       "86                          relu                    0.15   \n",
       "0                           relu                    0.05   \n",
       "69                          relu                     0.1   \n",
       "108                         relu                    0.15   \n",
       "16                          relu                    0.05   \n",
       "81                          relu                     0.1   \n",
       "10                          relu                    0.05   \n",
       "109                         relu                    0.15   \n",
       "53                          relu                    0.07   \n",
       "25                          relu                    0.05   \n",
       "\n",
       "    param_classifier__hidden_layer_sizes param_classifier__learning_rate  \\\n",
       "75                                (8, 2)                        adaptive   \n",
       "7                                 (8, 5)                        adaptive   \n",
       "35                                (8, 5)                        adaptive   \n",
       "47                                (8, 2)                        adaptive   \n",
       "67                                (9, 2)                        adaptive   \n",
       "91                                (8, 5)                        adaptive   \n",
       "11                                (9, 2)                        adaptive   \n",
       "63                                (8, 5)                        adaptive   \n",
       "19                                (8, 2)                        adaptive   \n",
       "88                                (8, 7)                        adaptive   \n",
       "95                                (9, 2)                        adaptive   \n",
       "39                                (9, 2)                        adaptive   \n",
       "103                               (8, 2)                        adaptive   \n",
       "71                                (5, 9)                        adaptive   \n",
       "83                                (7, 5)                        adaptive   \n",
       "84                                (9, 6)                        adaptive   \n",
       "43                                (5, 9)                        adaptive   \n",
       "99                                (5, 9)                        adaptive   \n",
       "102                               (8, 2)                        adaptive   \n",
       "27                                (7, 5)                        adaptive   \n",
       "51                                (8, 9)                        adaptive   \n",
       "110                               (7, 5)                        adaptive   \n",
       "28                                (9, 6)                        adaptive   \n",
       "15                                (5, 9)                        adaptive   \n",
       "56                                (9, 6)                        adaptive   \n",
       "55                                (7, 5)                        adaptive   \n",
       "111                               (7, 5)                        adaptive   \n",
       "106                               (8, 9)                        adaptive   \n",
       "74                                (8, 2)                        adaptive   \n",
       "23                                (8, 9)                        adaptive   \n",
       "34                                (8, 5)                        adaptive   \n",
       "107                               (8, 9)                        adaptive   \n",
       "87                                (4, 7)                        adaptive   \n",
       "82                                (7, 5)                        adaptive   \n",
       "96                                (7, 4)                        adaptive   \n",
       "3                                 (4, 7)                        adaptive   \n",
       "90                                (8, 5)                        adaptive   \n",
       "79                                (8, 9)                        adaptive   \n",
       "31                                (4, 7)                        adaptive   \n",
       "17                                (9, 5)                        adaptive   \n",
       "30                                (4, 7)                        adaptive   \n",
       "100                               (9, 5)                        adaptive   \n",
       "32                                (8, 7)                        adaptive   \n",
       "45                                (9, 5)                        adaptive   \n",
       "48                                (6, 4)                        adaptive   \n",
       "59                                (4, 7)                        adaptive   \n",
       "101                               (9, 5)                        adaptive   \n",
       "78                                (8, 9)                        adaptive   \n",
       "6                                 (8, 5)                        adaptive   \n",
       "85                                (9, 6)                        adaptive   \n",
       "65                                (5, 4)                        adaptive   \n",
       "37                                (5, 4)                        adaptive   \n",
       "29                                (9, 6)                        adaptive   \n",
       "46                                (8, 2)                        adaptive   \n",
       "36                                (5, 4)                        adaptive   \n",
       "38                                (9, 2)                        adaptive   \n",
       "104                               (6, 4)                        adaptive   \n",
       "12                                (7, 4)                        adaptive   \n",
       "2                                 (4, 7)                        adaptive   \n",
       "93                                (5, 4)                        adaptive   \n",
       "8                                 (5, 4)                        adaptive   \n",
       "40                                (7, 4)                        adaptive   \n",
       "73                                (9, 5)                        adaptive   \n",
       "9                                 (5, 4)                        adaptive   \n",
       "57                                (9, 6)                        adaptive   \n",
       "14                                (5, 9)                        adaptive   \n",
       "76                                (6, 4)                        adaptive   \n",
       "44                                (9, 5)                        adaptive   \n",
       "18                                (8, 2)                        adaptive   \n",
       "1                                 (9, 6)                        adaptive   \n",
       "20                                (6, 4)                        adaptive   \n",
       "50                                (8, 9)                        adaptive   \n",
       "52                                (4, 4)                        adaptive   \n",
       "77                                (6, 4)                        adaptive   \n",
       "54                                (7, 5)                        adaptive   \n",
       "24                                (4, 4)                        adaptive   \n",
       "98                                (5, 9)                        adaptive   \n",
       "49                                (6, 4)                        adaptive   \n",
       "21                                (6, 4)                        adaptive   \n",
       "58                                (4, 7)                        adaptive   \n",
       "72                                (9, 5)                        adaptive   \n",
       "26                                (7, 5)                        adaptive   \n",
       "94                                (9, 2)                        adaptive   \n",
       "22                                (8, 9)                        adaptive   \n",
       "64                                (5, 4)                        adaptive   \n",
       "62                                (8, 5)                        adaptive   \n",
       "42                                (5, 9)                        adaptive   \n",
       "80                                (4, 4)                        adaptive   \n",
       "66                                (9, 2)                        adaptive   \n",
       "92                                (5, 4)                        adaptive   \n",
       "68                                (7, 4)                        adaptive   \n",
       "70                                (5, 9)                        adaptive   \n",
       "60                                (8, 7)                        adaptive   \n",
       "105                               (6, 4)                        adaptive   \n",
       "4                                 (8, 7)                        adaptive   \n",
       "89                                (8, 7)                        adaptive   \n",
       "41                                (7, 4)                        adaptive   \n",
       "97                                (7, 4)                        adaptive   \n",
       "13                                (7, 4)                        adaptive   \n",
       "5                                 (8, 7)                        adaptive   \n",
       "33                                (8, 7)                        adaptive   \n",
       "61                                (8, 7)                        adaptive   \n",
       "86                                (4, 7)                        adaptive   \n",
       "0                                 (9, 6)                        adaptive   \n",
       "69                                (7, 4)                        adaptive   \n",
       "108                               (4, 4)                        adaptive   \n",
       "16                                (9, 5)                        adaptive   \n",
       "81                                (4, 4)                        adaptive   \n",
       "10                                (9, 2)                        adaptive   \n",
       "109                               (4, 4)                        adaptive   \n",
       "53                                (4, 4)                        adaptive   \n",
       "25                                (4, 4)                        adaptive   \n",
       "\n",
       "    param_classifier__max_iter param_classifier__solver  \\\n",
       "75                         500                      sgd   \n",
       "7                          500                      sgd   \n",
       "35                         500                      sgd   \n",
       "47                         500                      sgd   \n",
       "67                         500                      sgd   \n",
       "91                         500                      sgd   \n",
       "11                         500                      sgd   \n",
       "63                         500                      sgd   \n",
       "19                         500                      sgd   \n",
       "88                         500                     adam   \n",
       "95                         500                      sgd   \n",
       "39                         500                      sgd   \n",
       "103                        500                      sgd   \n",
       "71                         500                      sgd   \n",
       "83                         500                      sgd   \n",
       "84                         500                     adam   \n",
       "43                         500                      sgd   \n",
       "99                         500                      sgd   \n",
       "102                        500                     adam   \n",
       "27                         500                      sgd   \n",
       "51                         500                      sgd   \n",
       "110                        500                     adam   \n",
       "28                         500                     adam   \n",
       "15                         500                      sgd   \n",
       "56                         500                     adam   \n",
       "55                         500                      sgd   \n",
       "111                        500                      sgd   \n",
       "106                        500                     adam   \n",
       "74                         500                     adam   \n",
       "23                         500                      sgd   \n",
       "34                         500                     adam   \n",
       "107                        500                      sgd   \n",
       "87                         500                      sgd   \n",
       "82                         500                     adam   \n",
       "96                         500                     adam   \n",
       "3                          500                      sgd   \n",
       "90                         500                     adam   \n",
       "79                         500                      sgd   \n",
       "31                         500                      sgd   \n",
       "17                         500                      sgd   \n",
       "30                         500                     adam   \n",
       "100                        500                     adam   \n",
       "32                         500                     adam   \n",
       "45                         500                      sgd   \n",
       "48                         500                     adam   \n",
       "59                         500                      sgd   \n",
       "101                        500                      sgd   \n",
       "78                         500                     adam   \n",
       "6                          500                     adam   \n",
       "85                         500                      sgd   \n",
       "65                         500                      sgd   \n",
       "37                         500                      sgd   \n",
       "29                         500                      sgd   \n",
       "46                         500                     adam   \n",
       "36                         500                     adam   \n",
       "38                         500                     adam   \n",
       "104                        500                     adam   \n",
       "12                         500                     adam   \n",
       "2                          500                     adam   \n",
       "93                         500                      sgd   \n",
       "8                          500                     adam   \n",
       "40                         500                     adam   \n",
       "73                         500                      sgd   \n",
       "9                          500                      sgd   \n",
       "57                         500                      sgd   \n",
       "14                         500                     adam   \n",
       "76                         500                     adam   \n",
       "44                         500                     adam   \n",
       "18                         500                     adam   \n",
       "1                          500                      sgd   \n",
       "20                         500                     adam   \n",
       "50                         500                     adam   \n",
       "52                         500                     adam   \n",
       "77                         500                      sgd   \n",
       "54                         500                     adam   \n",
       "24                         500                     adam   \n",
       "98                         500                     adam   \n",
       "49                         500                      sgd   \n",
       "21                         500                      sgd   \n",
       "58                         500                     adam   \n",
       "72                         500                     adam   \n",
       "26                         500                     adam   \n",
       "94                         500                     adam   \n",
       "22                         500                     adam   \n",
       "64                         500                     adam   \n",
       "62                         500                     adam   \n",
       "42                         500                     adam   \n",
       "80                         500                     adam   \n",
       "66                         500                     adam   \n",
       "92                         500                     adam   \n",
       "68                         500                     adam   \n",
       "70                         500                     adam   \n",
       "60                         500                     adam   \n",
       "105                        500                      sgd   \n",
       "4                          500                     adam   \n",
       "89                         500                      sgd   \n",
       "41                         500                      sgd   \n",
       "97                         500                      sgd   \n",
       "13                         500                      sgd   \n",
       "5                          500                      sgd   \n",
       "33                         500                      sgd   \n",
       "61                         500                      sgd   \n",
       "86                         500                     adam   \n",
       "0                          500                     adam   \n",
       "69                         500                      sgd   \n",
       "108                        500                     adam   \n",
       "16                         500                     adam   \n",
       "81                         500                      sgd   \n",
       "10                         500                     adam   \n",
       "109                        500                      sgd   \n",
       "53                         500                      sgd   \n",
       "25                         500                      sgd   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "75   {'classifier__activation': 'relu', 'classifier...           0.864494   \n",
       "7    {'classifier__activation': 'relu', 'classifier...           0.861930   \n",
       "35   {'classifier__activation': 'relu', 'classifier...           0.862571   \n",
       "47   {'classifier__activation': 'relu', 'classifier...           0.863029   \n",
       "67   {'classifier__activation': 'relu', 'classifier...           0.865043   \n",
       "91   {'classifier__activation': 'relu', 'classifier...           0.862571   \n",
       "11   {'classifier__activation': 'relu', 'classifier...           0.864311   \n",
       "63   {'classifier__activation': 'relu', 'classifier...           0.862479   \n",
       "19   {'classifier__activation': 'relu', 'classifier...           0.862479   \n",
       "88   {'classifier__activation': 'relu', 'classifier...           0.863761   \n",
       "95   {'classifier__activation': 'relu', 'classifier...           0.865043   \n",
       "39   {'classifier__activation': 'relu', 'classifier...           0.864402   \n",
       "103  {'classifier__activation': 'relu', 'classifier...           0.864036   \n",
       "71   {'classifier__activation': 'relu', 'classifier...           0.864036   \n",
       "83   {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "84   {'classifier__activation': 'relu', 'classifier...           0.867973   \n",
       "43   {'classifier__activation': 'relu', 'classifier...           0.863395   \n",
       "99   {'classifier__activation': 'relu', 'classifier...           0.864127   \n",
       "102  {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "27   {'classifier__activation': 'relu', 'classifier...           0.863395   \n",
       "51   {'classifier__activation': 'relu', 'classifier...           0.863853   \n",
       "110  {'classifier__activation': 'relu', 'classifier...           0.863212   \n",
       "28   {'classifier__activation': 'relu', 'classifier...           0.864311   \n",
       "15   {'classifier__activation': 'relu', 'classifier...           0.863853   \n",
       "56   {'classifier__activation': 'relu', 'classifier...           0.863761   \n",
       "55   {'classifier__activation': 'relu', 'classifier...           0.863029   \n",
       "111  {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "106  {'classifier__activation': 'relu', 'classifier...           0.863670   \n",
       "74   {'classifier__activation': 'relu', 'classifier...           0.863395   \n",
       "23   {'classifier__activation': 'relu', 'classifier...           0.864127   \n",
       "34   {'classifier__activation': 'relu', 'classifier...           0.863853   \n",
       "107  {'classifier__activation': 'relu', 'classifier...           0.862296   \n",
       "87   {'classifier__activation': 'relu', 'classifier...           0.861747   \n",
       "82   {'classifier__activation': 'relu', 'classifier...           0.863029   \n",
       "96   {'classifier__activation': 'relu', 'classifier...           0.862388   \n",
       "3    {'classifier__activation': 'relu', 'classifier...           0.862846   \n",
       "90   {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "79   {'classifier__activation': 'relu', 'classifier...           0.863487   \n",
       "31   {'classifier__activation': 'relu', 'classifier...           0.862663   \n",
       "17   {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "30   {'classifier__activation': 'relu', 'classifier...           0.863395   \n",
       "100  {'classifier__activation': 'relu', 'classifier...           0.867515   \n",
       "32   {'classifier__activation': 'relu', 'classifier...           0.862296   \n",
       "45   {'classifier__activation': 'relu', 'classifier...           0.863212   \n",
       "48   {'classifier__activation': 'relu', 'classifier...           0.861655   \n",
       "59   {'classifier__activation': 'relu', 'classifier...           0.861564   \n",
       "101  {'classifier__activation': 'relu', 'classifier...           0.864768   \n",
       "78   {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "6    {'classifier__activation': 'relu', 'classifier...           0.862022   \n",
       "85   {'classifier__activation': 'relu', 'classifier...           0.862663   \n",
       "65   {'classifier__activation': 'relu', 'classifier...           0.865043   \n",
       "37   {'classifier__activation': 'relu', 'classifier...           0.864768   \n",
       "29   {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "46   {'classifier__activation': 'relu', 'classifier...           0.861930   \n",
       "36   {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "38   {'classifier__activation': 'relu', 'classifier...           0.861014   \n",
       "104  {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "12   {'classifier__activation': 'relu', 'classifier...           0.865409   \n",
       "2    {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "93   {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "8    {'classifier__activation': 'relu', 'classifier...           0.864677   \n",
       "40   {'classifier__activation': 'relu', 'classifier...           0.863670   \n",
       "73   {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "9    {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "57   {'classifier__activation': 'relu', 'classifier...           0.862388   \n",
       "14   {'classifier__activation': 'relu', 'classifier...           0.863029   \n",
       "76   {'classifier__activation': 'relu', 'classifier...           0.864127   \n",
       "44   {'classifier__activation': 'relu', 'classifier...           0.862022   \n",
       "18   {'classifier__activation': 'relu', 'classifier...           0.861930   \n",
       "1    {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "20   {'classifier__activation': 'relu', 'classifier...           0.863761   \n",
       "50   {'classifier__activation': 'relu', 'classifier...           0.865501   \n",
       "52   {'classifier__activation': 'relu', 'classifier...           0.862937   \n",
       "77   {'classifier__activation': 'relu', 'classifier...           0.861838   \n",
       "54   {'classifier__activation': 'relu', 'classifier...           0.862296   \n",
       "24   {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "98   {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "49   {'classifier__activation': 'relu', 'classifier...           0.860465   \n",
       "21   {'classifier__activation': 'relu', 'classifier...           0.860557   \n",
       "58   {'classifier__activation': 'relu', 'classifier...           0.863761   \n",
       "72   {'classifier__activation': 'relu', 'classifier...           0.860648   \n",
       "26   {'classifier__activation': 'relu', 'classifier...           0.861564   \n",
       "94   {'classifier__activation': 'relu', 'classifier...           0.862571   \n",
       "22   {'classifier__activation': 'relu', 'classifier...           0.863029   \n",
       "64   {'classifier__activation': 'relu', 'classifier...           0.862113   \n",
       "62   {'classifier__activation': 'relu', 'classifier...           0.863120   \n",
       "42   {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "80   {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "66   {'classifier__activation': 'relu', 'classifier...           0.861838   \n",
       "92   {'classifier__activation': 'relu', 'classifier...           0.862479   \n",
       "68   {'classifier__activation': 'relu', 'classifier...           0.865226   \n",
       "70   {'classifier__activation': 'relu', 'classifier...           0.862663   \n",
       "60   {'classifier__activation': 'relu', 'classifier...           0.862113   \n",
       "105  {'classifier__activation': 'relu', 'classifier...           0.861472   \n",
       "4    {'classifier__activation': 'relu', 'classifier...           0.860282   \n",
       "89   {'classifier__activation': 'relu', 'classifier...           0.860374   \n",
       "41   {'classifier__activation': 'relu', 'classifier...           0.861106   \n",
       "97   {'classifier__activation': 'relu', 'classifier...           0.861014   \n",
       "13   {'classifier__activation': 'relu', 'classifier...           0.861198   \n",
       "5    {'classifier__activation': 'relu', 'classifier...           0.860190   \n",
       "33   {'classifier__activation': 'relu', 'classifier...           0.860190   \n",
       "61   {'classifier__activation': 'relu', 'classifier...           0.859916   \n",
       "86   {'classifier__activation': 'relu', 'classifier...           0.862663   \n",
       "0    {'classifier__activation': 'relu', 'classifier...           0.862205   \n",
       "69   {'classifier__activation': 'relu', 'classifier...           0.861381   \n",
       "108  {'classifier__activation': 'relu', 'classifier...           0.858726   \n",
       "16   {'classifier__activation': 'relu', 'classifier...           0.857535   \n",
       "81   {'classifier__activation': 'relu', 'classifier...           0.860740   \n",
       "10   {'classifier__activation': 'relu', 'classifier...           0.861472   \n",
       "109  {'classifier__activation': 'relu', 'classifier...           0.860557   \n",
       "53   {'classifier__activation': 'relu', 'classifier...           0.860374   \n",
       "25   {'classifier__activation': 'relu', 'classifier...           0.860190   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "75            0.864585           0.862558           0.859354   \n",
       "7             0.863578           0.861551           0.862009   \n",
       "35            0.863761           0.861460           0.861368   \n",
       "47            0.863578           0.862192           0.859628   \n",
       "67            0.862846           0.860727           0.861460   \n",
       "91            0.863670           0.860819           0.861276   \n",
       "11            0.863487           0.861734           0.862009   \n",
       "63            0.863120           0.861185           0.861093   \n",
       "19            0.863578           0.862284           0.859995   \n",
       "88            0.859733           0.861643           0.861460   \n",
       "95            0.863487           0.861185           0.860819   \n",
       "39            0.862479           0.861643           0.861551   \n",
       "103           0.861381           0.862925           0.859628   \n",
       "71            0.861930           0.860635           0.860727   \n",
       "83            0.862479           0.862558           0.859262   \n",
       "84            0.862388           0.857888           0.860727   \n",
       "43            0.860740           0.860819           0.860544   \n",
       "99            0.862205           0.860910           0.859995   \n",
       "102           0.864494           0.858346           0.859079   \n",
       "27            0.864036           0.862101           0.858072   \n",
       "51            0.863212           0.859445           0.857705   \n",
       "110           0.863395           0.859903           0.859537   \n",
       "28            0.862388           0.860361           0.861093   \n",
       "15            0.861014           0.860178           0.858987   \n",
       "56            0.862113           0.859262           0.861460   \n",
       "55            0.861381           0.862192           0.858987   \n",
       "111           0.861381           0.861185           0.858896   \n",
       "106           0.864768           0.860544           0.857888   \n",
       "74            0.862388           0.857888           0.861276   \n",
       "23            0.863303           0.858804           0.857797   \n",
       "34            0.865318           0.856973           0.857797   \n",
       "107           0.862663           0.859628           0.858621   \n",
       "87            0.861655           0.859903           0.859170   \n",
       "82            0.864219           0.859995           0.858713   \n",
       "96            0.862663           0.859720           0.858896   \n",
       "3             0.861564           0.859903           0.859628   \n",
       "90            0.860465           0.860361           0.859628   \n",
       "79            0.862937           0.858438           0.857888   \n",
       "31            0.860831           0.859262           0.859720   \n",
       "17            0.863487           0.859903           0.859079   \n",
       "30            0.862113           0.858346           0.860635   \n",
       "100           0.863944           0.858072           0.857705   \n",
       "32            0.864402           0.858713           0.858346   \n",
       "45            0.863944           0.858621           0.859262   \n",
       "48            0.862205           0.859995           0.858987   \n",
       "59            0.861014           0.859354           0.859537   \n",
       "101           0.863487           0.857705           0.858987   \n",
       "78            0.862388           0.861002           0.857888   \n",
       "6             0.864585           0.857522           0.859537   \n",
       "85            0.861655           0.859079           0.859628   \n",
       "65            0.862937           0.857156           0.858438   \n",
       "37            0.863578           0.857064           0.857431   \n",
       "29            0.862663           0.857705           0.859445   \n",
       "46            0.861289           0.858713           0.858987   \n",
       "36            0.863212           0.855691           0.858529   \n",
       "38            0.865318           0.857248           0.859262   \n",
       "104           0.862479           0.856881           0.859720   \n",
       "12            0.862205           0.857888           0.856790   \n",
       "2             0.861289           0.858346           0.859445   \n",
       "93            0.863212           0.857156           0.858163   \n",
       "8             0.862663           0.855874           0.858621   \n",
       "40            0.862296           0.856973           0.859811   \n",
       "73            0.863029           0.857797           0.859262   \n",
       "9             0.864036           0.856881           0.857339   \n",
       "57            0.861198           0.859079           0.859354   \n",
       "14            0.861381           0.857980           0.859811   \n",
       "76            0.861198           0.857980           0.859445   \n",
       "44            0.864585           0.858621           0.859720   \n",
       "18            0.862296           0.858438           0.860269   \n",
       "1             0.862571           0.856240           0.859537   \n",
       "20            0.861106           0.857888           0.858163   \n",
       "50            0.861747           0.859170           0.856515   \n",
       "52            0.859458           0.857522           0.861826   \n",
       "77            0.861930           0.855782           0.858529   \n",
       "54            0.864494           0.856698           0.859628   \n",
       "24            0.861747           0.857156           0.860727   \n",
       "98            0.862205           0.857614           0.857522   \n",
       "49            0.861930           0.856607           0.859354   \n",
       "21            0.861930           0.857522           0.858438   \n",
       "58            0.862113           0.857797           0.858713   \n",
       "72            0.863487           0.858713           0.859720   \n",
       "26            0.863578           0.858987           0.857431   \n",
       "94            0.862754           0.858621           0.859354   \n",
       "22            0.862296           0.859354           0.856790   \n",
       "64            0.862113           0.855691           0.859079   \n",
       "62            0.860465           0.858163           0.859170   \n",
       "42            0.860648           0.856240           0.859811   \n",
       "80            0.862388           0.856515           0.861826   \n",
       "66            0.862022           0.857431           0.859262   \n",
       "92            0.859458           0.856240           0.859354   \n",
       "68            0.860557           0.856057           0.858346   \n",
       "70            0.862205           0.855141           0.857980   \n",
       "60            0.859092           0.858804           0.857339   \n",
       "105           0.860831           0.855508           0.857888   \n",
       "4             0.862022           0.857064           0.859720   \n",
       "89            0.860190           0.857339           0.860361   \n",
       "41            0.862296           0.856790           0.857522   \n",
       "97            0.861838           0.856515           0.857248   \n",
       "13            0.862205           0.856698           0.857339   \n",
       "5             0.860374           0.857797           0.858987   \n",
       "33            0.860465           0.857431           0.859262   \n",
       "61            0.860465           0.857339           0.859445   \n",
       "86            0.858542           0.857156           0.856607   \n",
       "0             0.857169           0.857431           0.860361   \n",
       "69            0.861289           0.856515           0.857431   \n",
       "108           0.859183           0.856149           0.862284   \n",
       "16            0.863578           0.856057           0.857156   \n",
       "81            0.858542           0.854501           0.858438   \n",
       "10            0.858176           0.855508           0.857797   \n",
       "109           0.858726           0.854501           0.858804   \n",
       "53            0.858359           0.854592           0.858804   \n",
       "25            0.858451           0.854592           0.858529   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "75            0.861185         0.862435        0.001997                1  \n",
       "7             0.861917         0.862197        0.000708                2  \n",
       "35            0.861643         0.862160        0.000908                3  \n",
       "47            0.862009         0.862087        0.001354                4  \n",
       "67            0.859811         0.861977        0.001826                5  \n",
       "91            0.861368         0.861941        0.001041                6  \n",
       "11            0.858163         0.861941        0.002113                7  \n",
       "63            0.861368         0.861849        0.000807                8  \n",
       "19            0.860727         0.861813        0.001286                9  \n",
       "88            0.862375         0.861794        0.001311               10  \n",
       "95            0.858163         0.861739        0.002363               11  \n",
       "39            0.858438         0.861703        0.001927               12  \n",
       "103           0.860178         0.861629        0.001652               13  \n",
       "71            0.860544         0.861574        0.001330               14  \n",
       "83            0.859995         0.861574        0.001652               15  \n",
       "84            0.858896         0.861574        0.003552               16  \n",
       "43            0.861643         0.861428        0.001053               17  \n",
       "99            0.859720         0.861391        0.001620               18  \n",
       "102           0.860910         0.861355        0.002489               19  \n",
       "27            0.859079         0.861336        0.002361               20  \n",
       "51            0.861734         0.861190        0.002309               21  \n",
       "110           0.859720         0.861153        0.001760               22  \n",
       "28            0.857431         0.861117        0.002279               23  \n",
       "15            0.861460         0.861098        0.001614               24  \n",
       "56            0.858713         0.861062        0.001861               25  \n",
       "55            0.859537         0.861025        0.001541               26  \n",
       "111           0.859995         0.861007        0.001566               27  \n",
       "106           0.858163         0.861007        0.002802               28  \n",
       "74            0.859628         0.860915        0.001963               29  \n",
       "23            0.860544         0.860915        0.002463               30  \n",
       "34            0.860452         0.860879        0.003271               31  \n",
       "107           0.861093         0.860860        0.001543               32  \n",
       "87            0.861734         0.860842        0.001091               33  \n",
       "82            0.858255         0.860842        0.002372               34  \n",
       "96            0.860361         0.860805        0.001482               35  \n",
       "3             0.859995         0.860787        0.001232               36  \n",
       "90            0.859811         0.860769        0.001440               37  \n",
       "79            0.860910         0.860732        0.002273               38  \n",
       "31            0.861002         0.860695        0.001182               39  \n",
       "17            0.857339         0.860677        0.002474               40  \n",
       "30            0.858804         0.860659        0.001918               41  \n",
       "100           0.855966         0.860640        0.004365               42  \n",
       "32            0.859170         0.860586        0.002367               43  \n",
       "45            0.857797         0.860567        0.002513               44  \n",
       "48            0.859811         0.860531        0.001205               45  \n",
       "59            0.860819         0.860457        0.000864               46  \n",
       "101           0.857339         0.860457        0.003073               47  \n",
       "78            0.856698         0.860384        0.002716               48  \n",
       "6             0.858163         0.860366        0.002614               49  \n",
       "85            0.858621         0.860329        0.001560               50  \n",
       "65            0.857980         0.860311        0.003104               51  \n",
       "37            0.858621         0.860292        0.003232               52  \n",
       "29            0.858804         0.860274        0.002064               53  \n",
       "46            0.860361         0.860256        0.001255               54  \n",
       "36            0.861093         0.860256        0.002811               55  \n",
       "38            0.858438         0.860256        0.002812               56  \n",
       "104           0.858529         0.860238        0.002475               57  \n",
       "12            0.858896         0.860238        0.003157               58  \n",
       "2             0.858438         0.860219        0.001985               59  \n",
       "93            0.858529         0.860201        0.002803               60  \n",
       "8             0.859170         0.860201        0.003110               61  \n",
       "40            0.858163         0.860183        0.002496               62  \n",
       "73            0.857064         0.860146        0.002679               63  \n",
       "9             0.858529         0.860146        0.003185               64  \n",
       "57            0.858621         0.860128        0.001430               65  \n",
       "14            0.858438         0.860128        0.001874               66  \n",
       "76            0.857797         0.860109        0.002352               67  \n",
       "44            0.855599         0.860109        0.003046               68  \n",
       "18            0.857522         0.860091        0.001877               69  \n",
       "1             0.859170         0.860054        0.002417               70  \n",
       "20            0.859262         0.860036        0.002179               71  \n",
       "50            0.857248         0.860036        0.003278               72  \n",
       "52            0.858255         0.860000        0.002071               73  \n",
       "77            0.861917         0.860000        0.002479               74  \n",
       "54            0.856881         0.860000        0.003041               75  \n",
       "24            0.857248         0.859926        0.002315               76  \n",
       "98            0.859445         0.859908        0.002216               77  \n",
       "49            0.861093         0.859890        0.001844               78  \n",
       "21            0.861002         0.859890        0.001647               79  \n",
       "58            0.856881         0.859853        0.002636               80  \n",
       "72            0.856607         0.859835        0.002267               81  \n",
       "26            0.857614         0.859835        0.002385               82  \n",
       "94            0.855782         0.859816        0.002613               83  \n",
       "22            0.857522         0.859798        0.002494               84  \n",
       "64            0.859720         0.859743        0.002371               85  \n",
       "62            0.857614         0.859707        0.001964               86  \n",
       "42            0.858987         0.859688        0.002131               87  \n",
       "80            0.853951         0.859652        0.003741               88  \n",
       "66            0.857614         0.859633        0.001982               89  \n",
       "92            0.860452         0.859597        0.002019               90  \n",
       "68            0.857614         0.859560        0.003182               91  \n",
       "70            0.859079         0.859414        0.002784               92  \n",
       "60            0.859537         0.859377        0.001554               93  \n",
       "105           0.861093         0.859359        0.002308               94  \n",
       "4             0.857339         0.859285        0.001865               95  \n",
       "89            0.857614         0.859176        0.001392               96  \n",
       "41            0.857431         0.859029        0.002228               97  \n",
       "97            0.858346         0.858992        0.002088               98  \n",
       "13            0.857064         0.858901        0.002318               99  \n",
       "5             0.856790         0.858828        0.001378              100  \n",
       "33            0.856790         0.858828        0.001472              101  \n",
       "61            0.856881         0.858809        0.001432              102  \n",
       "86            0.858713         0.858736        0.002121              103  \n",
       "0             0.856057         0.858644        0.002279              104  \n",
       "69            0.856057         0.858535        0.002329              105  \n",
       "108           0.855325         0.858333        0.002462              106  \n",
       "16            0.855966         0.858058        0.002826              107  \n",
       "81            0.857797         0.858003        0.002014              108  \n",
       "10            0.856515         0.857894        0.002024              109  \n",
       "109           0.856698         0.857857        0.002076              110  \n",
       "53            0.856973         0.857820        0.001945              111  \n",
       "25            0.856607         0.857674        0.001913              112  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_2_bis = pd.DataFrame(nn_grid_search_2_bis_cv.cv_results_)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "cv_res_2_bis.sort_values(by=\"mean_test_score\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a37bce56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__activation</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__hidden_layer_sizes</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>23.896105</td>\n",
       "      <td>3.810573</td>\n",
       "      <td>0.095188</td>\n",
       "      <td>0.018649</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.867973</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.861574</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "84      23.896105      3.810573         0.095188        0.018649   \n",
       "\n",
       "   param_classifier__activation param_classifier__alpha  \\\n",
       "84                         relu                    0.15   \n",
       "\n",
       "   param_classifier__hidden_layer_sizes param_classifier__learning_rate  \\\n",
       "84                               (9, 6)                        adaptive   \n",
       "\n",
       "   param_classifier__max_iter param_classifier__solver  \\\n",
       "84                        500                     adam   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "84  {'classifier__activation': 'relu', 'classifier...           0.867973   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "84           0.862388           0.857888           0.860727   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "84           0.858896         0.861574        0.003552               16  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores = nn_grid_search_2_bis_cv.cv_results_[\"mean_test_score\"]\n",
    "best_index = np.argmax(mean_scores)\n",
    "se_scores = nn_grid_search_2_bis_cv.cv_results_[\"std_test_score\"] / np.sqrt(5)\n",
    "\n",
    "one_stand_error_data_frame = cv_res_2_bis[cv_res_2_bis[\"mean_test_score\"] >= (mean_scores[best_index] - se_scores[best_index])]\n",
    "one_stand_error_data_frame[one_stand_error_data_frame[\"mean_test_score\"] == one_stand_error_data_frame[\"mean_test_score\"].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d1f97",
   "metadata": {},
   "source": [
    "## For 2 Layers Only: Last Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34cae3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 6),\n",
       " (4, 7),\n",
       " (8, 7),\n",
       " (8, 5),\n",
       " (5, 4),\n",
       " (9, 2),\n",
       " (7, 4),\n",
       " (5, 9),\n",
       " (9, 5),\n",
       " (8, 2),\n",
       " (6, 4),\n",
       " (8, 9),\n",
       " (4, 4),\n",
       " (7, 5)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_combinations_layers_2_ter = [(9,6), (4,7), (8,7), (8,5), (5,4), (9,2), (7,4), (5,9), (9,5), (8,2), (6,4), (8,9), (4,4), (7,5)]\n",
    "list_combinations_layers_2_ter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a353d20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__hidden_layer_sizes': [(9, 6),\n",
       "  (4, 7),\n",
       "  (8, 7),\n",
       "  (8, 5),\n",
       "  (5, 4),\n",
       "  (9, 2),\n",
       "  (7, 4),\n",
       "  (5, 9),\n",
       "  (9, 5),\n",
       "  (8, 2),\n",
       "  (6, 4),\n",
       "  (8, 9),\n",
       "  (4, 4),\n",
       "  (7, 5)],\n",
       " 'classifier__activation': ['relu'],\n",
       " 'classifier__solver': ['adam'],\n",
       " 'classifier__alpha': [0.15, 0.2],\n",
       " 'classifier__learning_rate': ['adaptive'],\n",
       " 'classifier__max_iter': [700]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param_2_ter = {\n",
    "    \"classifier__hidden_layer_sizes\": list_combinations_layers_2, \n",
    "              \"classifier__activation\": ['relu'],\n",
    "              \"classifier__solver\": ['adam'],\n",
    "              \"classifier__alpha\": [0.15, 0.2],\n",
    "              \"classifier__learning_rate\": ['adaptive'],\n",
    "              \"classifier__max_iter\": [700],\n",
    "}\n",
    "\n",
    "hyper_param_2_ter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "723d387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_grid_search_2_ter_cv = GridSearchCV(estimator = clf, param_grid=hyper_param_2_ter, scoring=\"accuracy\",\n",
    "                           cv = KFold(n_splits=5, shuffle=True, random_state=1), n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d06b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['occ_code_level2',\n",
       "                                                                          'age',\n",
       "                                                                          'stock_dividends',\n",
       "                                                                          'wage_per_hour',\n",
       "                                                                          'capital_losses',\n",
       "                                                                          'own_or_self',\n",
       "                                                                          'ind_code_level2',\n",
       "                                                                          'capital_gains',\n",
       "                                                                          'week...\n",
       "                                                      random_state=1))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__activation': ['relu'],\n",
       "                         'classifier__alpha': [0.15, 0.2],\n",
       "                         'classifier__hidden_layer_sizes': [(9, 6), (4, 7),\n",
       "                                                            (8, 7), (8, 5),\n",
       "                                                            (5, 4), (9, 2),\n",
       "                                                            (7, 4), (5, 9),\n",
       "                                                            (9, 5), (8, 2),\n",
       "                                                            (6, 4), (8, 9),\n",
       "                                                            (4, 4), (7, 5)],\n",
       "                         'classifier__learning_rate': ['adaptive'],\n",
       "                         'classifier__max_iter': [700],\n",
       "                         'classifier__solver': ['adam']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search_2_ter_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbd328b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__activation</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__hidden_layer_sizes</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.922922</td>\n",
       "      <td>2.955729</td>\n",
       "      <td>0.101816</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863761</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.861643</td>\n",
       "      <td>0.861460</td>\n",
       "      <td>0.862375</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.098867</td>\n",
       "      <td>2.534089</td>\n",
       "      <td>0.110552</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.867973</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.861574</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.431111</td>\n",
       "      <td>4.730634</td>\n",
       "      <td>0.093619</td>\n",
       "      <td>0.007955</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(8, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865501</td>\n",
       "      <td>0.859641</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.861460</td>\n",
       "      <td>0.861465</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.539760</td>\n",
       "      <td>3.991506</td>\n",
       "      <td>0.087995</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.864494</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.860910</td>\n",
       "      <td>0.861355</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21.479438</td>\n",
       "      <td>9.344530</td>\n",
       "      <td>0.087648</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.864219</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.861190</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.713836</td>\n",
       "      <td>5.900339</td>\n",
       "      <td>0.086524</td>\n",
       "      <td>0.007641</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.861153</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16.615588</td>\n",
       "      <td>2.856402</td>\n",
       "      <td>0.084787</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.861062</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.797997</td>\n",
       "      <td>2.967387</td>\n",
       "      <td>0.093971</td>\n",
       "      <td>0.013840</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863670</td>\n",
       "      <td>0.864768</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.861007</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.920825</td>\n",
       "      <td>3.717518</td>\n",
       "      <td>0.093516</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(9, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864768</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.860086</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.860952</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.339567</td>\n",
       "      <td>4.108686</td>\n",
       "      <td>0.092109</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865226</td>\n",
       "      <td>0.860099</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.860934</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.846424</td>\n",
       "      <td>2.892690</td>\n",
       "      <td>0.094151</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865867</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.860178</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.860824</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.675024</td>\n",
       "      <td>1.882494</td>\n",
       "      <td>0.091794</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(7, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.860805</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.660182</td>\n",
       "      <td>2.000921</td>\n",
       "      <td>0.073922</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(7, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.860805</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.040058</td>\n",
       "      <td>2.630045</td>\n",
       "      <td>0.097682</td>\n",
       "      <td>0.007432</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.860769</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.783890</td>\n",
       "      <td>3.917147</td>\n",
       "      <td>0.089884</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.860640</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16.058207</td>\n",
       "      <td>1.727290</td>\n",
       "      <td>0.083375</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.858176</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.861734</td>\n",
       "      <td>0.861093</td>\n",
       "      <td>0.860439</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.662352</td>\n",
       "      <td>3.235963</td>\n",
       "      <td>0.091461</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862937</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.860274</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.488510</td>\n",
       "      <td>3.217653</td>\n",
       "      <td>0.090950</td>\n",
       "      <td>0.006871</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.860238</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14.413966</td>\n",
       "      <td>2.570018</td>\n",
       "      <td>0.094132</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863303</td>\n",
       "      <td>0.862846</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.860054</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.835163</td>\n",
       "      <td>4.487161</td>\n",
       "      <td>0.112481</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.860635</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.860036</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18.377981</td>\n",
       "      <td>4.837818</td>\n",
       "      <td>0.090038</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865043</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>0.859926</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.912064</td>\n",
       "      <td>3.457430</td>\n",
       "      <td>0.087087</td>\n",
       "      <td>0.007086</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.859908</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.638771</td>\n",
       "      <td>3.561842</td>\n",
       "      <td>0.099360</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.859816</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.629448</td>\n",
       "      <td>3.838785</td>\n",
       "      <td>0.091773</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.859458</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.859597</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.207156</td>\n",
       "      <td>1.498197</td>\n",
       "      <td>0.094159</td>\n",
       "      <td>0.009957</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(5, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864402</td>\n",
       "      <td>0.861198</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.859304</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.766190</td>\n",
       "      <td>3.948222</td>\n",
       "      <td>0.112364</td>\n",
       "      <td>0.011629</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>0.858542</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.858736</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.285669</td>\n",
       "      <td>3.276043</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858726</td>\n",
       "      <td>0.859183</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>0.862284</td>\n",
       "      <td>0.855325</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.094280</td>\n",
       "      <td>3.027038</td>\n",
       "      <td>0.082849</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.858817</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.854134</td>\n",
       "      <td>0.858205</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2       13.922922      2.955729         0.101816        0.019364   \n",
       "0       21.098867      2.534089         0.110552        0.008046   \n",
       "16      15.431111      4.730634         0.093619        0.007955   \n",
       "9       18.539760      3.991506         0.087995        0.004409   \n",
       "17      21.479438      9.344530         0.087648        0.009255   \n",
       "13      15.713836      5.900339         0.086524        0.007641   \n",
       "20      16.615588      2.856402         0.084787        0.004108   \n",
       "11      14.797997      2.967387         0.093971        0.013840   \n",
       "14      20.920825      3.717518         0.093516        0.010958   \n",
       "19      19.339567      4.108686         0.092109        0.008733   \n",
       "25      12.846424      2.892690         0.094151        0.008498   \n",
       "6       17.675024      1.882494         0.091794        0.009100   \n",
       "27      12.660182      2.000921         0.073922        0.006538   \n",
       "3       16.040058      2.630045         0.097682        0.007432   \n",
       "8       15.783890      3.917147         0.089884        0.009796   \n",
       "23      16.058207      1.727290         0.083375        0.005892   \n",
       "21      11.662352      3.235963         0.091461        0.005424   \n",
       "10      15.488510      3.217653         0.090950        0.006871   \n",
       "24      14.413966      2.570018         0.094132        0.007034   \n",
       "15      14.835163      4.487161         0.112481        0.024380   \n",
       "22      18.377981      4.837818         0.090038        0.005486   \n",
       "7       10.912064      3.457430         0.087087        0.007086   \n",
       "5       18.638771      3.561842         0.099360        0.008517   \n",
       "4       18.629448      3.838785         0.091773        0.012535   \n",
       "18      14.207156      1.498197         0.094159        0.009957   \n",
       "1       15.766190      3.948222         0.112364        0.011629   \n",
       "12      12.285669      3.276043         0.085973        0.007007   \n",
       "26      12.094280      3.027038         0.082849        0.007530   \n",
       "\n",
       "   param_classifier__activation param_classifier__alpha  \\\n",
       "2                          relu                    0.15   \n",
       "0                          relu                    0.15   \n",
       "16                         relu                     0.2   \n",
       "9                          relu                    0.15   \n",
       "17                         relu                     0.2   \n",
       "13                         relu                    0.15   \n",
       "20                         relu                     0.2   \n",
       "11                         relu                    0.15   \n",
       "14                         relu                     0.2   \n",
       "19                         relu                     0.2   \n",
       "25                         relu                     0.2   \n",
       "6                          relu                    0.15   \n",
       "27                         relu                     0.2   \n",
       "3                          relu                    0.15   \n",
       "8                          relu                    0.15   \n",
       "23                         relu                     0.2   \n",
       "21                         relu                     0.2   \n",
       "10                         relu                    0.15   \n",
       "24                         relu                     0.2   \n",
       "15                         relu                     0.2   \n",
       "22                         relu                     0.2   \n",
       "7                          relu                    0.15   \n",
       "5                          relu                    0.15   \n",
       "4                          relu                    0.15   \n",
       "18                         relu                     0.2   \n",
       "1                          relu                    0.15   \n",
       "12                         relu                    0.15   \n",
       "26                         relu                     0.2   \n",
       "\n",
       "   param_classifier__hidden_layer_sizes param_classifier__learning_rate  \\\n",
       "2                                (8, 7)                        adaptive   \n",
       "0                                (9, 6)                        adaptive   \n",
       "16                               (8, 7)                        adaptive   \n",
       "9                                (8, 2)                        adaptive   \n",
       "17                               (8, 5)                        adaptive   \n",
       "13                               (7, 5)                        adaptive   \n",
       "20                               (7, 4)                        adaptive   \n",
       "11                               (8, 9)                        adaptive   \n",
       "14                               (9, 6)                        adaptive   \n",
       "19                               (9, 2)                        adaptive   \n",
       "25                               (8, 9)                        adaptive   \n",
       "6                                (7, 4)                        adaptive   \n",
       "27                               (7, 5)                        adaptive   \n",
       "3                                (8, 5)                        adaptive   \n",
       "8                                (9, 5)                        adaptive   \n",
       "23                               (8, 2)                        adaptive   \n",
       "21                               (5, 9)                        adaptive   \n",
       "10                               (6, 4)                        adaptive   \n",
       "24                               (6, 4)                        adaptive   \n",
       "15                               (4, 7)                        adaptive   \n",
       "22                               (9, 5)                        adaptive   \n",
       "7                                (5, 9)                        adaptive   \n",
       "5                                (9, 2)                        adaptive   \n",
       "4                                (5, 4)                        adaptive   \n",
       "18                               (5, 4)                        adaptive   \n",
       "1                                (4, 7)                        adaptive   \n",
       "12                               (4, 4)                        adaptive   \n",
       "26                               (4, 4)                        adaptive   \n",
       "\n",
       "   param_classifier__max_iter param_classifier__solver  \\\n",
       "2                         700                     adam   \n",
       "0                         700                     adam   \n",
       "16                        700                     adam   \n",
       "9                         700                     adam   \n",
       "17                        700                     adam   \n",
       "13                        700                     adam   \n",
       "20                        700                     adam   \n",
       "11                        700                     adam   \n",
       "14                        700                     adam   \n",
       "19                        700                     adam   \n",
       "25                        700                     adam   \n",
       "6                         700                     adam   \n",
       "27                        700                     adam   \n",
       "3                         700                     adam   \n",
       "8                         700                     adam   \n",
       "23                        700                     adam   \n",
       "21                        700                     adam   \n",
       "10                        700                     adam   \n",
       "24                        700                     adam   \n",
       "15                        700                     adam   \n",
       "22                        700                     adam   \n",
       "7                         700                     adam   \n",
       "5                         700                     adam   \n",
       "4                         700                     adam   \n",
       "18                        700                     adam   \n",
       "1                         700                     adam   \n",
       "12                        700                     adam   \n",
       "26                        700                     adam   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "2   {'classifier__activation': 'relu', 'classifier...           0.863761   \n",
       "0   {'classifier__activation': 'relu', 'classifier...           0.867973   \n",
       "16  {'classifier__activation': 'relu', 'classifier...           0.865501   \n",
       "9   {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "17  {'classifier__activation': 'relu', 'classifier...           0.864127   \n",
       "13  {'classifier__activation': 'relu', 'classifier...           0.863212   \n",
       "20  {'classifier__activation': 'relu', 'classifier...           0.864127   \n",
       "11  {'classifier__activation': 'relu', 'classifier...           0.863670   \n",
       "14  {'classifier__activation': 'relu', 'classifier...           0.864768   \n",
       "19  {'classifier__activation': 'relu', 'classifier...           0.865226   \n",
       "25  {'classifier__activation': 'relu', 'classifier...           0.865867   \n",
       "6   {'classifier__activation': 'relu', 'classifier...           0.862388   \n",
       "27  {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "3   {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "8   {'classifier__activation': 'relu', 'classifier...           0.867515   \n",
       "23  {'classifier__activation': 'relu', 'classifier...           0.863395   \n",
       "21  {'classifier__activation': 'relu', 'classifier...           0.862937   \n",
       "10  {'classifier__activation': 'relu', 'classifier...           0.863578   \n",
       "24  {'classifier__activation': 'relu', 'classifier...           0.863303   \n",
       "15  {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "22  {'classifier__activation': 'relu', 'classifier...           0.865043   \n",
       "7   {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "5   {'classifier__activation': 'relu', 'classifier...           0.862571   \n",
       "4   {'classifier__activation': 'relu', 'classifier...           0.862479   \n",
       "18  {'classifier__activation': 'relu', 'classifier...           0.864402   \n",
       "1   {'classifier__activation': 'relu', 'classifier...           0.862663   \n",
       "12  {'classifier__activation': 'relu', 'classifier...           0.858726   \n",
       "26  {'classifier__activation': 'relu', 'classifier...           0.863395   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "2            0.859733           0.861643           0.861460   \n",
       "0            0.862388           0.857888           0.860727   \n",
       "16           0.859641           0.861185           0.859537   \n",
       "9            0.864494           0.858346           0.859079   \n",
       "17           0.864219           0.860544           0.858438   \n",
       "13           0.863395           0.859903           0.859537   \n",
       "20           0.863395           0.857705           0.859354   \n",
       "11           0.864768           0.860544           0.857888   \n",
       "14           0.860282           0.859170           0.860086   \n",
       "19           0.860099           0.858896           0.860544   \n",
       "25           0.861289           0.860178           0.858621   \n",
       "6            0.862663           0.859720           0.858896   \n",
       "27           0.862205           0.859445           0.859262   \n",
       "3            0.860465           0.860361           0.859628   \n",
       "8            0.863944           0.858072           0.857705   \n",
       "23           0.858176           0.857797           0.861734   \n",
       "21           0.861930           0.858163           0.859262   \n",
       "10           0.862479           0.856881           0.859720   \n",
       "24           0.862846           0.857339           0.858163   \n",
       "15           0.859366           0.858255           0.860635   \n",
       "22           0.861106           0.857248           0.858255   \n",
       "7            0.862205           0.857614           0.857522   \n",
       "5            0.862754           0.858621           0.859354   \n",
       "4            0.859458           0.856240           0.859354   \n",
       "18           0.861198           0.856057           0.859445   \n",
       "1            0.858542           0.857156           0.856607   \n",
       "12           0.859183           0.856149           0.862284   \n",
       "26           0.858817           0.855599           0.859079   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "2            0.862375         0.861794        0.001311                1  \n",
       "0            0.858896         0.861574        0.003552                2  \n",
       "16           0.861460         0.861465        0.002164                3  \n",
       "9            0.860910         0.861355        0.002489                4  \n",
       "17           0.858621         0.861190        0.002545                5  \n",
       "13           0.859720         0.861153        0.001760                6  \n",
       "20           0.860727         0.861062        0.002414                7  \n",
       "11           0.858163         0.861007        0.002802                8  \n",
       "14           0.860452         0.860952        0.001959                9  \n",
       "19           0.859903         0.860934        0.002213               10  \n",
       "25           0.858163         0.860824        0.002757               11  \n",
       "6            0.860361         0.860805        0.001482               12  \n",
       "27           0.859170         0.860805        0.001935               13  \n",
       "3            0.859811         0.860769        0.001440               14  \n",
       "8            0.855966         0.860640        0.004365               15  \n",
       "23           0.861093         0.860439        0.002142               16  \n",
       "21           0.859079         0.860274        0.001830               17  \n",
       "10           0.858529         0.860238        0.002475               18  \n",
       "24           0.858621         0.860054        0.002504               19  \n",
       "15           0.859170         0.860036        0.001557               20  \n",
       "22           0.857980         0.859926        0.002875               21  \n",
       "7            0.859445         0.859908        0.002216               22  \n",
       "5            0.855782         0.859816        0.002613               23  \n",
       "4            0.860452         0.859597        0.002019               24  \n",
       "18           0.855416         0.859304        0.003324               25  \n",
       "1            0.858713         0.858736        0.002121               26  \n",
       "12           0.855325         0.858333        0.002462               27  \n",
       "26           0.854134         0.858205        0.003207               28  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_2_ter = pd.DataFrame(nn_grid_search_2_ter_cv.cv_results_)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "cv_res_2_ter.sort_values(by=\"mean_test_score\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d354ace8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__activation</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__hidden_layer_sizes</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.53976</td>\n",
       "      <td>3.991506</td>\n",
       "      <td>0.087995</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>(8, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>700</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.864494</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.86091</td>\n",
       "      <td>0.861355</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9       18.53976      3.991506         0.087995        0.004409   \n",
       "\n",
       "  param_classifier__activation param_classifier__alpha  \\\n",
       "9                         relu                    0.15   \n",
       "\n",
       "  param_classifier__hidden_layer_sizes param_classifier__learning_rate  \\\n",
       "9                               (8, 2)                        adaptive   \n",
       "\n",
       "  param_classifier__max_iter param_classifier__solver  \\\n",
       "9                        700                     adam   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "9  {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "9           0.864494           0.858346           0.859079            0.86091   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "9         0.861355        0.002489                4  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores = nn_grid_search_2_ter_cv.cv_results_[\"mean_test_score\"]\n",
    "best_index = np.argmax(mean_scores)\n",
    "se_scores = nn_grid_search_2_ter_cv.cv_results_[\"std_test_score\"] / np.sqrt(5)\n",
    "\n",
    "one_stand_error_data_frame = cv_res_2_ter[cv_res_2_ter[\"mean_test_score\"] >= (mean_scores[best_index] - se_scores[best_index])]\n",
    "one_stand_error_data_frame[one_stand_error_data_frame[\"mean_test_score\"] == one_stand_error_data_frame[\"mean_test_score\"].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae57ea2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## For 3 Layers Only: First Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4eb21eed",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__hidden_layer_sizes': [(2, 2, 2),\n",
       "  (2, 2, 3),\n",
       "  (2, 2, 4),\n",
       "  (2, 3, 2),\n",
       "  (2, 3, 3),\n",
       "  (2, 3, 4),\n",
       "  (2, 4, 2),\n",
       "  (2, 4, 3),\n",
       "  (2, 4, 4),\n",
       "  (3, 2, 2),\n",
       "  (3, 2, 3),\n",
       "  (3, 2, 4),\n",
       "  (3, 3, 2),\n",
       "  (3, 3, 3),\n",
       "  (3, 3, 4),\n",
       "  (3, 4, 2),\n",
       "  (3, 4, 3),\n",
       "  (3, 4, 4),\n",
       "  (4, 2, 2),\n",
       "  (4, 2, 3),\n",
       "  (4, 2, 4),\n",
       "  (4, 3, 2),\n",
       "  (4, 3, 3),\n",
       "  (4, 3, 4),\n",
       "  (4, 4, 2),\n",
       "  (4, 4, 3),\n",
       "  (4, 4, 4)],\n",
       " 'classifier__activation': ['relu'],\n",
       " 'classifier__solver': ['adam'],\n",
       " 'classifier__alpha': [0.05, 0.07],\n",
       " 'classifier__learning_rate': ['adaptive'],\n",
       " 'classifier__max_iter': [500]}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param_3 = {\n",
    "    \"classifier__hidden_layer_sizes\": list_combinations_layers_3, \n",
    "              \"classifier__activation\": ['relu'],\n",
    "              \"classifier__solver\": ['adam'],\n",
    "              \"classifier__alpha\": [0.05, 0.07],\n",
    "              \"classifier__learning_rate\": ['adaptive'],\n",
    "              \"classifier__max_iter\": [500],\n",
    "}\n",
    "\n",
    "hyper_param_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7299db40",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nn_grid_search_3_cv = GridSearchCV(estimator = clf, param_grid=hyper_param_3, scoring=\"accuracy\",\n",
    "                           cv = KFold(n_splits=5, shuffle=True, random_state=1), n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "128b3be9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['occ_code_level2',\n",
       "                                                                          'age',\n",
       "                                                                          'stock_dividends',\n",
       "                                                                          'wage_per_hour',\n",
       "                                                                          'capital_losses',\n",
       "                                                                          'own_or_self',\n",
       "                                                                          'ind_code_level2',\n",
       "                                                                          'capital_gains',\n",
       "                                                                          'week...\n",
       "                         'classifier__hidden_layer_sizes': [(2, 2, 2),\n",
       "                                                            (2, 2, 3),\n",
       "                                                            (2, 2, 4),\n",
       "                                                            (2, 3, 2),\n",
       "                                                            (2, 3, 3),\n",
       "                                                            (2, 3, 4),\n",
       "                                                            (2, 4, 2),\n",
       "                                                            (2, 4, 3),\n",
       "                                                            (2, 4, 4),\n",
       "                                                            (3, 2, 2),\n",
       "                                                            (3, 2, 3),\n",
       "                                                            (3, 2, 4),\n",
       "                                                            (3, 3, 2),\n",
       "                                                            (3, 3, 3),\n",
       "                                                            (3, 3, 4),\n",
       "                                                            (3, 4, 2),\n",
       "                                                            (3, 4, 3),\n",
       "                                                            (3, 4, 4),\n",
       "                                                            (4, 2, 2),\n",
       "                                                            (4, 2, 3),\n",
       "                                                            (4, 2, 4),\n",
       "                                                            (4, 3, 2),\n",
       "                                                            (4, 3, 3),\n",
       "                                                            (4, 3, 4),\n",
       "                                                            (4, 4, 2),\n",
       "                                                            (4, 4, 3),\n",
       "                                                            (4, 4, 4)],\n",
       "                         'classifier__learning_rate': ['adaptive'],\n",
       "                         'classifier__max_iter': [500],\n",
       "                         'classifier__solver': ['adam']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search_3_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1b18b456",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__activation</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__hidden_layer_sizes</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.128447</td>\n",
       "      <td>4.324626</td>\n",
       "      <td>0.082921</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.857169</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.859262</td>\n",
       "      <td>0.696456</td>\n",
       "      <td>0.825937</td>\n",
       "      <td>0.064752</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.825178</td>\n",
       "      <td>2.596659</td>\n",
       "      <td>0.083624</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.854409</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.857472</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.038758</td>\n",
       "      <td>5.210331</td>\n",
       "      <td>0.081968</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860557</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>0.852211</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.696456</td>\n",
       "      <td>0.825461</td>\n",
       "      <td>0.064568</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.452147</td>\n",
       "      <td>1.647914</td>\n",
       "      <td>0.087250</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 3, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862846</td>\n",
       "      <td>0.859183</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.854226</td>\n",
       "      <td>0.857875</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.005495</td>\n",
       "      <td>4.174497</td>\n",
       "      <td>0.082096</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 3, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859092</td>\n",
       "      <td>0.857535</td>\n",
       "      <td>0.856973</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.696456</td>\n",
       "      <td>0.825772</td>\n",
       "      <td>0.064663</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.694295</td>\n",
       "      <td>1.492008</td>\n",
       "      <td>0.090998</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 3, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859916</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.856607</td>\n",
       "      <td>0.858351</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.889145</td>\n",
       "      <td>11.219328</td>\n",
       "      <td>0.086501</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 4, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.689251</td>\n",
       "      <td>0.689526</td>\n",
       "      <td>0.696548</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.724670</td>\n",
       "      <td>0.066295</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.690574</td>\n",
       "      <td>5.140968</td>\n",
       "      <td>0.080340</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 4, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858359</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.857125</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.403090</td>\n",
       "      <td>2.586638</td>\n",
       "      <td>0.087042</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859183</td>\n",
       "      <td>0.856437</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.857051</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.792281</td>\n",
       "      <td>1.578882</td>\n",
       "      <td>0.083475</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 2, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.858176</td>\n",
       "      <td>0.854043</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.857399</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.478514</td>\n",
       "      <td>5.516243</td>\n",
       "      <td>0.086901</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 2, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860099</td>\n",
       "      <td>0.858726</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.854317</td>\n",
       "      <td>0.857582</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.556464</td>\n",
       "      <td>2.377288</td>\n",
       "      <td>0.083871</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 2, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.857810</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.858351</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.680422</td>\n",
       "      <td>5.409723</td>\n",
       "      <td>0.088718</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 3, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.689251</td>\n",
       "      <td>0.689526</td>\n",
       "      <td>0.696548</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.854134</td>\n",
       "      <td>0.724066</td>\n",
       "      <td>0.065088</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.007630</td>\n",
       "      <td>9.156823</td>\n",
       "      <td>0.088798</td>\n",
       "      <td>0.011231</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 3, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.689251</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.067614</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19.414818</td>\n",
       "      <td>3.167781</td>\n",
       "      <td>0.087070</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 3, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859092</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.857784</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.420305</td>\n",
       "      <td>3.823158</td>\n",
       "      <td>0.087629</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 4, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859183</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.857637</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20.957866</td>\n",
       "      <td>3.998486</td>\n",
       "      <td>0.083502</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 4, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.853768</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.854226</td>\n",
       "      <td>0.857344</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.623792</td>\n",
       "      <td>4.480909</td>\n",
       "      <td>0.086238</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858176</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.854958</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.856960</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.347293</td>\n",
       "      <td>3.205629</td>\n",
       "      <td>0.088718</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 2, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861381</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.858791</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14.429774</td>\n",
       "      <td>2.307198</td>\n",
       "      <td>0.085047</td>\n",
       "      <td>0.009767</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 2, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.861198</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.860361</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.859743</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.228413</td>\n",
       "      <td>5.568020</td>\n",
       "      <td>0.083827</td>\n",
       "      <td>0.008616</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 2, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.856986</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.855325</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.857198</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.748655</td>\n",
       "      <td>4.097731</td>\n",
       "      <td>0.087574</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 3, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863944</td>\n",
       "      <td>0.858359</td>\n",
       "      <td>0.858529</td>\n",
       "      <td>0.861368</td>\n",
       "      <td>0.860178</td>\n",
       "      <td>0.860476</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19.331285</td>\n",
       "      <td>4.024008</td>\n",
       "      <td>0.084839</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 3, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859092</td>\n",
       "      <td>0.858726</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.861368</td>\n",
       "      <td>0.858535</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16.500988</td>\n",
       "      <td>2.839943</td>\n",
       "      <td>0.083519</td>\n",
       "      <td>0.007288</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 3, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.857993</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.857888</td>\n",
       "      <td>0.858461</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.438173</td>\n",
       "      <td>5.350972</td>\n",
       "      <td>0.084492</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 4, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.861917</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.859743</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.356195</td>\n",
       "      <td>3.005091</td>\n",
       "      <td>0.087084</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 4, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861838</td>\n",
       "      <td>0.859092</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.856973</td>\n",
       "      <td>0.858242</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15.597766</td>\n",
       "      <td>2.817251</td>\n",
       "      <td>0.090150</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861838</td>\n",
       "      <td>0.862846</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.859633</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.654168</td>\n",
       "      <td>4.566487</td>\n",
       "      <td>0.083903</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 2, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860557</td>\n",
       "      <td>0.857261</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.859628</td>\n",
       "      <td>0.696456</td>\n",
       "      <td>0.826028</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.389529</td>\n",
       "      <td>1.325659</td>\n",
       "      <td>0.086152</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 2, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.857352</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.857582</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.703250</td>\n",
       "      <td>4.781179</td>\n",
       "      <td>0.086474</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 2, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860099</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>0.855050</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.696456</td>\n",
       "      <td>0.826065</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17.168977</td>\n",
       "      <td>3.472410</td>\n",
       "      <td>0.082321</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 3, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.859183</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.853035</td>\n",
       "      <td>0.857894</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11.000520</td>\n",
       "      <td>4.114816</td>\n",
       "      <td>0.084180</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 3, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.857352</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.696456</td>\n",
       "      <td>0.825735</td>\n",
       "      <td>0.064644</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9.663813</td>\n",
       "      <td>1.456791</td>\n",
       "      <td>0.083249</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 3, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859275</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.858370</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9.490922</td>\n",
       "      <td>10.506090</td>\n",
       "      <td>0.089220</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 4, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.689251</td>\n",
       "      <td>0.689526</td>\n",
       "      <td>0.696548</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.856515</td>\n",
       "      <td>0.724542</td>\n",
       "      <td>0.066039</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12.737902</td>\n",
       "      <td>2.631426</td>\n",
       "      <td>0.080973</td>\n",
       "      <td>0.005749</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 4, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.859916</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.853860</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>11.707681</td>\n",
       "      <td>2.328974</td>\n",
       "      <td>0.083559</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(2, 4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859092</td>\n",
       "      <td>0.856894</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.856740</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18.272124</td>\n",
       "      <td>2.006203</td>\n",
       "      <td>0.084479</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 2, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.858542</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.857765</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>17.719680</td>\n",
       "      <td>5.380615</td>\n",
       "      <td>0.083759</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 2, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.860557</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.857705</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.858681</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>17.136951</td>\n",
       "      <td>1.331983</td>\n",
       "      <td>0.084469</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 2, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860099</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.855050</td>\n",
       "      <td>0.854867</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>0.856886</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.711122</td>\n",
       "      <td>5.567298</td>\n",
       "      <td>0.082739</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 3, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.689251</td>\n",
       "      <td>0.689526</td>\n",
       "      <td>0.696548</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.853951</td>\n",
       "      <td>0.724029</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>13.867348</td>\n",
       "      <td>8.220564</td>\n",
       "      <td>0.086172</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 3, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.689251</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.824109</td>\n",
       "      <td>0.067448</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>17.269321</td>\n",
       "      <td>1.591068</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 3, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859275</td>\n",
       "      <td>0.857810</td>\n",
       "      <td>0.854775</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>0.857614</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>15.678647</td>\n",
       "      <td>4.529034</td>\n",
       "      <td>0.083716</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 4, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860557</td>\n",
       "      <td>0.857718</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.858187</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>18.766820</td>\n",
       "      <td>3.428893</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 4, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.857930</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>13.950568</td>\n",
       "      <td>4.463963</td>\n",
       "      <td>0.084736</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(3, 4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858085</td>\n",
       "      <td>0.858726</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.853860</td>\n",
       "      <td>0.856429</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15.478524</td>\n",
       "      <td>2.825390</td>\n",
       "      <td>0.083130</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 2, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858085</td>\n",
       "      <td>0.860923</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.855782</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.857875</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15.526437</td>\n",
       "      <td>2.596218</td>\n",
       "      <td>0.087773</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 2, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863761</td>\n",
       "      <td>0.861564</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.859011</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15.900825</td>\n",
       "      <td>3.921599</td>\n",
       "      <td>0.082685</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 2, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.858542</td>\n",
       "      <td>0.856894</td>\n",
       "      <td>0.861002</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.857797</td>\n",
       "      <td>0.858205</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20.959317</td>\n",
       "      <td>3.944470</td>\n",
       "      <td>0.087043</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 3, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.864768</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.854592</td>\n",
       "      <td>0.859413</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19.425219</td>\n",
       "      <td>3.430793</td>\n",
       "      <td>0.089185</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 3, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>0.858255</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.860178</td>\n",
       "      <td>0.859249</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>19.142573</td>\n",
       "      <td>3.160063</td>\n",
       "      <td>0.084829</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 3, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.854958</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.854409</td>\n",
       "      <td>0.856960</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>16.734364</td>\n",
       "      <td>2.585208</td>\n",
       "      <td>0.085387</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 4, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862571</td>\n",
       "      <td>0.859000</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.860178</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>0.858461</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>15.317711</td>\n",
       "      <td>1.073272</td>\n",
       "      <td>0.079723</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 4, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861014</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.858438</td>\n",
       "      <td>0.854043</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.857894</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>11.734682</td>\n",
       "      <td>1.384646</td>\n",
       "      <td>0.068856</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.07</td>\n",
       "      <td>(4, 4, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.865135</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.860178</td>\n",
       "      <td>0.857980</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.860219</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       10.128447      4.324626         0.082921        0.007652   \n",
       "1       16.825178      2.596659         0.083624        0.003457   \n",
       "2       13.038758      5.210331         0.081968        0.001906   \n",
       "3       16.452147      1.647914         0.087250        0.007125   \n",
       "4       11.005495      4.174497         0.082096        0.005611   \n",
       "5        9.694295      1.492008         0.090998        0.009761   \n",
       "6        9.889145     11.219328         0.086501        0.008817   \n",
       "7       11.690574      5.140968         0.080340        0.006791   \n",
       "8       11.403090      2.586638         0.087042        0.005475   \n",
       "9       17.792281      1.578882         0.083475        0.004781   \n",
       "10      22.478514      5.516243         0.086901        0.008447   \n",
       "11      14.556464      2.377288         0.083871        0.005475   \n",
       "12       5.680422      5.409723         0.088718        0.005479   \n",
       "13      18.007630      9.156823         0.088798        0.011231   \n",
       "14      19.414818      3.167781         0.087070        0.002630   \n",
       "15      19.420305      3.823158         0.087629        0.005294   \n",
       "16      20.957866      3.998486         0.083502        0.006980   \n",
       "17      14.623792      4.480909         0.086238        0.001436   \n",
       "18      16.347293      3.205629         0.088718        0.004620   \n",
       "19      14.429774      2.307198         0.085047        0.009767   \n",
       "20      14.228413      5.568020         0.083827        0.008616   \n",
       "21      22.748655      4.097731         0.087574        0.010322   \n",
       "22      19.331285      4.024008         0.084839        0.007894   \n",
       "23      16.500988      2.839943         0.083519        0.007288   \n",
       "24      18.438173      5.350972         0.084492        0.006080   \n",
       "25      17.356195      3.005091         0.087084        0.011044   \n",
       "26      15.597766      2.817251         0.090150        0.005136   \n",
       "27      10.654168      4.566487         0.083903        0.003543   \n",
       "28      14.389529      1.325659         0.086152        0.005278   \n",
       "29      12.703250      4.781179         0.086474        0.002883   \n",
       "30      17.168977      3.472410         0.082321        0.003950   \n",
       "31      11.000520      4.114816         0.084180        0.001721   \n",
       "32       9.663813      1.456791         0.083249        0.001245   \n",
       "33       9.490922     10.506090         0.089220        0.006348   \n",
       "34      12.737902      2.631426         0.080973        0.005749   \n",
       "35      11.707681      2.328974         0.083559        0.004490   \n",
       "36      18.272124      2.006203         0.084479        0.001713   \n",
       "37      17.719680      5.380615         0.083759        0.002864   \n",
       "38      17.136951      1.331983         0.084469        0.002849   \n",
       "39       5.711122      5.567298         0.082739        0.003602   \n",
       "40      13.867348      8.220564         0.086172        0.009289   \n",
       "41      17.269321      1.591068         0.084404        0.001638   \n",
       "42      15.678647      4.529034         0.083716        0.002961   \n",
       "43      18.766820      3.428893         0.089316        0.005292   \n",
       "44      13.950568      4.463963         0.084736        0.004074   \n",
       "45      15.478524      2.825390         0.083130        0.009908   \n",
       "46      15.526437      2.596218         0.087773        0.009567   \n",
       "47      15.900825      3.921599         0.082685        0.005283   \n",
       "48      20.959317      3.944470         0.087043        0.005698   \n",
       "49      19.425219      3.430793         0.089185        0.008857   \n",
       "50      19.142573      3.160063         0.084829        0.006028   \n",
       "51      16.734364      2.585208         0.085387        0.006822   \n",
       "52      15.317711      1.073272         0.079723        0.008181   \n",
       "53      11.734682      1.384646         0.068856        0.002722   \n",
       "\n",
       "   param_classifier__activation param_classifier__alpha  \\\n",
       "0                          relu                    0.05   \n",
       "1                          relu                    0.05   \n",
       "2                          relu                    0.05   \n",
       "3                          relu                    0.05   \n",
       "4                          relu                    0.05   \n",
       "5                          relu                    0.05   \n",
       "6                          relu                    0.05   \n",
       "7                          relu                    0.05   \n",
       "8                          relu                    0.05   \n",
       "9                          relu                    0.05   \n",
       "10                         relu                    0.05   \n",
       "11                         relu                    0.05   \n",
       "12                         relu                    0.05   \n",
       "13                         relu                    0.05   \n",
       "14                         relu                    0.05   \n",
       "15                         relu                    0.05   \n",
       "16                         relu                    0.05   \n",
       "17                         relu                    0.05   \n",
       "18                         relu                    0.05   \n",
       "19                         relu                    0.05   \n",
       "20                         relu                    0.05   \n",
       "21                         relu                    0.05   \n",
       "22                         relu                    0.05   \n",
       "23                         relu                    0.05   \n",
       "24                         relu                    0.05   \n",
       "25                         relu                    0.05   \n",
       "26                         relu                    0.05   \n",
       "27                         relu                    0.07   \n",
       "28                         relu                    0.07   \n",
       "29                         relu                    0.07   \n",
       "30                         relu                    0.07   \n",
       "31                         relu                    0.07   \n",
       "32                         relu                    0.07   \n",
       "33                         relu                    0.07   \n",
       "34                         relu                    0.07   \n",
       "35                         relu                    0.07   \n",
       "36                         relu                    0.07   \n",
       "37                         relu                    0.07   \n",
       "38                         relu                    0.07   \n",
       "39                         relu                    0.07   \n",
       "40                         relu                    0.07   \n",
       "41                         relu                    0.07   \n",
       "42                         relu                    0.07   \n",
       "43                         relu                    0.07   \n",
       "44                         relu                    0.07   \n",
       "45                         relu                    0.07   \n",
       "46                         relu                    0.07   \n",
       "47                         relu                    0.07   \n",
       "48                         relu                    0.07   \n",
       "49                         relu                    0.07   \n",
       "50                         relu                    0.07   \n",
       "51                         relu                    0.07   \n",
       "52                         relu                    0.07   \n",
       "53                         relu                    0.07   \n",
       "\n",
       "   param_classifier__hidden_layer_sizes param_classifier__learning_rate  \\\n",
       "0                             (2, 2, 2)                        adaptive   \n",
       "1                             (2, 2, 3)                        adaptive   \n",
       "2                             (2, 2, 4)                        adaptive   \n",
       "3                             (2, 3, 2)                        adaptive   \n",
       "4                             (2, 3, 3)                        adaptive   \n",
       "5                             (2, 3, 4)                        adaptive   \n",
       "6                             (2, 4, 2)                        adaptive   \n",
       "7                             (2, 4, 3)                        adaptive   \n",
       "8                             (2, 4, 4)                        adaptive   \n",
       "9                             (3, 2, 2)                        adaptive   \n",
       "10                            (3, 2, 3)                        adaptive   \n",
       "11                            (3, 2, 4)                        adaptive   \n",
       "12                            (3, 3, 2)                        adaptive   \n",
       "13                            (3, 3, 3)                        adaptive   \n",
       "14                            (3, 3, 4)                        adaptive   \n",
       "15                            (3, 4, 2)                        adaptive   \n",
       "16                            (3, 4, 3)                        adaptive   \n",
       "17                            (3, 4, 4)                        adaptive   \n",
       "18                            (4, 2, 2)                        adaptive   \n",
       "19                            (4, 2, 3)                        adaptive   \n",
       "20                            (4, 2, 4)                        adaptive   \n",
       "21                            (4, 3, 2)                        adaptive   \n",
       "22                            (4, 3, 3)                        adaptive   \n",
       "23                            (4, 3, 4)                        adaptive   \n",
       "24                            (4, 4, 2)                        adaptive   \n",
       "25                            (4, 4, 3)                        adaptive   \n",
       "26                            (4, 4, 4)                        adaptive   \n",
       "27                            (2, 2, 2)                        adaptive   \n",
       "28                            (2, 2, 3)                        adaptive   \n",
       "29                            (2, 2, 4)                        adaptive   \n",
       "30                            (2, 3, 2)                        adaptive   \n",
       "31                            (2, 3, 3)                        adaptive   \n",
       "32                            (2, 3, 4)                        adaptive   \n",
       "33                            (2, 4, 2)                        adaptive   \n",
       "34                            (2, 4, 3)                        adaptive   \n",
       "35                            (2, 4, 4)                        adaptive   \n",
       "36                            (3, 2, 2)                        adaptive   \n",
       "37                            (3, 2, 3)                        adaptive   \n",
       "38                            (3, 2, 4)                        adaptive   \n",
       "39                            (3, 3, 2)                        adaptive   \n",
       "40                            (3, 3, 3)                        adaptive   \n",
       "41                            (3, 3, 4)                        adaptive   \n",
       "42                            (3, 4, 2)                        adaptive   \n",
       "43                            (3, 4, 3)                        adaptive   \n",
       "44                            (3, 4, 4)                        adaptive   \n",
       "45                            (4, 2, 2)                        adaptive   \n",
       "46                            (4, 2, 3)                        adaptive   \n",
       "47                            (4, 2, 4)                        adaptive   \n",
       "48                            (4, 3, 2)                        adaptive   \n",
       "49                            (4, 3, 3)                        adaptive   \n",
       "50                            (4, 3, 4)                        adaptive   \n",
       "51                            (4, 4, 2)                        adaptive   \n",
       "52                            (4, 4, 3)                        adaptive   \n",
       "53                            (4, 4, 4)                        adaptive   \n",
       "\n",
       "   param_classifier__max_iter param_classifier__solver  \\\n",
       "0                         500                     adam   \n",
       "1                         500                     adam   \n",
       "2                         500                     adam   \n",
       "3                         500                     adam   \n",
       "4                         500                     adam   \n",
       "5                         500                     adam   \n",
       "6                         500                     adam   \n",
       "7                         500                     adam   \n",
       "8                         500                     adam   \n",
       "9                         500                     adam   \n",
       "10                        500                     adam   \n",
       "11                        500                     adam   \n",
       "12                        500                     adam   \n",
       "13                        500                     adam   \n",
       "14                        500                     adam   \n",
       "15                        500                     adam   \n",
       "16                        500                     adam   \n",
       "17                        500                     adam   \n",
       "18                        500                     adam   \n",
       "19                        500                     adam   \n",
       "20                        500                     adam   \n",
       "21                        500                     adam   \n",
       "22                        500                     adam   \n",
       "23                        500                     adam   \n",
       "24                        500                     adam   \n",
       "25                        500                     adam   \n",
       "26                        500                     adam   \n",
       "27                        500                     adam   \n",
       "28                        500                     adam   \n",
       "29                        500                     adam   \n",
       "30                        500                     adam   \n",
       "31                        500                     adam   \n",
       "32                        500                     adam   \n",
       "33                        500                     adam   \n",
       "34                        500                     adam   \n",
       "35                        500                     adam   \n",
       "36                        500                     adam   \n",
       "37                        500                     adam   \n",
       "38                        500                     adam   \n",
       "39                        500                     adam   \n",
       "40                        500                     adam   \n",
       "41                        500                     adam   \n",
       "42                        500                     adam   \n",
       "43                        500                     adam   \n",
       "44                        500                     adam   \n",
       "45                        500                     adam   \n",
       "46                        500                     adam   \n",
       "47                        500                     adam   \n",
       "48                        500                     adam   \n",
       "49                        500                     adam   \n",
       "50                        500                     adam   \n",
       "51                        500                     adam   \n",
       "52                        500                     adam   \n",
       "53                        500                     adam   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'classifier__activation': 'relu', 'classifier...           0.860007   \n",
       "1   {'classifier__activation': 'relu', 'classifier...           0.860282   \n",
       "2   {'classifier__activation': 'relu', 'classifier...           0.860557   \n",
       "3   {'classifier__activation': 'relu', 'classifier...           0.862846   \n",
       "4   {'classifier__activation': 'relu', 'classifier...           0.859092   \n",
       "5   {'classifier__activation': 'relu', 'classifier...           0.859916   \n",
       "6   {'classifier__activation': 'relu', 'classifier...           0.689251   \n",
       "7   {'classifier__activation': 'relu', 'classifier...           0.858359   \n",
       "8   {'classifier__activation': 'relu', 'classifier...           0.859183   \n",
       "9   {'classifier__activation': 'relu', 'classifier...           0.861564   \n",
       "10  {'classifier__activation': 'relu', 'classifier...           0.860099   \n",
       "11  {'classifier__activation': 'relu', 'classifier...           0.862479   \n",
       "12  {'classifier__activation': 'relu', 'classifier...           0.689251   \n",
       "13  {'classifier__activation': 'relu', 'classifier...           0.689251   \n",
       "14  {'classifier__activation': 'relu', 'classifier...           0.859092   \n",
       "15  {'classifier__activation': 'relu', 'classifier...           0.859183   \n",
       "16  {'classifier__activation': 'relu', 'classifier...           0.859733   \n",
       "17  {'classifier__activation': 'relu', 'classifier...           0.858176   \n",
       "18  {'classifier__activation': 'relu', 'classifier...           0.861381   \n",
       "19  {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "20  {'classifier__activation': 'relu', 'classifier...           0.859733   \n",
       "21  {'classifier__activation': 'relu', 'classifier...           0.863944   \n",
       "22  {'classifier__activation': 'relu', 'classifier...           0.859092   \n",
       "23  {'classifier__activation': 'relu', 'classifier...           0.863395   \n",
       "24  {'classifier__activation': 'relu', 'classifier...           0.862479   \n",
       "25  {'classifier__activation': 'relu', 'classifier...           0.861838   \n",
       "26  {'classifier__activation': 'relu', 'classifier...           0.861838   \n",
       "27  {'classifier__activation': 'relu', 'classifier...           0.860557   \n",
       "28  {'classifier__activation': 'relu', 'classifier...           0.859366   \n",
       "29  {'classifier__activation': 'relu', 'classifier...           0.860099   \n",
       "30  {'classifier__activation': 'relu', 'classifier...           0.863029   \n",
       "31  {'classifier__activation': 'relu', 'classifier...           0.859366   \n",
       "32  {'classifier__activation': 'relu', 'classifier...           0.860465   \n",
       "33  {'classifier__activation': 'relu', 'classifier...           0.689251   \n",
       "34  {'classifier__activation': 'relu', 'classifier...           0.861106   \n",
       "35  {'classifier__activation': 'relu', 'classifier...           0.859092   \n",
       "36  {'classifier__activation': 'relu', 'classifier...           0.861014   \n",
       "37  {'classifier__activation': 'relu', 'classifier...           0.862388   \n",
       "38  {'classifier__activation': 'relu', 'classifier...           0.860099   \n",
       "39  {'classifier__activation': 'relu', 'classifier...           0.689251   \n",
       "40  {'classifier__activation': 'relu', 'classifier...           0.689251   \n",
       "41  {'classifier__activation': 'relu', 'classifier...           0.859275   \n",
       "42  {'classifier__activation': 'relu', 'classifier...           0.860557   \n",
       "43  {'classifier__activation': 'relu', 'classifier...           0.859733   \n",
       "44  {'classifier__activation': 'relu', 'classifier...           0.858085   \n",
       "45  {'classifier__activation': 'relu', 'classifier...           0.858085   \n",
       "46  {'classifier__activation': 'relu', 'classifier...           0.863761   \n",
       "47  {'classifier__activation': 'relu', 'classifier...           0.858542   \n",
       "48  {'classifier__activation': 'relu', 'classifier...           0.864768   \n",
       "49  {'classifier__activation': 'relu', 'classifier...           0.859366   \n",
       "50  {'classifier__activation': 'relu', 'classifier...           0.859366   \n",
       "51  {'classifier__activation': 'relu', 'classifier...           0.862571   \n",
       "52  {'classifier__activation': 'relu', 'classifier...           0.861014   \n",
       "53  {'classifier__activation': 'relu', 'classifier...           0.865135   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.857169           0.856790           0.859262   \n",
       "1            0.857627           0.854409           0.857248   \n",
       "2            0.859550           0.852211           0.858529   \n",
       "3            0.859183           0.855691           0.857431   \n",
       "4            0.857535           0.856973           0.858804   \n",
       "5            0.859366           0.857522           0.858346   \n",
       "6            0.689526           0.696548           0.690871   \n",
       "7            0.857627           0.855691           0.858713   \n",
       "8            0.856437           0.856240           0.858255   \n",
       "9            0.858176           0.854043           0.856881   \n",
       "10           0.858726           0.857156           0.857614   \n",
       "11           0.857810           0.857064           0.858987   \n",
       "12           0.689526           0.696548           0.690871   \n",
       "13           0.860007           0.855508           0.859903   \n",
       "14           0.859733           0.855508           0.856423   \n",
       "15           0.859366           0.856057           0.857797   \n",
       "16           0.861747           0.853768           0.857248   \n",
       "17           0.859366           0.856515           0.854958   \n",
       "18           0.862479           0.855874           0.857431   \n",
       "19           0.861198           0.855416           0.860361   \n",
       "20           0.856986           0.858438           0.855325   \n",
       "21           0.858359           0.858529           0.861368   \n",
       "22           0.858726           0.855966           0.857522   \n",
       "23           0.857993           0.855233           0.857797   \n",
       "24           0.860465           0.858713           0.861917   \n",
       "25           0.859092           0.856149           0.857156   \n",
       "26           0.862846           0.858896           0.858346   \n",
       "27           0.857261           0.856240           0.859628   \n",
       "28           0.857352           0.856057           0.858438   \n",
       "29           0.859550           0.855050           0.859170   \n",
       "30           0.859183           0.855966           0.858255   \n",
       "31           0.857352           0.857156           0.858346   \n",
       "32           0.859275           0.857614           0.858621   \n",
       "33           0.689526           0.696548           0.690871   \n",
       "34           0.859916           0.855416           0.858163   \n",
       "35           0.856894           0.855141           0.856332   \n",
       "36           0.858542           0.855599           0.855874   \n",
       "37           0.860557           0.856698           0.857705   \n",
       "38           0.858268           0.855050           0.854867   \n",
       "39           0.689526           0.696548           0.690871   \n",
       "40           0.859733           0.855416           0.859354   \n",
       "41           0.857810           0.854775           0.856240   \n",
       "42           0.857718           0.856332           0.859170   \n",
       "43           0.862022           0.856149           0.856332   \n",
       "44           0.858726           0.856057           0.855416   \n",
       "45           0.860923           0.857248           0.855782   \n",
       "46           0.861564           0.855874           0.856423   \n",
       "47           0.856894           0.861002           0.856790   \n",
       "48           0.861289           0.857064           0.859354   \n",
       "49           0.859550           0.858255           0.858896   \n",
       "50           0.857627           0.854958           0.858438   \n",
       "51           0.859000           0.855874           0.860178   \n",
       "52           0.860282           0.858438           0.854043   \n",
       "53           0.862388           0.860178           0.857980   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.696456         0.825937        0.064752               45  \n",
       "1            0.857797         0.857472        0.001869               31  \n",
       "2            0.696456         0.825461        0.064568               48  \n",
       "3            0.854226         0.857875        0.002990               24  \n",
       "4            0.696456         0.825772        0.064663               46  \n",
       "5            0.856607         0.858351        0.001201               15  \n",
       "6            0.857156         0.724670        0.066295               51  \n",
       "7            0.855233         0.857125        0.001409               36  \n",
       "8            0.855141         0.857051        0.001461               37  \n",
       "9            0.856332         0.857399        0.002475               32  \n",
       "10           0.854317         0.857582        0.001923               30  \n",
       "11           0.855416         0.858351        0.002367               16  \n",
       "12           0.854134         0.724066        0.065088               53  \n",
       "13           0.857522         0.824438        0.067614               49  \n",
       "14           0.858163         0.857784        0.001593               25  \n",
       "15           0.855782         0.857637        0.001506               28  \n",
       "16           0.854226         0.857344        0.003086               33  \n",
       "17           0.855782         0.856960        0.001604               39  \n",
       "18           0.856790         0.858791        0.002633                9  \n",
       "19           0.857797         0.859743        0.002921                4  \n",
       "20           0.855508         0.857198        0.001695               34  \n",
       "21           0.860178         0.860476        0.002058                1  \n",
       "22           0.861368         0.858535        0.001789               11  \n",
       "23           0.857888         0.858461        0.002674               12  \n",
       "24           0.855141         0.859743        0.002645                3  \n",
       "25           0.856973         0.858242        0.002041               17  \n",
       "26           0.856240         0.859633        0.002404                5  \n",
       "27           0.696456         0.826028        0.064805               44  \n",
       "28           0.856698         0.857582        0.001190               29  \n",
       "29           0.696456         0.826065        0.064829               43  \n",
       "30           0.853035         0.857894        0.003331               22  \n",
       "31           0.696456         0.825735        0.064644               47  \n",
       "32           0.855874         0.858370        0.001554               14  \n",
       "33           0.856515         0.724542        0.066039               52  \n",
       "34           0.853860         0.857692        0.002709               27  \n",
       "35           0.856240         0.856740        0.001306               41  \n",
       "36           0.857797         0.857765        0.001971               26  \n",
       "37           0.856057         0.858681        0.002409               10  \n",
       "38           0.856149         0.856886        0.002011               40  \n",
       "39           0.853951         0.724029        0.065014               54  \n",
       "40           0.856790         0.824109        0.067448               50  \n",
       "41           0.857614         0.857143        0.001525               35  \n",
       "42           0.857156         0.858187        0.001504               19  \n",
       "43           0.855416         0.857930        0.002531               20  \n",
       "44           0.853860         0.856429        0.001777               42  \n",
       "45           0.857339         0.857875        0.001697               23  \n",
       "46           0.857431         0.859011        0.003102                8  \n",
       "47           0.857797         0.858205        0.001538               18  \n",
       "48           0.854592         0.859413        0.003492                6  \n",
       "49           0.860178         0.859249        0.000645                7  \n",
       "50           0.854409         0.856960        0.001946               38  \n",
       "51           0.854684         0.858461        0.002867               13  \n",
       "52           0.855691         0.857894        0.002662               21  \n",
       "53           0.855416         0.860219        0.003375                2  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_3 = pd.DataFrame(nn_grid_search_3_cv.cv_results_)\n",
    "cv_res_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e74d230b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__activation': 'relu',\n",
       " 'classifier__alpha': 0.05,\n",
       " 'classifier__hidden_layer_sizes': (4, 3, 2),\n",
       " 'classifier__learning_rate': 'adaptive',\n",
       " 'classifier__max_iter': 500,\n",
       " 'classifier__solver': 'adam'}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search_3_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2f0c3f58",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__activation</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__hidden_layer_sizes</th>\n",
       "      <th>param_classifier__learning_rate_init</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.882455</td>\n",
       "      <td>3.683285</td>\n",
       "      <td>0.080744</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862754</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.859926</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8      14.882455      3.683285         0.080744        0.005577   \n",
       "\n",
       "  param_classifier__activation param_classifier__alpha  \\\n",
       "8                         relu                    0.05   \n",
       "\n",
       "  param_classifier__hidden_layer_sizes param_classifier__learning_rate_init  \\\n",
       "8                               (4, 4)                                0.001   \n",
       "\n",
       "  param_classifier__max_iter param_classifier__solver  \\\n",
       "8                        300                     adam   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "8  {'classifier__activation': 'relu', 'classifier...           0.862754   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "8           0.861747           0.857156           0.860727           0.857248   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "8         0.859926        0.002315                2  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores = nn_grid_search_3_cv.cv_results_[\"mean_test_score\"]\n",
    "best_index = np.argmax(mean_scores)\n",
    "se_scores = nn_grid_search_3_cv.cv_results_[\"std_test_score\"] / np.sqrt(5)\n",
    "\n",
    "one_stand_error_data_frame = cv_res[cv_res[\"mean_test_score\"] >= (mean_scores[best_index] - se_scores[best_index])]\n",
    "one_stand_error_data_frame[one_stand_error_data_frame[\"mean_test_score\"] == one_stand_error_data_frame[\"mean_test_score\"].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c678c86d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## For 3 Layers Only: Further Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b4699ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_combinations_layers_3_bis = []\n",
    "for i in np.arange(3, 7):\n",
    "    for j in np.arange(3, 7):\n",
    "        for k in np.arange(3, 7):\n",
    "            list_combinations_layers_3_bis.append((i, j, k))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dbacc40",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__hidden_layer_sizes': [(3, 3, 3),\n",
       "  (3, 3, 4),\n",
       "  (3, 3, 5),\n",
       "  (3, 3, 6),\n",
       "  (3, 4, 3),\n",
       "  (3, 4, 4),\n",
       "  (3, 4, 5),\n",
       "  (3, 4, 6),\n",
       "  (3, 5, 3),\n",
       "  (3, 5, 4),\n",
       "  (3, 5, 5),\n",
       "  (3, 5, 6),\n",
       "  (3, 6, 3),\n",
       "  (3, 6, 4),\n",
       "  (3, 6, 5),\n",
       "  (3, 6, 6),\n",
       "  (4, 3, 3),\n",
       "  (4, 3, 4),\n",
       "  (4, 3, 5),\n",
       "  (4, 3, 6),\n",
       "  (4, 4, 3),\n",
       "  (4, 4, 4),\n",
       "  (4, 4, 5),\n",
       "  (4, 4, 6),\n",
       "  (4, 5, 3),\n",
       "  (4, 5, 4),\n",
       "  (4, 5, 5),\n",
       "  (4, 5, 6),\n",
       "  (4, 6, 3),\n",
       "  (4, 6, 4),\n",
       "  (4, 6, 5),\n",
       "  (4, 6, 6),\n",
       "  (5, 3, 3),\n",
       "  (5, 3, 4),\n",
       "  (5, 3, 5),\n",
       "  (5, 3, 6),\n",
       "  (5, 4, 3),\n",
       "  (5, 4, 4),\n",
       "  (5, 4, 5),\n",
       "  (5, 4, 6),\n",
       "  (5, 5, 3),\n",
       "  (5, 5, 4),\n",
       "  (5, 5, 5),\n",
       "  (5, 5, 6),\n",
       "  (5, 6, 3),\n",
       "  (5, 6, 4),\n",
       "  (5, 6, 5),\n",
       "  (5, 6, 6),\n",
       "  (6, 3, 3),\n",
       "  (6, 3, 4),\n",
       "  (6, 3, 5),\n",
       "  (6, 3, 6),\n",
       "  (6, 4, 3),\n",
       "  (6, 4, 4),\n",
       "  (6, 4, 5),\n",
       "  (6, 4, 6),\n",
       "  (6, 5, 3),\n",
       "  (6, 5, 4),\n",
       "  (6, 5, 5),\n",
       "  (6, 5, 6),\n",
       "  (6, 6, 3),\n",
       "  (6, 6, 4),\n",
       "  (6, 6, 5),\n",
       "  (6, 6, 6)],\n",
       " 'classifier__activation': ['relu'],\n",
       " 'classifier__solver': ['adam'],\n",
       " 'classifier__alpha': [0.05],\n",
       " 'classifier__learning_rate': ['adaptive'],\n",
       " 'classifier__max_iter': [500]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param_3_bis = {\n",
    "    \"classifier__hidden_layer_sizes\": list_combinations_layers_3_bis, \n",
    "              \"classifier__activation\": ['relu'],\n",
    "              \"classifier__solver\": ['adam'],\n",
    "              \"classifier__alpha\": [0.05],\n",
    "              \"classifier__learning_rate\": ['adaptive'],\n",
    "              \"classifier__max_iter\": [500],\n",
    "}\n",
    "\n",
    "hyper_param_3_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32676ec5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nn_grid_search_3_bis_cv = GridSearchCV(estimator = clf, param_grid=hyper_param_3_bis, scoring=\"accuracy\",\n",
    "                           cv = KFold(n_splits=5, shuffle=True, random_state=1), n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff23ced8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['occ_code_level2',\n",
       "                                                                          'age',\n",
       "                                                                          'stock_dividends',\n",
       "                                                                          'wage_per_hour',\n",
       "                                                                          'capital_losses',\n",
       "                                                                          'own_or_self',\n",
       "                                                                          'ind_code_level2',\n",
       "                                                                          'capital_gains',\n",
       "                                                                          'week...\n",
       "                                                            (3, 3, 6),\n",
       "                                                            (3, 4, 3),\n",
       "                                                            (3, 4, 4),\n",
       "                                                            (3, 4, 5),\n",
       "                                                            (3, 4, 6),\n",
       "                                                            (3, 5, 3),\n",
       "                                                            (3, 5, 4),\n",
       "                                                            (3, 5, 5),\n",
       "                                                            (3, 5, 6),\n",
       "                                                            (3, 6, 3),\n",
       "                                                            (3, 6, 4),\n",
       "                                                            (3, 6, 5),\n",
       "                                                            (3, 6, 6),\n",
       "                                                            (4, 3, 3),\n",
       "                                                            (4, 3, 4),\n",
       "                                                            (4, 3, 5),\n",
       "                                                            (4, 3, 6),\n",
       "                                                            (4, 4, 3),\n",
       "                                                            (4, 4, 4),\n",
       "                                                            (4, 4, 5),\n",
       "                                                            (4, 4, 6),\n",
       "                                                            (4, 5, 3),\n",
       "                                                            (4, 5, 4),\n",
       "                                                            (4, 5, 5),\n",
       "                                                            (4, 5, 6),\n",
       "                                                            (4, 6, 3),\n",
       "                                                            (4, 6, 4), ...],\n",
       "                         'classifier__learning_rate': ['adaptive'],\n",
       "                         'classifier__max_iter': [500],\n",
       "                         'classifier__solver': ['adam']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search_3_bis_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a98afdd",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__activation</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__hidden_layer_sizes</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.136612</td>\n",
       "      <td>12.802592</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 3, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.689251</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.067614</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.422111</td>\n",
       "      <td>5.761657</td>\n",
       "      <td>0.122802</td>\n",
       "      <td>0.040248</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 3, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859092</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>0.857784</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.257417</td>\n",
       "      <td>4.245060</td>\n",
       "      <td>0.117979</td>\n",
       "      <td>0.028292</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 3, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.855325</td>\n",
       "      <td>0.855325</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.857271</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.826344</td>\n",
       "      <td>8.082648</td>\n",
       "      <td>0.108971</td>\n",
       "      <td>0.026733</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 3, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.859916</td>\n",
       "      <td>0.851387</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>0.857033</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.033522</td>\n",
       "      <td>3.349086</td>\n",
       "      <td>0.117198</td>\n",
       "      <td>0.035801</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(3, 4, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>0.861747</td>\n",
       "      <td>0.853768</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.854226</td>\n",
       "      <td>0.857344</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>19.768195</td>\n",
       "      <td>5.414982</td>\n",
       "      <td>0.092075</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 5, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.859487</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>24.913933</td>\n",
       "      <td>4.022864</td>\n",
       "      <td>0.078287</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 6, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.862937</td>\n",
       "      <td>0.859275</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.859194</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>26.132830</td>\n",
       "      <td>3.378800</td>\n",
       "      <td>0.105675</td>\n",
       "      <td>0.019195</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 6, 4)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.853860</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.857546</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>27.450243</td>\n",
       "      <td>4.270590</td>\n",
       "      <td>0.077526</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 6, 5)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.860557</td>\n",
       "      <td>0.860099</td>\n",
       "      <td>0.859720</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.859725</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>21.862521</td>\n",
       "      <td>3.072915</td>\n",
       "      <td>0.070306</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(6, 6, 6)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863761</td>\n",
       "      <td>0.861198</td>\n",
       "      <td>0.852761</td>\n",
       "      <td>0.858713</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       24.136612     12.802592         0.096552        0.003779   \n",
       "1       25.422111      5.761657         0.122802        0.040248   \n",
       "2       22.257417      4.245060         0.117979        0.028292   \n",
       "3       24.826344      8.082648         0.108971        0.026733   \n",
       "4       26.033522      3.349086         0.117198        0.035801   \n",
       "..            ...           ...              ...             ...   \n",
       "59      19.768195      5.414982         0.092075        0.013535   \n",
       "60      24.913933      4.022864         0.078287        0.001567   \n",
       "61      26.132830      3.378800         0.105675        0.019195   \n",
       "62      27.450243      4.270590         0.077526        0.004023   \n",
       "63      21.862521      3.072915         0.070306        0.003300   \n",
       "\n",
       "   param_classifier__activation param_classifier__alpha  \\\n",
       "0                          relu                    0.05   \n",
       "1                          relu                    0.05   \n",
       "2                          relu                    0.05   \n",
       "3                          relu                    0.05   \n",
       "4                          relu                    0.05   \n",
       "..                          ...                     ...   \n",
       "59                         relu                    0.05   \n",
       "60                         relu                    0.05   \n",
       "61                         relu                    0.05   \n",
       "62                         relu                    0.05   \n",
       "63                         relu                    0.05   \n",
       "\n",
       "   param_classifier__hidden_layer_sizes param_classifier__learning_rate  \\\n",
       "0                             (3, 3, 3)                        adaptive   \n",
       "1                             (3, 3, 4)                        adaptive   \n",
       "2                             (3, 3, 5)                        adaptive   \n",
       "3                             (3, 3, 6)                        adaptive   \n",
       "4                             (3, 4, 3)                        adaptive   \n",
       "..                                  ...                             ...   \n",
       "59                            (6, 5, 6)                        adaptive   \n",
       "60                            (6, 6, 3)                        adaptive   \n",
       "61                            (6, 6, 4)                        adaptive   \n",
       "62                            (6, 6, 5)                        adaptive   \n",
       "63                            (6, 6, 6)                        adaptive   \n",
       "\n",
       "   param_classifier__max_iter param_classifier__solver  \\\n",
       "0                         500                     adam   \n",
       "1                         500                     adam   \n",
       "2                         500                     adam   \n",
       "3                         500                     adam   \n",
       "4                         500                     adam   \n",
       "..                        ...                      ...   \n",
       "59                        500                     adam   \n",
       "60                        500                     adam   \n",
       "61                        500                     adam   \n",
       "62                        500                     adam   \n",
       "63                        500                     adam   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'classifier__activation': 'relu', 'classifier...           0.689251   \n",
       "1   {'classifier__activation': 'relu', 'classifier...           0.859092   \n",
       "2   {'classifier__activation': 'relu', 'classifier...           0.861747   \n",
       "3   {'classifier__activation': 'relu', 'classifier...           0.859366   \n",
       "4   {'classifier__activation': 'relu', 'classifier...           0.859733   \n",
       "..                                                ...                ...   \n",
       "59  {'classifier__activation': 'relu', 'classifier...           0.861472   \n",
       "60  {'classifier__activation': 'relu', 'classifier...           0.862937   \n",
       "61  {'classifier__activation': 'relu', 'classifier...           0.860007   \n",
       "62  {'classifier__activation': 'relu', 'classifier...           0.860557   \n",
       "63  {'classifier__activation': 'relu', 'classifier...           0.863761   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.860007           0.855508           0.859903   \n",
       "1            0.859733           0.855508           0.856423   \n",
       "2            0.858268           0.855325           0.855325   \n",
       "3            0.859916           0.851387           0.857064   \n",
       "4            0.861747           0.853768           0.857248   \n",
       "..                ...                ...                ...   \n",
       "59           0.860465           0.856881           0.859720   \n",
       "60           0.859275           0.857156           0.857064   \n",
       "61           0.859366           0.857339           0.853860   \n",
       "62           0.860099           0.859720           0.859445   \n",
       "63           0.861198           0.852761           0.858713   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.857522         0.824438        0.067614               63  \n",
       "1            0.858163         0.857784        0.001593               51  \n",
       "2            0.855691         0.857271        0.002494               56  \n",
       "3            0.857431         0.857033        0.003026               59  \n",
       "4            0.854226         0.857344        0.003086               55  \n",
       "..                ...              ...             ...              ...  \n",
       "59           0.858896         0.859487        0.001555               11  \n",
       "60           0.859537         0.859194        0.002137               15  \n",
       "61           0.857156         0.857546        0.002152               53  \n",
       "62           0.858804         0.859725        0.000593                5  \n",
       "63           0.855233         0.858333        0.003962               35  \n",
       "\n",
       "[64 rows x 19 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_3_bis = pd.DataFrame(nn_grid_search_3_bis_cv.cv_results_)\n",
    "cv_res_3_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a12f56ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__activation</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__hidden_layer_sizes</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>27.282106</td>\n",
       "      <td>5.024387</td>\n",
       "      <td>0.133753</td>\n",
       "      <td>0.032768</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(5, 4, 3)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>500</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.859432</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "36      27.282106      5.024387         0.133753        0.032768   \n",
       "\n",
       "   param_classifier__activation param_classifier__alpha  \\\n",
       "36                         relu                    0.05   \n",
       "\n",
       "   param_classifier__hidden_layer_sizes param_classifier__learning_rate  \\\n",
       "36                            (5, 4, 3)                        adaptive   \n",
       "\n",
       "   param_classifier__max_iter param_classifier__solver  \\\n",
       "36                        500                     adam   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "36  {'classifier__activation': 'relu', 'classifier...           0.863212   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "36           0.861655           0.857064           0.859537   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "36           0.855691         0.859432        0.002787               13  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores = nn_grid_search_3_bis_cv.cv_results_[\"mean_test_score\"]\n",
    "best_index = np.argmax(mean_scores)\n",
    "se_scores = nn_grid_search_3_bis_cv.cv_results_[\"std_test_score\"] / np.sqrt(5)\n",
    "\n",
    "one_stand_error_data_frame = cv_res_3_bis[cv_res_3_bis[\"mean_test_score\"] >= (mean_scores[best_index] - se_scores[best_index])]\n",
    "one_stand_error_data_frame[one_stand_error_data_frame[\"mean_test_score\"] == one_stand_error_data_frame[\"mean_test_score\"].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698c4c1",
   "metadata": {},
   "source": [
    "## Fit the best model & export the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b30a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer_num',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['occ_code_level2', 'age',\n",
       "                                                   'stock_dividends',\n",
       "                                                   'wage_per_hour',\n",
       "                                                   'capital_losses',\n",
       "                                                   'own_or_self',\n",
       "                                                   'ind_code_level2',\n",
       "                                                   'capital_gains',\n",
       "                                                   'weeks_worked', 'num_emp',\n",
       "                                                   'vet_benefits']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer_ca...\n",
       "                                                   'state_prev_res', 'race',\n",
       "                                                   'country_mother', 'sex',\n",
       "                                                   'ind_code_level1',\n",
       "                                                   'citizenship',\n",
       "                                                   'union_member',\n",
       "                                                   'fam_under_18',\n",
       "                                                   'marital_stat',\n",
       "                                                   'region_prev_res',\n",
       "                                                   'mig_chg_reg',\n",
       "                                                   'country_father',\n",
       "                                                   'occ_code_level1',\n",
       "                                                   'full_or_part_emp',\n",
       "                                                   'det_hh_fam_stat'])])),\n",
       "                ('classifier',\n",
       "                 MLPClassifier(alpha=0.15, hidden_layer_sizes=(8, 2),\n",
       "                               learning_rate='adaptive', max_iter=700,\n",
       "                               random_state=1))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(classifier__activation= 'relu', classifier__alpha = 0.15, classifier__hidden_layer_sizes = (8,2), classifier__solver = 'adam', classifier__max_iter = 700, classifier__learning_rate = 'adaptive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d888b306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer_num',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['occ_code_level2', 'age',\n",
       "                                                   'stock_dividends',\n",
       "                                                   'wage_per_hour',\n",
       "                                                   'capital_losses',\n",
       "                                                   'own_or_self',\n",
       "                                                   'ind_code_level2',\n",
       "                                                   'capital_gains',\n",
       "                                                   'weeks_worked', 'num_emp',\n",
       "                                                   'vet_benefits']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer_ca...\n",
       "                                                   'state_prev_res', 'race',\n",
       "                                                   'country_mother', 'sex',\n",
       "                                                   'ind_code_level1',\n",
       "                                                   'citizenship',\n",
       "                                                   'union_member',\n",
       "                                                   'fam_under_18',\n",
       "                                                   'marital_stat',\n",
       "                                                   'region_prev_res',\n",
       "                                                   'mig_chg_reg',\n",
       "                                                   'country_father',\n",
       "                                                   'occ_code_level1',\n",
       "                                                   'full_or_part_emp',\n",
       "                                                   'det_hh_fam_stat'])])),\n",
       "                ('classifier',\n",
       "                 MLPClassifier(alpha=0.15, hidden_layer_sizes=(8, 2),\n",
       "                               learning_rate='adaptive', max_iter=700,\n",
       "                               random_state=1))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efb70eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_df[[\"id\"]]\n",
    "test_df.drop(\"id\",axis = 1, inplace = True)\n",
    "\n",
    "y_test_pred = clf.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "224b5b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d885e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>6064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>6065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>6066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>6067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>6068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6068 rows Ã 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id\n",
       "0        1\n",
       "1        2\n",
       "2        3\n",
       "3        4\n",
       "4        5\n",
       "...    ...\n",
       "6063  6064\n",
       "6064  6065\n",
       "6065  6066\n",
       "6066  6067\n",
       "6067  6068\n",
       "\n",
       "[6068 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_8_2 = test_id\n",
    "nn_8_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64a7da36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/j3q5g8gs44n5d1rkmyq_rtv40000gn/T/ipykernel_1710/3932108181.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nn_8_2[\"high_income\"] = y_test_pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>high_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>6064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>6065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>6066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>6067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>6068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6068 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  high_income\n",
       "0        1            0\n",
       "1        2            0\n",
       "2        3            0\n",
       "3        4            1\n",
       "4        5            0\n",
       "...    ...          ...\n",
       "6063  6064            0\n",
       "6064  6065            1\n",
       "6065  6066            0\n",
       "6066  6067            0\n",
       "6067  6068            1\n",
       "\n",
       "[6068 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_8_2[\"high_income\"] = y_test_pred\n",
    "nn_8_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "543f52be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_8_2.to_csv(\"Predictions/nn_8_2.csv\",index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
